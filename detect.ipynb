{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b676c638-f48d-49a7-a1a1-6fe98e5b5d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fea66d1b-2c79-4b27-9ad9-63c735af94ed",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    WARNING  stream/video/webcam/dir predict source will accumulate results in RAM unless `stream=True` is passed,\n",
      "    causing potential out-of-memory errors for large sources or long-running streams/videos.\n",
      "\n",
      "    Usage:\n",
      "        results = model(source=..., stream=True)  # generator of Results objects\n",
      "        for r in results:\n",
      "            boxes = r.boxes  # Boxes object for bbox outputs\n",
      "            masks = r.masks  # Masks object for segment masks outputs\n",
      "            probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "video 1/1 (1/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 (no detections), 20.1ms\n",
      "video 1/1 (2/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 (no detections), 34.0ms\n",
      "video 1/1 (3/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 (no detections), 35.0ms\n",
      "video 1/1 (4/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 (no detections), 32.5ms\n",
      "video 1/1 (5/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 (no detections), 23.0ms\n",
      "video 1/1 (6/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 (no detections), 26.0ms\n",
      "video 1/1 (7/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 (no detections), 26.0ms\n",
      "video 1/1 (8/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 (no detections), 26.5ms\n",
      "video 1/1 (9/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 (no detections), 18.0ms\n",
      "video 1/1 (10/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 (no detections), 21.0ms\n",
      "video 1/1 (11/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 (no detections), 10.0ms\n",
      "video 1/1 (12/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 (no detections), 10.0ms\n",
      "video 1/1 (13/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 (no detections), 11.0ms\n",
      "video 1/1 (14/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 (no detections), 10.0ms\n",
      "video 1/1 (15/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 (no detections), 10.0ms\n",
      "video 1/1 (16/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 (no detections), 8.0ms\n",
      "video 1/1 (17/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 (no detections), 8.0ms\n",
      "video 1/1 (18/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 (no detections), 8.0ms\n",
      "video 1/1 (19/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 (no detections), 9.0ms\n",
      "video 1/1 (20/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 (no detections), 12.0ms\n",
      "video 1/1 (21/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 1 cow, 9.0ms\n",
      "video 1/1 (22/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 1 cow, 14.0ms\n",
      "video 1/1 (23/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 1 cow, 14.0ms\n",
      "video 1/1 (24/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 1 cow, 15.0ms\n",
      "video 1/1 (25/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 (no detections), 9.0ms\n",
      "video 1/1 (26/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 (no detections), 8.0ms\n",
      "video 1/1 (27/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 (no detections), 10.0ms\n",
      "video 1/1 (28/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 (no detections), 11.0ms\n",
      "video 1/1 (29/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 (no detections), 10.0ms\n",
      "video 1/1 (30/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 (no detections), 10.0ms\n",
      "video 1/1 (31/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 (no detections), 10.0ms\n",
      "video 1/1 (32/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 (no detections), 10.0ms\n",
      "video 1/1 (33/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 (no detections), 10.0ms\n",
      "video 1/1 (34/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 (no detections), 16.0ms\n",
      "video 1/1 (35/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 (no detections), 10.0ms\n",
      "video 1/1 (36/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 (no detections), 11.0ms\n",
      "video 1/1 (37/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 1 cow, 10.0ms\n",
      "video 1/1 (38/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 1 cow, 11.0ms\n",
      "video 1/1 (39/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 1 cow, 9.0ms\n",
      "video 1/1 (40/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 1 cow, 10.0ms\n",
      "video 1/1 (41/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 (no detections), 15.0ms\n",
      "video 1/1 (42/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 (no detections), 16.7ms\n",
      "video 1/1 (43/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 (no detections), 28.8ms\n",
      "video 1/1 (44/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 (no detections), 24.0ms\n",
      "video 1/1 (45/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 (no detections), 17.0ms\n",
      "video 1/1 (46/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 (no detections), 9.0ms\n",
      "video 1/1 (47/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 (no detections), 11.0ms\n",
      "video 1/1 (48/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 (no detections), 8.0ms\n",
      "video 1/1 (49/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 (no detections), 9.0ms\n",
      "video 1/1 (50/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 (no detections), 10.0ms\n",
      "video 1/1 (51/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 (no detections), 16.3ms\n",
      "video 1/1 (52/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 (no detections), 12.0ms\n",
      "video 1/1 (53/5984) D:\\815_CowDataChecking\\uom\\2023-04-04\\09\\20230404-092500-092959.mp4: 640x384 (no detections), 12.0ms\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mruns/segment/train4/weights/best.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# load a custom model\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Predict with the model\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mD:\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43m815_CowDataChecking\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43muom\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43m2023-04-04\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43m09\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43m20230404-092500-092959.mp4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mretina_masks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mshow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# predict on an image\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;66;03m#print(result.boxes)\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     vid_path \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mpath\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\yolov8_v2\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py:111\u001b[0m, in \u001b[0;36mYOLO.__call__\u001b[1;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, source\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;124;03m\"\"\"Calls the 'predict' function with given arguments to perform object detection.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(source, stream, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\yolov8_v2\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\yolov8_v2\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py:252\u001b[0m, in \u001b[0;36mYOLO.predict\u001b[1;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# only update args if predictor is already setup\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m get_cfg(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39margs, overrides)\n\u001b[1;32m--> 252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\yolov8_v2\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py:157\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, source, model, stream)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\yolov8_v2\\lib\\site-packages\\torch\\autograd\\grad_mode.py:64\u001b[0m, in \u001b[0;36m_DecoratorContextManager._wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m             \u001b[38;5;66;03m# Pass the last request to the generator and get its response\u001b[39;00m\n\u001b[0;32m     63\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[1;32m---> 64\u001b[0m                 response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# We let the exceptions raised above by the generator's `.throw` or\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# `.send` methods bubble up to our caller, except for StopIteration\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# The generator informed us that it is done: take whatever its\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;66;03m# returned value (if any) was and indicate that we're done too\u001b[39;00m\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;66;03m# by returning it (see docs for python's return-statement).\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\yolov8_v2\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py:207\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindows, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdt, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, [], (ops\u001b[38;5;241m.\u001b[39mProfile(), ops\u001b[38;5;241m.\u001b[39mProfile(), ops\u001b[38;5;241m.\u001b[39mProfile()), \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_callbacks(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mon_predict_start\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 207\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_callbacks(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mon_predict_batch_start\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch \u001b[38;5;241m=\u001b[39m batch\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\yolov8_v2\\lib\\site-packages\\ultralytics\\yolo\\data\\dataloaders\\stream_loaders.py:235\u001b[0m, in \u001b[0;36mLoadImages.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvid_stride):\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcap\u001b[38;5;241m.\u001b[39mgrab()\n\u001b[1;32m--> 235\u001b[0m success, im0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m success:\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcount \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "import os\n",
    "# Set PYTORCH_CUDA_ALLOC_CONF environment variable\n",
    "#os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"0:15360\"\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "#import cv2\n",
    "#import glob\n",
    "#gc.collect()\n",
    "#torch.cuda.empty_cache()\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "from ultralytics.yolo.utils.plotting import Annotator\n",
    "\n",
    "\n",
    "# Load a model\n",
    "#model = YOLO('yolov8n-seg.pt')  # load an official models\n",
    "model = YOLO('runs/segment/train4/weights/best.pt')  # load a custom model\n",
    "\n",
    "# Predict with the model\n",
    "results = model('D:\\\\815_CowDataChecking\\\\uom\\\\2023-04-04\\\\09\\\\20230404-092500-092959.mp4',save=False,retina_masks=False,show=True,batch=1,imgsz=640,stream=False)  # predict on an image\n",
    "\n",
    "\n",
    "for result in results:\n",
    "    #print(result.boxes)\n",
    "    vid_path = result.path\n",
    "    filename = vid_path.split(\"\\\\\")[-1].replace(\".mkv\",\"\")\n",
    "    \n",
    "    \n",
    "    boxes = result.boxes.cpu().numpy()\n",
    "    ori_img = result.orig_img\n",
    "    annotator = Annotator(ori_img)\n",
    "    box_count = 0\n",
    "    cow_position = 1\n",
    "    \n",
    "    h,w = result.orig_shape\n",
    "    count = 1\n",
    "    b_boxes = []\n",
    "    masks = []\n",
    "    ids = []\n",
    "    has_cattle = False\n",
    "    if  result.masks != None:\n",
    "        \n",
    "        #result_masks = result.masks.cpu().numpy().masks.astype(bool)\n",
    "        for m in result.masks.cpu().numpy().masks.astype(bool):\n",
    "        #for i in range(1,len(result_masks)+1):\n",
    "        #for m in result.masks.masks.astype(bool):\n",
    "            xyxy = boxes[box_count].xyxy[0]\n",
    "        #   m = result_masks[-1]\n",
    "            #print(xyxy)\n",
    "            #print(m.shape)\n",
    "            box_count += 1\n",
    "            x1= int(xyxy[0])\n",
    "            y1= int(xyxy[1])\n",
    "            x2= int(xyxy[2])\n",
    "            y2= int(xyxy[3])\n",
    "\n",
    "          \n",
    "            #print(\"not skipped\")\n",
    "            #new_results.append(result)\n",
    "            box_left = x1\n",
    "            box_top = y1\n",
    "            box_w = x2 - x1\n",
    "            box_h = y2 - y1\n",
    "\n",
    "            new = np.zeros_like(ori_img, dtype=np.uint8)\n",
    "            new[m] = ori_img[m]\n",
    "            #masks.append(m)\n",
    "            \n",
    "           \n",
    "            crop = new[y1:y2, x1:x2]\n",
    "           \n",
    "\n",
    "           \n",
    "    #frame = annotator.result() \n",
    "    frame = cv2.resize(ori_img, (1080,1080), interpolation = cv2.INTER_AREA)\n",
    "    if has_cattle:\n",
    "        #ori_img = cv2.resize(ori_img,(1088,1088))\n",
    "        for i in range(len(b_boxes)):\n",
    "            box = b_boxes[i]\n",
    "            #mask = masks[i]\n",
    "            prev_id = 5\n",
    "            draw_bounding_box(ori_img,(box[0],box[1],box[2],box[3]),str(prev_id))\n",
    "            #ori_img = overlay(ori_img,mask,(0,0,255),0.3)\n",
    "        frame = cv2.resize(ori_img, (1080,1080), interpolation = cv2.INTER_AREA)\n",
    "        cap.write(frame)\n",
    "    \n",
    "    \n",
    "    cv2.imshow('YOLO V8 Detection', frame)     \n",
    "    if cv2.waitKey(1) & 0xFF == ord(' '):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4c942cd-755b-4a3b-907f-44eb3a9b1d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16abd98a-5a5c-4d05-b271-eedfed0315ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "import time\n",
    "\n",
    "X1=230 #same as NEW_BLACK_X1\n",
    "X2=410 #same as NEW_BLACK_X2 # incase of x2 out of bound\n",
    "Y1=94\n",
    "Y2=590\n",
    "SIZE =224\n",
    "Y1_NEW=125 #135  #decrease here to extend, increase to shrink \n",
    "Y2_NEW=490  #530  # redyce here to extend , increase to do vice casa 460 previous\n",
    "FRAME = 1\n",
    "\n",
    "default=640\n",
    "\n",
    "BATCH = 100\n",
    "BATCH_COUNT = 1\n",
    "PREV_BATCH = 0\n",
    "LAST_SEEN = time.time()\n",
    "FIRST_SEEN = True\n",
    "demo_img_save_path = []\n",
    "\n",
    "prevId_record =[]\n",
    "\n",
    "#end\n",
    "\n",
    "#region Cattle Tracking\n",
    "STORED_IDS= []\n",
    "STORED_MID_Y = []\n",
    "STORED_MID_Y1 = []\n",
    "STORED_MID_Y2 = []\n",
    "STORED_MISS = []\n",
    "PREVIOUS_ID = [] # keep the record of last seen ids and position\n",
    "PREVIOUS_Y1 = [] \n",
    "PREVIOUS_Y2 = [] \n",
    "PREVIOUS_LOCAL_IDS = []\n",
    "CATTLE_LOCAL_ID= 1\n",
    "IS_FIRST_CATTLE = True\n",
    "\n",
    "###### load dataset and model\n",
    "\n",
    "\n",
    "def check_withinROI_NEW(x1,y1,x2,y2,h,w):\n",
    "    #print(x1, '  ',y1, '  ',x2, '  ',y2, '  ',h, '  ',w)\n",
    "    if(x1<int(X1*(w/default)) or x2>int(X2*(w/default)) or y1<int(Y1_NEW*(h/default)) or y2>int(Y2_NEW*(h/default)) or x1>=int(X2*(w/default))):\n",
    "        return False\n",
    "    if(y2 - y1>1400 or y2-y1<400): #1400 to 700 Before\n",
    "        return False\n",
    "    return True  \n",
    "\n",
    "def check_withinROI_Resize(x1,y1,x2,y2,h,w):\n",
    "    #print(x1, '  ',y1, '  ',x2, '  ',y2, '  ',h, '  ',w)\n",
    "    resize_x1=850#*(w/2992)\n",
    "    resize_x2=1050#*(w/2992)\n",
    "    resize_y1=Y1_NEW#Y1_NEW*(w/2992)\n",
    "    resize_y2=Y1_NEW#Y2_NEW*(w/2992)\n",
    "    #print(resize_x1, '  ',resize_y1, '  ',resize_x2, '  ',resize_y2)\n",
    "    if(x1<int(resize_x1) or x2>int(resize_x2) or x1>=int(resize_x2)):\n",
    "        return False\n",
    "    if(y2 - y1>1400 or y2-y1<200): #1400 to 700 Before\n",
    "        return False\n",
    "    return True  \n",
    "\n",
    "\n",
    "################################################################################    \n",
    "\n",
    "def Is_Duplicate_Id(y1,y2,id):\n",
    "    global PREVIOUS_ID\n",
    "    global PREVIOUS_Y1\n",
    "    global PREVIOUS_Y2\n",
    "    global PREVIOUS_LOCAL_IDS\n",
    "    global CATTLE_LOCAL_ID\n",
    "    \n",
    "    try: \n",
    "        index = PREVIOUS_ID.index(id)\n",
    "        #print('I reached here')\n",
    "        if(PREVIOUS_Y1[index]+351<=y1 and PREVIOUS_Y2[index]+371<y2): #duplicate from bottom\n",
    "           \n",
    "            PREVIOUS_ID.append(CATTLE_LOCAL_ID)\n",
    "            PREVIOUS_Y1.append(y1)\n",
    "            PREVIOUS_Y2.append(y2)\n",
    "            #print('New Cattle Id')\n",
    "            return CATTLE_LOCAL_ID\n",
    "        \n",
    "        else:\n",
    "\n",
    "            PREVIOUS_Y1[index]=y1 #duplicate is solved or no duplicate and just need for last y \n",
    "            PREVIOUS_Y2[index]=y2\n",
    "            return PREVIOUS_ID[index]\n",
    "    except:\n",
    "        CATTLE_LOCAL_ID += 1\n",
    "        #print('except')\n",
    "        PREVIOUS_ID.append(CATTLE_LOCAL_ID)\n",
    "        PREVIOUS_Y1.append(y1)\n",
    "        PREVIOUS_Y2.append(y2)\n",
    "        return id\n",
    "        \n",
    "#def Take_Prev_Label(y2,id,cow_srno):\n",
    "def Take_Prev_Label(y,h,id,cow_srno):\n",
    "    global STORED_IDS\n",
    "    global STORED_MID_Y\n",
    "    global STORED_MID_Y1\n",
    "    global STORED_MID_Y2\n",
    "    global STORED_MISS\n",
    "    global LAST_SEEN_IDS\n",
    "    global LAST_SEEN_ID_CENTROIDS\n",
    "    global CATTLE_LOCAL_ID\n",
    "    global IS_FIRST_CATTLE \n",
    "    y1 , y2 = y , y+h\n",
    "    \n",
    "    if IS_FIRST_CATTLE:\n",
    "        IS_FIRST_CATTLE = False\n",
    "        id = CATTLE_LOCAL_ID\n",
    "    #mid_y = y2\n",
    "    mid_y = int(2*y + h)/2\n",
    "    IS_NEW = True\n",
    "    last_id = 999\n",
    "    last_y1 = 0\n",
    "    last_y2 = 0\n",
    "    if(len(STORED_IDS)>0): \n",
    "        last_id = STORED_IDS[len(STORED_IDS)-1]\n",
    "        last_y1 = STORED_MID_Y1[len(STORED_MID_Y1)-1]\n",
    "        last_y2 = STORED_MID_Y2[len(STORED_MID_Y2)-1]\n",
    "        MISSED_LEN = len(STORED_MISS)\n",
    "        #if(IS_NEW):\n",
    "        \n",
    "        #    MISSED_LEN -=1\n",
    "        removed = 0\n",
    "        for i in range(MISSED_LEN):\n",
    "            #print(i, ' missed index checking' )\n",
    "            missed = STORED_MISS[i-removed]\n",
    "            #print('checking ',i-removed, 'to remove')\n",
    "            if((missed>100 and len(STORED_MISS)>0) or int(last_id)-1>int(STORED_IDS[i-removed])): #if missed 35 frames\n",
    "    \n",
    "                del STORED_MISS[i-removed]  \n",
    "                del STORED_MID_Y[i-removed]\n",
    "                del STORED_MID_Y1[i-removed]\n",
    "                del STORED_MID_Y2[i-removed]\n",
    "                del STORED_IDS[i-removed]\n",
    "                removed+=1\n",
    "                #print('removed')\n",
    "                \n",
    "    #clear misses\n",
    "   \n",
    "    \n",
    "    threshold_1 = 250 #300\n",
    "    threshold_2 = 300  #230\n",
    "    Distance = 2000\n",
    "     \n",
    "    if mid_y <= 1300 or mid_y >= 700:\n",
    "        threshold_1 = 320 #350\n",
    "        threshold_2 = 370 #280\n",
    "    for i in range(1,len(STORED_MID_Y)+1):\n",
    "        #print(STORED_IDS[-i-1],STORED_MID_Y[-i-1],' ',i)\n",
    "        \n",
    "        \n",
    "        #if(STORED_MID_Y[-i]+threshold_2>=mid_y and STORED_MID_Y[-i]-threshold_1<=mid_y): # and IS_NEW): #previous 150 #200\n",
    "        if(STORED_MID_Y1[-i]-threshold_1<=y1 and STORED_MID_Y1[-i]+threshold_1-50>=y1) or (STORED_MID_Y2[-i]-threshold_2<=y2 and STORED_MID_Y2[-i]+threshold_2-50>=y2): # and IS_NEW): #previous 150 #200\n",
    "            if(IS_NEW):\n",
    "                #print('mid_y ',mid_y,'existing y ',STORED_MID_Y[-i])\n",
    "                #print('all mid_y ',STORED_MID_Y) \n",
    "                #print(\"Old\")\n",
    "                #print(\"STORED_MID_Y1\",STORED_MID_Y1[-1], \" and STORED_MID_Y2\", STORED_MID_Y2)\n",
    "                #print(\"Y!\",y1, \" and Y@\", y2)\n",
    "                \n",
    "                Distance = abs(STORED_MID_Y1[-i] - y1)\n",
    "                if(abs(STORED_MID_Y2[-i] - y2)<Distance):\n",
    "                    Distance = abs(STORED_MID_Y2[-i] - y2)\n",
    "                IS_NEW = False\n",
    "                STORED_MID_Y1[-i] = y1\n",
    "                STORED_MID_Y2[-i] = y2\n",
    "                \n",
    "                STORED_MISS[-i]=1\n",
    "                id= STORED_IDS[-i]\n",
    "                #print(Distance)\n",
    "                #print(id)\n",
    "                \n",
    "            #try:\n",
    "            #    exist_index = LAST_SEEN_IDS.index(id)\n",
    "            #    if(LAST_SEEN_ID_CENTROIDS[exist_index]+200>y): # showing old id\n",
    "            #        LAST_SEEN_ID_CENTROIDS[exist_index] = y\n",
    "            #except:\n",
    "            #print('corrected id :',STORED_IDS[-i])\n",
    "            elif Distance >60:\n",
    "                STORED_MISS[-i]+=1\n",
    "            else:\n",
    "                STORED_MISS[-i]= 15 #reset count to 2 when not moving\n",
    "        elif(STORED_MID_Y1[-i]<=y1 and STORED_MID_Y2[-i]>=y2):\n",
    "                STORED_MISS[-i]=5\n",
    "        else:\n",
    "            STORED_MISS[-i]+=1    \n",
    "            \n",
    "    if(IS_NEW):\n",
    "        #print('SMY: ',STORED_MID_Y,', new my:',mid_y) \n",
    "        #print('new id: ',id)\n",
    "        updatedID = Is_Duplicate_Id(y1,y2,id)\n",
    "        #CATTLE_LOCAL_ID+=1\n",
    "        #updatedID = CATTLE_LOCAL_ID\n",
    "        if(int(last_id) <int(updatedID) and y1<last_y1-150 and y2<last_y2-150): # duplicate cattle with increased cattleID\n",
    "            CATTLE_LOCAL_ID-=1\n",
    "            print(\"last_id\",last_id,\" updatedID \",updatedID)\n",
    "            for i in range(len(STORED_MID_Y)-1,0,-1):\n",
    "                STORED_MISS[i]=15\n",
    "            return -1\n",
    "        if(int(last_id)-1>int(updatedID) and last_id!=999):\n",
    "            return -1\n",
    "            \n",
    "    #if(updatedID!=id):\n",
    "    #    print('orgID: ',id,' updated ID: ',updatedID)\n",
    "        #id = str(updated_ID)+'_'+str(id)\n",
    "        \n",
    "        id=CATTLE_LOCAL_ID\n",
    "        STORED_IDS.append(id)\n",
    "        STORED_MID_Y.append(mid_y)\n",
    "        STORED_MID_Y1.append(y1)\n",
    "        STORED_MID_Y2.append(y2)\n",
    "        STORED_MISS.append(1)\n",
    "    \n",
    "    #print('returned id :',id)\n",
    "    \n",
    "    print(id)\n",
    "    \n",
    "    result = []\n",
    "    result.append(str(id-1))\n",
    "    \n",
    "    removed = 0\n",
    "    for i in range(len(STORED_MID_Y)-1,0,-1):\n",
    "        if(y1>STORED_MID_Y1[i] and y2>STORED_MID_Y2[i]):\n",
    "             del STORED_MISS[i-removed]  \n",
    "             del STORED_MID_Y[i-removed]\n",
    "             del STORED_MID_Y1[i-removed]\n",
    "             del STORED_MID_Y2[i-removed]\n",
    "             del STORED_IDS[i-removed]\n",
    "             removed+=1\n",
    "                 \n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def CALCULATE_MAX_CATTLE_ID(csv_path):\n",
    "    print(csv_path, \" is csv_path and \")\n",
    "\n",
    "    data = pd.read_csv(csv_path)\n",
    "\n",
    "    list_of_csv = [list(row) for row in data.values]\n",
    "\n",
    "    prev_id_record = [] \n",
    "    prev=None\n",
    "\n",
    "    current_cow = []\n",
    "    excel_cow_count = []\n",
    "    boxes = []\n",
    "    file_locations = []\n",
    "\n",
    "    for i in range (len(list_of_csv)):\n",
    "        filtered_id = list_of_csv[i][0]\n",
    "        actual_id = list_of_csv[i][1]\n",
    "        file_locations.append(list_of_csv[i][2])\n",
    "        boxes.append([list_of_csv[i][3],list_of_csv[i][4],list_of_csv[i][5],list_of_csv[i][6]])\n",
    "        try: \n",
    "            index = current_cow.index(actual_id)\n",
    "            excel_cow_count[index]+=1\n",
    "        except:\n",
    "            current_cow.append(actual_id)\n",
    "            excel_cow_count.append(1)\n",
    "\n",
    "    maxpos = excel_cow_count.index(max(excel_cow_count))\n",
    "    cattle_id = current_cow[maxpos]\n",
    "    return cattle_id,file_locations,boxes\n",
    "\n",
    "\n",
    "def writeVideo(filePath):\n",
    "    img_array = []\n",
    "    size = (302,1080)\n",
    "    names = ['cow']\n",
    "\n",
    "\n",
    "    vid_name = os.path.basename(os.path.normpath(filePath))\n",
    "    vid_path = str(Path(filePath + \"/\" + vid_name ).with_suffix('.mp4'))\n",
    "    id,img_locations,*xyxys = CALCULATE_MAX_CATTLE_ID(filePath+\"/\"+vid_name+\".csv\")\n",
    "    out = cv2.VideoWriter(vid_path,cv2.VideoWriter_fourcc(*'mp4v'), 6, size)\n",
    "    if len(img_locations)<10: \n",
    "        return -1\n",
    "\n",
    "    for ind in range(len(img_locations)):\n",
    "        img = cv2.imread(img_locations[ind])\n",
    "        annotator = Annotator(img, line_width=8, example=str(names))\n",
    "        try:\n",
    "            annotator.box_label(xyxys[0][ind],str(id), color=(15, 0, 255))\n",
    "            annotated_img =cv2.resize(annotator.result(),size) \n",
    "            out.write(annotated_img)\n",
    "        except:\n",
    "            continue\n",
    "    out.release()\n",
    "    img_array=[]\n",
    "    print(\"done \", vid_name)\n",
    "    cv2.destroyAllWindows()\n",
    "    return id\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e1d50a-b306-4766-a862-f0dbac99c59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics.yolo.utils.files import increment_path\n",
    "import torch\n",
    "import gc\n",
    "#from pathlib import Path\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "from ultralytics.yolo.utils.plotting import Annotator\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('runs/segment/train4/weights/best.pt')  # load a custom model\n",
    "\n",
    "# Predict with the model\n",
    "project = 'D:/Python/SULarbmon/Python/env/yolov8_june/ultralytics/runs/segment/uom'\n",
    "name = 'uom'\n",
    "results = model('D:\\\\815_CowDataChecking\\\\uom\\\\2023-04-04\\\\09\\\\20230404-092500-092959.mp4',imgsz=1088,save=False,retina_masks=False,show=False,stream=True,device = '0')\n",
    "save_dir = increment_path(Path(project) / name, exist_ok=True)  # increment run\n",
    "#save_dir = increment_path(Path(project) / name,mkdir=True)\n",
    "#(save_dir / 'labels' if False else save_dir).mkdir(parents=True, exist_ok=True)  # make dir\n",
    "manual_cow_count = 0\n",
    "\n",
    "#cap.set(4, 480)\n",
    "cap = cv2.VideoWriter(os.path.join(save_dir,'output.mkv'),cv2.VideoWriter_fourcc(*'mp4v'), 13, (1088,1088))\n",
    "\n",
    "for result in results:\n",
    "    print(\"here\")\n",
    "       \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be6244e-9022-4362-b4ed-be4fa72cad78",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ee745d-1e26-4f99-aeb7-a454fce0698c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_path = result.path\n",
    "    filename = vid_path.split(\"\\\\\")[-1].replace(\".mkv\",\"\")\n",
    "    \n",
    "    \n",
    "    boxes = result.boxes.cpu().numpy()\n",
    "    ori_img = cv2.resize(result.orig_img, (1088,1088), interpolation = cv2.INTER_AREA)\n",
    "    annotator = Annotator(ori_img)\n",
    "    box_count = 0\n",
    "    cow_position = 1\n",
    "    \n",
    "    h,w = result.orig_shape\n",
    "    if  result.masks != None:\n",
    "        \n",
    "        for m in result.masks.cpu().numpy().masks.astype(bool):\n",
    "        #for m in result.masks.masks.astype(bool):\n",
    "            xyxy = boxes[box_count].xyxy[0]\n",
    "            #print(xyxy)\n",
    "            #print(m.shape)\n",
    "            box_count += 1\n",
    "            x1= int(xyxy[0])\n",
    "            y1= int(xyxy[1])\n",
    "            x2= int(xyxy[2])\n",
    "            y2= int(xyxy[3])\n",
    "\n",
    "            ################## Validate  #####################\n",
    "            if(check_withinROI_NEW(x1,y1,x2,y2,h,w)==False):\n",
    "                continue\n",
    "            #print(\"not skipped\")\n",
    "            #new_results.append(result)\n",
    "            box_left = x1\n",
    "            box_top = y1\n",
    "            box_w = x2 - x1\n",
    "            box_h = y2 - y1\n",
    "\n",
    "            new = np.zeros_like(ori_img, dtype=np.uint8)\n",
    "            new[m] = ori_img[m]\n",
    "            \n",
    "            x1= int(x1 * (1088/2992))\n",
    "            x2= int(x2 * (1088/2992))\n",
    "            y1= int(y1 * (1088/2992))\n",
    "            y2= int(y2 * (1088/2992))\n",
    "\n",
    "            crop = new[y1:y2, x1:x2]\n",
    "            ###### LABEL\n",
    "            #label = predict_hog_svm(crop)\n",
    "            label = 1\n",
    "            prev_id = Take_Prev_Label(box_top,box_h,label,cow_position)\n",
    "          #########################################  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            HAS_COW=True\n",
    "\n",
    "            if(prev_id==-1): #skip cattle when prev_id // filter id is -1\n",
    "                if(count==1):\n",
    "                    has_seen_cattle=False\n",
    "                    count-=1\n",
    "                print('skipped')\n",
    "                continue\n",
    "            #print(prev_id)\n",
    "            cow_position+=1 \n",
    "            BATCH_COUNT = prev_id[0] # skip batch count here  \n",
    "            #BATCH calculator\n",
    "\n",
    "            ### annotate ######\n",
    "            b = xyxy  # get box coordinates in (top, left, bottom, right) format\n",
    "            #c = box.cls\n",
    "            annotator.box_label(b, str(prev_id[0]))\n",
    "\n",
    "            ###################### CREATE dir to save img\n",
    "            base_path = str(Path(save_dir / prev_id[0]))\n",
    "            if not os.path.exists(base_path):\n",
    "                os.makedirs(base_path)\n",
    "\n",
    "            LAST_SEEN = time.time()\n",
    "\n",
    "            FRAME+=1\n",
    "            #save each images for taking max label later\n",
    "            ######################################\n",
    "\n",
    "            demo_annotated_img_save_path = Path(base_path+ '/' + f'{filename}_{str(manual_cow_count).zfill(4)}.jpg')\n",
    "            try:\n",
    "                cv2.imwrite(str(demo_annotated_img_save_path), crop)\n",
    "                print(demo_annotated_img_save_path)\n",
    "            except:\n",
    "                print('cannot save ',demo_annotated_img_save_path)\n",
    "            #change cropped size here  #230 to 215 410 to 390\n",
    "\n",
    "            manual_cow_count += 1\n",
    "\n",
    "    frame = annotator.result()  \n",
    "    frame = cv2.resize(frame, (1080,1080), interpolation = cv2.INTER_AREA)\n",
    "    cap.write(frame)\n",
    "    cv2.imshow('YOLO V8 Detection', frame)     \n",
    "    if cv2.waitKey(1) & 0xFF == ord(' '):\n",
    "        break\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1c1ca9-0881-4794-89c9-b7aa42edd592",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
