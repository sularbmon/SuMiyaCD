{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5099ec81-b427-40ee-bd81-671d3f5b6941",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This ipynb is using Yolov5_VGG_SVM , taking first frame from the start\n",
    "#taking first frame and all frame to calculate the max show ups cattle id\n",
    "#No black box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d34cb07-e050-4e68-9f50-0d2513f48518",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1be2ec-4090-4ae5-befa-3569ea8c34bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### run here first\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import imutils\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import math\n",
    "from collections import deque\n",
    "import cv2\n",
    "\n",
    "import glob\n",
    "import cv2\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import tensorflow as tf \n",
    "import pandas as pd\n",
    "import nas_video_module as nas\n",
    "from re import match\n",
    "\n",
    "from models.common import DetectMultiBackend\n",
    "from utils.dataloaders import IMG_FORMATS, VID_FORMATS, LoadImages, LoadStreams\n",
    "from utils.general import (LOGGER, check_file, check_img_size, check_imshow, check_requirements, colorstr, cv2,\n",
    "                           increment_path, non_max_suppression, print_args, scale_coords, strip_optimizer, xyxy2xywh)\n",
    "from utils.plots import Annotator, colors, save_one_box\n",
    "from utils.torch_utils import select_device, time_sync\n",
    "\n",
    "from datetime import datetime\n",
    "from timer import Timer\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "#from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "#load model\n",
    "#vgg_filename='vgg16_nov_model.h5'\n",
    "#svm_filename ='svm_nov_model.pkl'\n",
    "#le_filename = 'label_encode.le'\n",
    "\n",
    "le_filename = 'May_Weights/GENERAL_LABEL_v1.le'\n",
    "\n",
    "\n",
    "vgg_filename ='May_Weights/GENERAL_VGG_v1.h5'\n",
    "\n",
    "\n",
    "\n",
    "knn_fileName ='May_Weights/VGG_SVM/all_cows_svm_v1.pkl'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "knn = pickle.load(open(knn_fileName, 'rb'))\n",
    "le = pickle.load(open(le_filename, 'rb'))\n",
    "vgg = tf.keras.models.load_model(vgg_filename, compile = False)\n",
    "\n",
    "##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adbac30-3eb1-404d-9a66-3bdad227eb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa44b89e-c027-4f1b-b9c7-32a0adcf9057",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7ceace-1f3e-4ad8-b87f-017884129b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict_SVM(image):  ## new with vgg\n",
    "    \n",
    "#Check results on a few select images\n",
    "    #n=np.random.randint(0, x_test.shape[0])\n",
    "    img = image\n",
    "\n",
    "    #plt.imshow(img)\n",
    "    input_img = np.expand_dims(img, axis=0) #Expand dims so the input is (num images, x, y, c)\n",
    "    input_img_feature=vgg.predict(input_img)\n",
    "    input_img_features=input_img_feature.reshape(input_img_feature.shape[0], -1)\n",
    "    prediction_RF = knn.predict(input_img_features)[0] \n",
    "    prediction_RF = le.inverse_transform([prediction_RF])  #Reverse the label encoder to original name\n",
    "    #label = [str(COW_MAPPER[int(prediction_RF)][0])]\n",
    "    #print(\"The prediction for this image is: \", prediction_RF)\n",
    "    #predict_proba= clf.predict_proba(input_img_features)\n",
    "    #print(predict_proba)\n",
    "    #print(\"max predict value is \"+str(predict_proba.max()) )\n",
    "    \n",
    "    #decision_svc= clf.predict_proba(input_img_features)\n",
    "    #probs_svc = (decision_svc - decision_svc.min()) / (decision_svc.max() - decision_svc.min())\n",
    "    #print(\"decision probability \"+str(probs_svc))\n",
    "    \n",
    "    return prediction_RF\n",
    "print(\"defined RF new VGG SVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9156b9-b51d-46bd-b3f5-a4a856c8d0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Is_Duplicate_Id(y1,y2,id):\n",
    "    global PREVIOUS_ID\n",
    "    global PREVIOUS_Y1\n",
    "    global PREVIOUS_Y2\n",
    "    global PREVIOUS_LOCAL_IDS\n",
    "    global CATTLE_LOCAL_ID\n",
    "    \n",
    "    try: \n",
    "        index = PREVIOUS_ID.index(id)\n",
    "        #print('I reached here')\n",
    "        if(PREVIOUS_Y1[index]+351<=y1 and PREVIOUS_Y2[index]+371<y2): #duplicate from bottom\n",
    "            #if(id in PREVIOUS_LOCAL_IDS):\n",
    "            #print('id: ',id,' LOCAL_ID: ',CATTLE_LOCAL_ID)\n",
    "            #return PREVIOUS_LOCAL_IDS[id][0]\n",
    "            \n",
    "            #print('This is not gonna happen again')\n",
    "            #PREVIOUS_LOCAL_IDS.append([id,LOCAL_ID])\n",
    "            #PREVIOUS_Y[index]=\n",
    "            #print('PREVIOUS ID')\n",
    "            #CATTLE_LOCAL_ID +=1\n",
    "            #CATTLE_LOCAL_ID += 1\n",
    "            \n",
    "            #print('except')\n",
    "            PREVIOUS_ID.append(CATTLE_LOCAL_ID)\n",
    "            PREVIOUS_Y1.append(y1)\n",
    "            PREVIOUS_Y2.append(y2)\n",
    "            #print('New Cattle Id')\n",
    "            return CATTLE_LOCAL_ID\n",
    "        #elif(PREVIOUS_Y[index]+400<center): #stepping back\n",
    "        #    if(id in PREVIOUS_LOCAL_IDS):\n",
    "        #        return PREVIOUS_LOCAL_IDS[id][0]\n",
    "        else:\n",
    "            #print('Oh. here ? really?')\n",
    "            PREVIOUS_Y1[index]=y1 #duplicate is solved or no duplicate and just need for last y \n",
    "            PREVIOUS_Y2[index]=y2\n",
    "            #return PREVIOUS_LOCAL_IDS[index][1]\n",
    "            \n",
    "            #update('PREVIOUS Y')\n",
    "            return PREVIOUS_ID[index]\n",
    "    except:\n",
    "        #print(PREVIOUS_ID)\n",
    "        #print(id)\n",
    "        CATTLE_LOCAL_ID += 1\n",
    "        #print('except')\n",
    "        PREVIOUS_ID.append(CATTLE_LOCAL_ID)\n",
    "        PREVIOUS_Y1.append(y1)\n",
    "        PREVIOUS_Y2.append(y2)\n",
    "        return id\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7080613c-3de4-4517-93a0-f0d51cc64ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def Take_Prev_Label(y2,id,cow_srno):\n",
    "def Take_Prev_Label(y,h,id,cow_srno):\n",
    "    global STORED_IDS\n",
    "    global STORED_MID_Y\n",
    "    global STORED_MID_Y1\n",
    "    global STORED_MID_Y2\n",
    "    global STORED_MISS\n",
    "    global LAST_SEEN_IDS\n",
    "    global LAST_SEEN_ID_CENTROIDS\n",
    "    global CATTLE_LOCAL_ID\n",
    "    global IS_FIRST_CATTLE \n",
    "    y1 , y2 = y , y+h\n",
    "    \n",
    "    if IS_FIRST_CATTLE:\n",
    "        IS_FIRST_CATTLE = False\n",
    "        id = CATTLE_LOCAL_ID\n",
    "    #mid_y = y2\n",
    "    mid_y = int(2*y + h)/2\n",
    "    IS_NEW = True\n",
    "    last_id = 999\n",
    "    last_y1 = 0\n",
    "    last_y2 = 0\n",
    "    if(len(STORED_IDS)>0): \n",
    "        last_id = STORED_IDS[len(STORED_IDS)-1]\n",
    "        last_y1 = STORED_MID_Y1[len(STORED_MID_Y1)-1]\n",
    "        last_y2 = STORED_MID_Y2[len(STORED_MID_Y2)-1]\n",
    "        MISSED_LEN = len(STORED_MISS)\n",
    "        #if(IS_NEW):\n",
    "        \n",
    "        #    MISSED_LEN -=1\n",
    "        removed = 0\n",
    "        for i in range(MISSED_LEN):\n",
    "            #print(i, ' missed index checking' )\n",
    "            missed = STORED_MISS[i-removed]\n",
    "            #print('checking ',i-removed, 'to remove')\n",
    "            if((missed>100 and len(STORED_MISS)>0) or int(last_id)-1>int(STORED_IDS[i-removed])): #if missed 35 frames\n",
    "    \n",
    "                del STORED_MISS[i-removed]  \n",
    "                del STORED_MID_Y[i-removed]\n",
    "                del STORED_MID_Y1[i-removed]\n",
    "                del STORED_MID_Y2[i-removed]\n",
    "                del STORED_IDS[i-removed]\n",
    "                removed+=1\n",
    "                #print('removed')\n",
    "                \n",
    "    #clear misses\n",
    "   \n",
    "    \n",
    "    threshold_1 = 250 #300\n",
    "    threshold_2 = 300  #230\n",
    "    Distance = 2000\n",
    "     \n",
    "    if mid_y <= 1300 or mid_y >= 700:\n",
    "        threshold_1 = 320 #350\n",
    "        threshold_2 = 370 #280\n",
    "    for i in range(1,len(STORED_MID_Y)+1):\n",
    "        #print(STORED_IDS[-i-1],STORED_MID_Y[-i-1],' ',i)\n",
    "        \n",
    "        \n",
    "        #if(STORED_MID_Y[-i]+threshold_2>=mid_y and STORED_MID_Y[-i]-threshold_1<=mid_y): # and IS_NEW): #previous 150 #200\n",
    "        if(STORED_MID_Y1[-i]-threshold_1<=y1 and STORED_MID_Y1[-i]+threshold_1-50>=y1) or (STORED_MID_Y2[-i]-threshold_2<=y2 and STORED_MID_Y2[-i]+threshold_2-50>=y2): # and IS_NEW): #previous 150 #200\n",
    "            if(IS_NEW):\n",
    "                #print('mid_y ',mid_y,'existing y ',STORED_MID_Y[-i])\n",
    "                #print('all mid_y ',STORED_MID_Y) \n",
    "                #print(\"Old\")\n",
    "                #print(\"STORED_MID_Y1\",STORED_MID_Y1[-1], \" and STORED_MID_Y2\", STORED_MID_Y2)\n",
    "                #print(\"Y!\",y1, \" and Y@\", y2)\n",
    "                \n",
    "                Distance = abs(STORED_MID_Y1[-i] - y1)\n",
    "                if(abs(STORED_MID_Y2[-i] - y2)<Distance):\n",
    "                    Distance = abs(STORED_MID_Y2[-i] - y2)\n",
    "                IS_NEW = False\n",
    "                STORED_MID_Y1[-i] = y1\n",
    "                STORED_MID_Y2[-i] = y2\n",
    "                \n",
    "                STORED_MISS[-i]=1\n",
    "                id= STORED_IDS[-i]\n",
    "                #print(Distance)\n",
    "                #print(id)\n",
    "                \n",
    "            #try:\n",
    "            #    exist_index = LAST_SEEN_IDS.index(id)\n",
    "            #    if(LAST_SEEN_ID_CENTROIDS[exist_index]+200>y): # showing old id\n",
    "            #        LAST_SEEN_ID_CENTROIDS[exist_index] = y\n",
    "            #except:\n",
    "            #print('corrected id :',STORED_IDS[-i])\n",
    "            elif Distance >60:\n",
    "                STORED_MISS[-i]+=1\n",
    "            else:\n",
    "                STORED_MISS[-i]= 15 #reset count to 2 when not moving\n",
    "        elif(STORED_MID_Y1[-i]<=y1 and STORED_MID_Y2[-i]>=y2):\n",
    "                STORED_MISS[-i]=5\n",
    "        else:\n",
    "            STORED_MISS[-i]+=1    \n",
    "                \n",
    "        #elif(cow_srno==1):\n",
    "                \n",
    "    #print(STORED_IDS,' IDS ',STORED_MID_Y,' SMY ',mid_y,' mid_y')\n",
    "    if(IS_NEW):\n",
    "        #print('SMY: ',STORED_MID_Y,', new my:',mid_y) \n",
    "        #print('new id: ',id)\n",
    "        updatedID = Is_Duplicate_Id(y1,y2,id)\n",
    "        #CATTLE_LOCAL_ID+=1\n",
    "        #updatedID = CATTLE_LOCAL_ID\n",
    "        if(int(last_id) <int(updatedID) and y1<last_y1-150 and y2<last_y2-150): # duplicate cattle with increased cattleID\n",
    "            CATTLE_LOCAL_ID-=1\n",
    "            print(\"last_id\",last_id,\" updatedID \",updatedID)\n",
    "            for i in range(len(STORED_MID_Y)-1,0,-1):\n",
    "                STORED_MISS[i]=15\n",
    "            return -1\n",
    "        if(int(last_id)-1>int(updatedID)):\n",
    "            return -1\n",
    "            \n",
    "    #if(updatedID!=id):\n",
    "    #    print('orgID: ',id,' updated ID: ',updatedID)\n",
    "        #id = str(updated_ID)+'_'+str(id)\n",
    "        \n",
    "        id=CATTLE_LOCAL_ID\n",
    "        STORED_IDS.append(id)\n",
    "        STORED_MID_Y.append(mid_y)\n",
    "        STORED_MID_Y1.append(y1)\n",
    "        STORED_MID_Y2.append(y2)\n",
    "        STORED_MISS.append(1)\n",
    "    \n",
    "    #print('returned id :',id)\n",
    "    \n",
    "    print(id)\n",
    "    \n",
    "    result = []\n",
    "    result.append(str(id-1))\n",
    "    \n",
    "    #region remove stored id\n",
    "    removed = 0\n",
    "    for i in range(len(STORED_MID_Y)-1,0,-1):\n",
    "        if(y1>STORED_MID_Y1[i] and y2>STORED_MID_Y2[i]):\n",
    "             del STORED_MISS[i-removed]  \n",
    "             del STORED_MID_Y[i-removed]\n",
    "             del STORED_MID_Y1[i-removed]\n",
    "             del STORED_MID_Y2[i-removed]\n",
    "             del STORED_IDS[i-removed]\n",
    "             removed+=1\n",
    "                 \n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04e79fa-89b0-4a18-9748-07c69e56ff30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_most_cattle_id():\n",
    "    global current_cow\n",
    "    global excel_cow_count\n",
    "    global final_result\n",
    "    global fial_total\n",
    "    global final_percentage\n",
    "    global prev_id_record\n",
    "    maxpos = excel_cow_count.index(max(excel_cow_count))\n",
    "    #or i in range (len(current_cow)):\n",
    "    #   print('cattle ',current_cow[i],' id is ',excel_cow_count[i] , ' count(s)')\n",
    "    cattle_id = current_cow[maxpos]\n",
    "    \n",
    "    final_total.append(sum(excel_cow_count))\n",
    "    final_percentage.append(max(excel_cow_count)/sum(excel_cow_count))\n",
    "    final_result.append(cattle_id)\n",
    "    excel_cow_count = [] #reset\n",
    "    current_cow = [] #reset\n",
    "    \n",
    "\n",
    "def Generate_Cattle_Id_By_Apperance(csv_path,save_dir):\n",
    "    print(csv_path, \" is csv_path and \", save_dir , \" is save_dir\")\n",
    "\n",
    "    data = pd.read_csv(csv_path)\n",
    "\n",
    "    list_of_csv = [list(row) for row in data.values]\n",
    "    global  final_result \n",
    "    global final_percentage\n",
    "    global final_total\n",
    "    global current_cow\n",
    "    global excel_cow_count\n",
    "    prev_id_record = [] \n",
    "    prev=None\n",
    "\n",
    "\n",
    "\n",
    "    for i in range (len(list_of_csv)):\n",
    "        #rint('from ',list_of_csv[i][1],' to ',list_of_csv[i][0])\n",
    "        filtered_id = list_of_csv[i][0]\n",
    "        actual_id = list_of_csv[i][1]\n",
    "        if(prev!=filtered_id):\n",
    "            if(prev is not None):\n",
    "                calculate_most_cattle_id()\n",
    "                prev_id_record.append(prev)\n",
    "            prev = filtered_id\n",
    "\n",
    "        try: \n",
    "            index = current_cow.index(actual_id)\n",
    "            #print('I reached here')\n",
    "            excel_cow_count[index]+=1\n",
    "        except:\n",
    "            current_cow.append(actual_id)\n",
    "            excel_cow_count.append(1)\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(final_result, columns = [\"ID\"])\n",
    "    try:\n",
    "        final_percentage = torch.tensor(final_percentage, device = 'cpu')\n",
    "        final_total = torch.tensor(final_total, device = 'cpu')\n",
    "        final_prev = torch.tensor(prev_id_record, device = 'cpu')\n",
    "\n",
    "        df[\"total\"] = final_total\n",
    "        df[\"percentage\"] = final_percentage\n",
    "        df[\"prev_id\"]=prev_id_record\n",
    "    except:\n",
    "        df[\"total\"] = final_total\n",
    "        df[\"percentage\"] = final_percentage\n",
    "        df[\"prev_id\"]=prev_id_record\n",
    "    now=str(datetime.now().date())\n",
    "\n",
    "    df.to_csv(save_dir+\"/MaxCattleId_new \"+now+'.csv', index= False)\n",
    "    print(\"successfully saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5011f957-3149-4535-b4bb-460e932cf619",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#csv_path = \"D:\\\\Python\\\\SULarbmon\\\\Python\\\\env\\\\yolov5\\\\runs\\\\detect_SVM_NV_demo_center\\\\exp_3_fps79\\\\1\\\\3849\\\\3849.csv\"\n",
    "def CALCULATE_MAX_CATTLE_ID(csv_path):\n",
    "    print(csv_path, \" is csv_path and \")\n",
    "\n",
    "    data = pd.read_csv(csv_path)\n",
    "\n",
    "    list_of_csv = [list(row) for row in data.values]\n",
    "    \n",
    "    prev_id_record = [] \n",
    "    prev=None\n",
    "\n",
    "    current_cow = []\n",
    "    excel_cow_count = []\n",
    "    boxes = []\n",
    "    file_locations = []\n",
    "\n",
    "    for i in range (len(list_of_csv)):\n",
    "        #rint('from ',list_of_csv[i][1],' to ',list_of_csv[i][0])\n",
    "        filtered_id = list_of_csv[i][0]\n",
    "        actual_id = list_of_csv[i][1]\n",
    "        file_locations.append(list_of_csv[i][2])\n",
    "        boxes.append([list_of_csv[i][3],list_of_csv[i][4],list_of_csv[i][5],list_of_csv[i][6]])\n",
    "        #print(list_of_csv[i][2])\n",
    "        try: \n",
    "            index = current_cow.index(actual_id)\n",
    "            #print('I reached here')\n",
    "            excel_cow_count[index]+=1\n",
    "        except:\n",
    "            current_cow.append(actual_id)\n",
    "            excel_cow_count.append(1)\n",
    "    \n",
    "    maxpos = excel_cow_count.index(max(excel_cow_count))\n",
    "    #or i in range (len(current_cow)):\n",
    "    #   print('cattle ',current_cow[i],' id is ',excel_cow_count[i] , ' count(s)')\n",
    "    cattle_id = current_cow[maxpos]\n",
    "    #print(cattle_id)\n",
    "    #print(current_cow)\n",
    "    #print(excel_cow_count)\n",
    "    return cattle_id,file_locations,boxes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd12945-b965-4d40-8e06-e9937c88eaeb",
   "metadata": {},
   "source": [
    "final_result = []\n",
    "final_percentage = []\n",
    "final_total = []\n",
    "current_cow = []\n",
    "excel_cow_count=[]\n",
    "\n",
    "Generate_Cattle_Id_By_Apperance(\"G:\\\\ToCCA\\\\exp_3_fps47\\\\detected_cow_vggSVM_2022-11-20.csv\",\"G:\\\\ToCCA\\\\exp_3_fps47\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29b96bd-1eda-436f-b806-3fcc1f4dda91",
   "metadata": {},
   "outputs": [],
   "source": [
    "default = \"D:\\\\Python\\\\SULarbmon\\\\Python\\\\env\\\\yolov5\\\\runs\\\\detect_SVM_NV_demo_center\\\\exp_3_fps481\\\\9\\\\9\"\n",
    "def writeVideo(filePath):\n",
    "    img_array = []\n",
    "    size = (302,1080)\n",
    "    names = ['cow']\n",
    "    \n",
    "    \n",
    "    vid_name = os.path.basename(os.path.normpath(filePath))\n",
    "    vid_path = str(Path(filePath + \"/\" + vid_name ).with_suffix('.mp4'))\n",
    "    id,img_locations,*xyxys = CALCULATE_MAX_CATTLE_ID(filePath+\"/\"+vid_name+\".csv\")\n",
    "    #print(xyxys)\n",
    "    \n",
    "    out = cv2.VideoWriter(vid_path,cv2.VideoWriter_fourcc(*'mp4v'), 6, size)\n",
    "    if len(img_locations)<10: #skip if less than 6 photos\n",
    "        return -1\n",
    "    \n",
    "    for ind in range(len(img_locations)):\n",
    "        #x,y,w,h = cv2.boundingRect(contour)\n",
    "        #x1,y1,x2,y2 = xyxys[0][ind][1], xyxys[ind][1], xyxys[ind][2], xyxys[ind][3]\n",
    "        #print(x1,y1,x2,y2)\n",
    "        #cv2.rectangle(image, (x, y), (x + w, y + h), (36,255,12), 1)\n",
    "        #image = cv2.rectangle(img_array[ind],(x1,y1),(x2,y2) , (36,255,12),1)\n",
    "        #cv2.putText(image, str(id), (xyxys[0][0], xyxys[ind][1]-3), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n",
    "        #print(xyxys[0][ind])\n",
    "        \n",
    "        \n",
    "        img = cv2.imread(img_locations[ind])\n",
    "        annotator = Annotator(img, line_width=8, example=str(names))\n",
    "        #print('ind', ind)\n",
    "        #print(xyxys[0][ind])\n",
    "        try:\n",
    "            annotator.box_label(xyxys[0][ind],str(id), color=(15, 0, 255))\n",
    "            annotated_img =cv2.resize(annotator.result(),size) \n",
    "            #cv2.imshow('new cow',img)\n",
    "            #if cv2.waitKey(1) == ord('a'):  # q to quit\n",
    "            #    raise StopIteration\n",
    "            out.write(annotated_img)\n",
    "        except:\n",
    "            continue\n",
    "    out.release()\n",
    "    img_array=[]\n",
    "    print(\"done \", vid_name)\n",
    "    cv2.destroyAllWindows()\n",
    "    return id\n",
    "#writeVideo(default)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa4bb81-65fc-4aa4-a41e-08a2f48ad939",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%%python --source \"D:\\Python\\env\\Lameness\\Frames\\Videos\\20220201_145508_7108.mp4\"  --yolo-weights weights_slm/best_6_23_gpu.pt --view-img --save-crop --device 0\n",
    "\n",
    "\n",
    "# YOLOv5 🚀 by Ultralytics, GPL-3.0 license\n",
    "\"\"\"\n",
    "Run inference on images, videos, directories, streams, etc.\n",
    "\n",
    "Usage - sources:\n",
    "    $ python path/to/detect.py --weights yolov5s.pt --source 0              # webcam\n",
    "                                                             img.jpg        # image\n",
    "                                                             vid.mp4        # video\n",
    "                                                             path/          # directory\n",
    "                                                             path/*.jpg     # glob\n",
    "                                                             'https://youtu.be/Zgi9g1ksQHc'  # YouTube\n",
    "                                                             'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream\n",
    "\n",
    "Usage - formats:\n",
    "    $ python path/to/detect.py --weights yolov5s.pt                 # PyTorch\n",
    "                                         yolov5s.torchscript        # TorchScript\n",
    "                                         yolov5s.onnx               # ONNX Runtime or OpenCV DNN with --dnn\n",
    "                                         yolov5s.xml                # OpenVINO\n",
    "                                         yolov5s.engine             # TensorRT\n",
    "                                         yolov5s.mlmodel            # CoreML (macOS-only)\n",
    "                                         yolov5s_saved_model        # TensorFlow SavedModel\n",
    "                                         yolov5s.pb                 # TensorFlow GraphDef\n",
    "                                         yolov5s.tflite             # TensorFlow Lite\n",
    "                                         yolov5s_edgetpu.tflite     # TensorFlow Edge TPU\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "FILE = Path(\"__file__\").resolve()\n",
    "ROOT = FILE.parents[0]  # YOLOv5 root directory\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))  # add ROOT to PATH\n",
    "ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative\n",
    "\n",
    "X1=240\n",
    "X2=400\n",
    "Y1=94\n",
    "Y2=590\n",
    "SIZE =224\n",
    "\n",
    "\n",
    "\n",
    "default=640\n",
    "save_video=True\n",
    "\n",
    "#file_location=\"D:\\\\815_CowDataChecking\\\\20221228\\\\20221228_E\\\\\"#20221228_055019_5DDC.mkv\"\n",
    "file_location=\"D:\\\\815_CowDataChecking\\\\20221229\\\\20221229_M_cow\"#\\\\20221228_055019_5DDC.mkv\" #\\\\20221228_055019_5DDC.mkv\"#20221230_155051_3DBF.mkv\"#20221228_055019_5DDC.mkv\"\n",
    "\n",
    "SKIP_VIDEOS=False # True False toggle here to have skip videos\n",
    "NUMBER_SKIP_VIDEOS = 5\n",
    "#file_location = \"\\\\172.16.4.111\\\\Public\\訓子府L5G_2020\\\\生データ_original_data\\\\360カメラ\\\\A\\\\20221115\\\\13\\\\20221115_135954_9B55_ACCC8EEE85E1\\\\20221115_15\\\\20221115_151030_8349.mkv\"\n",
    "\n",
    "\n",
    "#file_location=\"D:\\\\815_CowDataChecking\\\\20220906\\\\360\\A\\\\20220906\\\\13\\\\20220906_135955_2249_ACCC8EEE85E1\\\\20220906_16\\\\20220906_161102_E42D.mkv\"\n",
    "#file_location = \"C:\\\\Users\\\\thithilab\\\\Desktop\\\\Cow Data (22~28)\\\\20220722\\\\all\\\\20220722_152539_53E5.mkv\"\n",
    "#filename=\"20220705_135955_4D30\"\n",
    "#file_path = \"D:\\\\815_CowDataChecking\\\\20220704\\\\13\\\\20220704_135955_D85D_ACCC8EEE85E1\\\\20220704_E_All\\\\\"\n",
    "#deep_test ='C:/Users/thithilab/Desktop/20220705/m_videos_5_7/DEEP1/DEEP2'\n",
    "#multifile = 'D:/CheckFrame/14B8/20220704_145523_14B8.mkv,C:/Users/thithilab/Desktop/20220705/m_videos_5_7/20220705_053512_A9B0.mkv'\n",
    "#Y1_NEW=110\n",
    "#Y2_NEW=530\n",
    "Y1_NEW=110 #135  #decrease here to extend, increase to shrink \n",
    "Y2_NEW=500  #530  # redyce here to extend , increase to do vice casa 460 previous\n",
    "\n",
    "Y1_PRECISE=100\n",
    "Y2_PRECISE=400  #where cow is most precise  August 7 2022\n",
    "HAS_COW=False  # to save video when has cow\n",
    "\n",
    "cow_order=[]\n",
    "cow_count = []\n",
    "cow_label=[]\n",
    "frame_rate=3\n",
    "has_seen_cattle = False \n",
    "prev_label_store=[None] * 5\n",
    "prev_cow_position=[None] * 5\n",
    "\n",
    "\n",
    "all_detected_cow=[]\n",
    "\n",
    "local_id=1\n",
    "\n",
    "\n",
    "#for max apperance cattle id \n",
    "final_result = []\n",
    "final_percentage = []\n",
    "final_total = []\n",
    "current_cow = []\n",
    "excel_cow_count=[]\n",
    "#end\n",
    "\n",
    "#demo video write\n",
    "BATCH = 100\n",
    "BATCH_COUNT = 1\n",
    "PREV_BATCH = 0\n",
    "LAST_SEEN = time.time()\n",
    "FIRST_SEEN = True\n",
    "demo_img_save_path = []\n",
    "\n",
    "prevId_record =[]\n",
    "MAX_prevId = [] \n",
    "MAX_xyxy1 = [] \n",
    "MAX_xyxy2 = [] \n",
    "MAX_xyxy3 = [] \n",
    "MAX_xyxy4 = [] \n",
    "MAX_orgId = []\n",
    "IMAGE_STORED_LOCATION = []\n",
    "#end\n",
    "\n",
    "#region Cattle Tracking\n",
    "STORED_IDS= []\n",
    "STORED_MID_Y = []\n",
    "STORED_MID_Y1 = []\n",
    "STORED_MID_Y2 = []\n",
    "STORED_MISS = []\n",
    "PREVIOUS_ID = [] # keep the record of last seen ids and position\n",
    "PREVIOUS_Y1 = [] \n",
    "PREVIOUS_Y2 = [] \n",
    "PREVIOUS_LOCAL_IDS = []\n",
    "CATTLE_LOCAL_ID= 0\n",
    "IS_FIRST_CATTLE = True\n",
    "#end\n",
    "NEW_BLACK_X1= 230\n",
    "NEW_BLACK_X2= 410\n",
    "\n",
    "\n",
    "\n",
    "def DoROI(image):\n",
    "    h,w,c = image.shape\n",
    "    img_arr = np.array(image)\n",
    "    img_arr[0 : int(94*(h/default)), 0 : h] = (0, 0, 0)   #top\n",
    "    img_arr[0 : h, 0 : int(240*(w/default))] = (0, 0, 0)   #left\n",
    "    img_arr[0 : h, int(400*(w/default)) : w] = (0, 0, 0)   #right\n",
    "    img_arr[int(590*(h/default)) : h,0 : w] = (0, 0, 0)   #bottom\n",
    "    return img_arr\n",
    "\n",
    "def Demo_DoROI(image):\n",
    "    h,w,c = image.shape\n",
    "    img_arr = np.array(image)\n",
    "    #img_arr[0 : int(94*(h/default)), 0 : h] = (0, 0, 0)   #top\n",
    "    img_arr[0 : h, 0 : int(239*(w/default))] = (0, 0, 0)   #left\n",
    "    img_arr[0 : h, int(410*(w/default)) : w] = (0, 0, 0)   #right\n",
    "    #img_arr[int(590*(h/default)) : h,0 : w] = (0, 0, 0)   #bottom\n",
    "    return img_arr\n",
    "\n",
    "\n",
    "def DoROI_640(image):\n",
    "    img_arr = np.array(image)\n",
    "    img_arr[0 : 94, 0 : 640] = (0, 0, 0)   #top\n",
    "    img_arr[0 : 640, 0 : 240] = (0, 0, 0)   #left\n",
    "    img_arr[0 : 640, 400 : 640] = (0, 0, 0)   #right\n",
    "    img_arr[590 : 640,0 : 640] = (0, 0, 0)   #bottom\n",
    "    return img_arr\n",
    "  \n",
    "def check_withinROI(x1,y1,x2,y2,h,w):\n",
    "    if(x1<int(X1*(w/default)) or x2>int(X2*(w/default)) or y1<int(Y1*(h/default)) or y2>int(Y2*(h/default)) or x1>=int(X2*(w/default))):\n",
    "      return False\n",
    "    return True  \n",
    "\n",
    "def check_withinROI_NEW(x1,y1,x2,y2,h,w):\n",
    "    if(x1<int(X1*(w/default)) or x2>int(X2*(w/default)) or y1<int(Y1_NEW*(h/default)) or y2>int(Y2_NEW*(h/default)) or x1>=int(X2*(w/default))):\n",
    "        return False\n",
    "    if(y2 - y1>1400 or y2-y1<800): #1400 to 700 Before\n",
    "        return False\n",
    "    return True  \n",
    "\n",
    "def check_withinROI_PRECISE(x1,y1,x2,y2,h,w):\n",
    "    if(x1<int(X1*(w/default)) or x2>int(X2*(w/default)) or y1<int(Y1_PRECISE*(h/default)) or y2>int(Y2_PRECISE*(h/default)) or x1>=int(X2*(w/default))):\n",
    "      return False\n",
    "    return True  \n",
    "\n",
    "def check_cow_Count(label):\n",
    "    global cow_label\n",
    "    global cow_count\n",
    "    print(\"inserting label\")\n",
    "    if label in cow_label: #check exist\n",
    "        cow_count[cow_label.index(label)]+=1  #start counting of the newly inserted cow\n",
    "        \n",
    "    else:\n",
    "        cow_label.append(label)  # if not exist then add the cow label to array\n",
    "        cow_count.append(1)  #start counting of the newly inserted cow\n",
    "\n",
    "\n",
    "def determine_label(img):\n",
    "    \n",
    "    #if Isolation_Forest(img) != 1:\n",
    "    #    res = ['unknown']\n",
    "    #    check_cow_Count(res[0])\n",
    "    #    return res\n",
    "    global all_detected_cow\n",
    "    label = LCNN_GNB_CLASSIFIER(img)\n",
    "    HAS_COW=True\n",
    "    check_cow_Count(label[0])\n",
    "    all_detected_cow.append(label[0])\n",
    "    return label\n",
    "\n",
    "#label for cow label, y for y2 postion of cow, h for total height if image, position for 1st cow of the frame, 2nd cow of the frame etc,...\n",
    "def take_first_appear_lable(label,y,h,nth_cows):\n",
    "    \n",
    "    global prev_label_store\n",
    "    global prev_cow_position\n",
    "    \n",
    "\n",
    "    #prev_label_length = len(prev_label_store)\n",
    "    #prev_position_length = len(prev_label_store)\n",
    "    #print(prev_label_length)\n",
    "    \n",
    "    #first\n",
    "    print(\"cow position :\"+str(nth_cows))\n",
    "    print(\"label \"+label)\n",
    "    if(prev_label_store[nth_cows]==None and prev_label_store[nth_cows+1]==None):\n",
    "        prev_label_store[nth_cows]=label\n",
    "        prev_cow_position[nth_cows]=y\n",
    "        res = [label]\n",
    "        return res\n",
    "        \n",
    "    if(prev_label_store[nth_cows]!=None):\n",
    "        if(y<prev_cow_position[nth_cows]+35) : #check if prev_cow\n",
    "            prev_cow_position[nth_cows]=y\n",
    "            res = [prev_label_store[nth_cows] ]\n",
    "            return res\n",
    "        elif(prev_cow_position[nth_cows+1]!=None and y<prev_cow_position[nth_cows+1]+35) : #check if prev_cow second cow \n",
    "            #2nd one become 1st cow\n",
    "            prev_cow_position[nth_cows]=None\n",
    "            prev_label_store[nth_cows]=None\n",
    "            \n",
    "            prev_label_store = deque(prev_label_store)\n",
    "            prev_label_store(1)\n",
    "            prev_label_store = list(prev_label_store)\n",
    "            \n",
    "            \n",
    "            prev_cow_position = deque(prev_cow_position)\n",
    "            prev_cow_position(1)\n",
    "            prev_cow_position = list(prev_cow_position)\n",
    "            \n",
    "            \n",
    "            prev_cow_position[nth_cows]=y\n",
    "            res = [prev_label_store[nth_cows]]\n",
    "            return res  #move 2nd index to first index\n",
    "        elif(prev_cow_position[nth_cows+1] == None) : #new cows in first place\n",
    "            prev_cow_position[nth_cows]=y\n",
    "            prev_label_store[nth_cows] = label\n",
    "            res = [label]\n",
    "            return res\n",
    "           \n",
    "    res = [label]\n",
    "    return res\n",
    "    \n",
    "    \n",
    "    \n",
    "prev_labels=[]  #keep last records to compare y pixel value    \n",
    "prev_y1s=[]    \n",
    "\n",
    "\n",
    "def compare_with_prev_cow(label,y,h):\n",
    "    prev_labels.append(label)\n",
    "    prev_y1s.append(y)\n",
    "    has_100_record = len(prev_labels)\n",
    "    start = 0\n",
    "    end = 0\n",
    "    ceiling = h-int(h*(Y1_NEW/default))\n",
    "    #print(ceiling )\n",
    "    #print(h)\n",
    "    #print(y)\n",
    "    if(y+100>=ceiling) :   #checking if the image reach the top\n",
    "        if has_100_record>=20:\n",
    "            start=has_100_record - 20 - 1 #only check last 20 values\n",
    "            end = has_100_record - 1\n",
    "        cow_count_c=[]\n",
    "        cow_label_c=[]\n",
    "        prev_y_value=y\n",
    "        total_frames=0\n",
    "        global cow_order\n",
    "        for i in range(end,start,-1):\n",
    "            if(prev_y1s[i]>=h/2 +50 ):  #check only for half of screen\n",
    "                #for l in range(len(label[i].split(',')):\n",
    "                #split_label = label[i].split(',')[l]\n",
    "                #if split_label in cow_label: #check exist\n",
    "                if(prev_y1s[i]>prev_y_value):\n",
    "                    prev_y_value=prev_y1s[i] #go with 30 pixel different\n",
    "                    total_frames += 1\n",
    "                    if prev_labels[i] in cow_label_c:\n",
    "                        cow_count_c[cow_label_c.index(prev_labels[i])]+=1  #start counting of the newly inserted cow\n",
    "        \n",
    "                    else:\n",
    "                        cow_label_c.append(prev_labels[i])  # if not exist then add the cow label to array\n",
    "                        cow_count_c.append(1)  #start counting of the newly inserted cow\n",
    "                #else:\n",
    "                    \n",
    "                \n",
    "        #prediction_RF = np.argmax(prop)         \n",
    "        #get max cow id\n",
    "        if(len(cow_count_c)<1):\n",
    "            return None\n",
    "        max_count = max(cow_count_c)\n",
    "        threshold_50_percent = math.floor(total_frames*0.5)\n",
    "        if(max_count>threshold_50_percent + 1):\n",
    "            index = np.argmax(cow_count_c)\n",
    "            cow_order.append(cow_label_c[index])\n",
    "            #print(\" cow label \"+str(cow_label_c[index]))\n",
    "            return cow_label_c[index]\n",
    "        else:\n",
    "            #print(\" cow label unknown\")\n",
    "            cow_order.append(\"unknown\")\n",
    "            return \"unknown\"\n",
    "    \n",
    "    if(len(prev_y1s) >700): # delete first 500 when greater than 800\n",
    "        del prev_labels[:500]\n",
    "        del prev_y1s[:500]    \n",
    "         \n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def run(\n",
    "        #weights=ROOT / 'Sept_no_alien_weight_v1/best.pt',  # model.pt path(s)  #july_weight\n",
    "        #weights=ROOT / 'September_bounding_flip_800/best.pt',\n",
    "        #weights=ROOT / 'weights/Dec_new_v1/best.pt', \n",
    "        #apirl_weights/v1_bright_dar_noise/best.pt\n",
    "        weights=ROOT / 'apirl_weights/v1_bright_dar_noise/best.pt',#'paper_weights/epochs_200_weights/best.pt',  #v3\n",
    "        source=ROOT / file_location,  #file_location,  # file/dir/URL/glob, 0 for webcam\n",
    "        data=ROOT / 'data/coco128.yaml',  # dataset.yaml path\n",
    "        imgsz=(640, 640),  # inference size (height, width)\n",
    "        conf_thres=0.1,  # confidence threshold\n",
    "        iou_thres=0.001,  #NS IOU threshold\n",
    "        max_det=1000,  # maximum detections per image\n",
    "        device='0',  # cuda device, i.e. 0 or 0,1,2,3 or cpu\n",
    "        view_img=True,  # show results\n",
    "        save_txt=False,  # save results to *.txt\n",
    "        save_conf=False,  # save confidences in --save-txt labels\n",
    "        save_crop=True,  # save cropped prediction boxes\n",
    "        nosave=False,  # do not save images/videos\n",
    "        classes=None,  # filter by class: --class 0, or --class 0 2 3 #None\n",
    "        agnostic_nms=False,  # class-agnostic NMS\n",
    "        augment=False,  # augmented inference\n",
    "        visualize=False,  # visualize features\n",
    "        update=False,  # update all models\n",
    "        project=ROOT / 'runs/paper/may/vgg_SVM',  # save results to project/name\n",
    "        name='exp_'+str(frame_rate)+'_fps',  # save results to project/name\n",
    "        exist_ok=False,  # existing project/name ok, do not increment\n",
    "        line_thickness=8,  # bounding box thickness (pixels)\n",
    "        hide_labels=False,  # hide labels\n",
    "        hide_conf=False,  # hide confidences\n",
    "        half=True,  # use FP16 half-precision inference #True\n",
    "        dnn=False,  # use OpenCV DNN for ONNX inference\n",
    "    \n",
    "):\n",
    "    \n",
    "    global all_detected_cow\n",
    "    global frame_rate\n",
    "    #added\n",
    "    sec=0\n",
    "    global cow_lable\n",
    "    global cow_count\n",
    "    global cow_order\n",
    "    global FIRST_SEEN\n",
    "    global BATCH\n",
    "    global BATCH_COUNT\n",
    "    global PREV_BATCH\n",
    "    global LAST_SEEN\n",
    "    global demo_img_save_path\n",
    "    global has_seen_cattle\n",
    "    \n",
    "    global NEW_BLACK_X1\n",
    "    global NEW_BLACK_X2\n",
    "    cow_id = []\n",
    "    cow_id_original =[]\n",
    "    cow_top = []\n",
    "    cow_left = []\n",
    "    cow_width = []\n",
    "    cow_height = []\n",
    "    cow_score = []\n",
    "    cow_frame = []\n",
    "    \n",
    "    manual_summarize_ids = []\n",
    "    manual_local_ids = []\n",
    "    manual_id = 1\n",
    "    \n",
    "    read_after_frame = 1\n",
    "    manual_cow_count = 1\n",
    "    \n",
    "    global prevId_record\n",
    "    global MAX_prevId\n",
    "    global MAX_xyxy1\n",
    "    global MAX_xyxy2\n",
    "    global MAX_xyxy3\n",
    "    global MAX_xyxy4\n",
    "    global MAX_orgId\n",
    "\n",
    "    global SKIP_VIDEOS\n",
    "    global NUMBER_SKIP_VIDEOS\n",
    "    \n",
    "    global IMAGE_STORED_LOCATION\n",
    "    \n",
    "    cf = 0  \n",
    "    count=0\n",
    "    \n",
    "    source = str(source)\n",
    "    #vid_path = []\n",
    "    #vid_path.append(\"D:\\\\CheckFrame\\\\14B8\")\n",
    "    #vid_path.append(source)\n",
    "    #source = vid_path\n",
    "    #save_img = not nosave and not source.endswith('.txt')  # save inference images\n",
    "    #added\n",
    "    save_img=True\n",
    "    \n",
    "    is_file = Path(source).suffix[1:] in (IMG_FORMATS + VID_FORMATS)\n",
    "    is_url = source.lower().startswith(('rtsp://', 'rtmp://', 'http://', 'https://'))\n",
    "    webcam = source.isnumeric() or source.endswith('.txt') or (is_url and not is_file)\n",
    "    if is_url and is_file:\n",
    "        source = check_file(source)  # download\n",
    "\n",
    "    # Directories\n",
    "    save_dir = increment_path(Path(project) / name, exist_ok=exist_ok)  # increment run\n",
    "    #print(save_dir)\n",
    "    csv_save_dir = str(save_dir)\n",
    "    #print(csv_save_dir)\n",
    "    (save_dir / 'labels' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # make dir\n",
    "\n",
    "    \n",
    "    \n",
    "    # Load model\n",
    "    device = select_device(device)\n",
    "    model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=half)\n",
    "    stride, names, pt = model.stride, model.names, model.pt\n",
    "    #print(names)\n",
    "    imgsz = check_img_size(imgsz, s=stride)  # check image size\n",
    "\n",
    "    # Dataloader\n",
    "    if webcam and False:\n",
    "        view_img = check_imshow()\n",
    "        cudnn.benchmark = True  # set True to speed up constant image size inference\n",
    "        dataset = LoadStreams(source, img_size=imgsz, stride=stride, auto=pt)\n",
    "        bs = len(dataset)  # batch_size\n",
    "    else:\n",
    "        dataset = LoadImages(source, img_size=imgsz, stride=stride, auto=pt)\n",
    "        bs = 1  # batch_size\n",
    "    vid_path, vid_writer = [None] * bs, [None] * bs\n",
    "    \n",
    "    demo_vid_path ,demo_vid_writer = [] ,[None]  * 12\n",
    "    \n",
    "    demo_vid_save_path = str(save_dir)\n",
    "\n",
    "    # Run inference\n",
    "    model.warmup(imgsz=(1 if pt else bs, 3, *imgsz))  # warmup\n",
    "    dt, seen = [0.0, 0.0, 0.0], 0\n",
    "    #frame_rate = 4    #frame rate here\n",
    "    prev = 0\n",
    "    prev_frame = 0\n",
    "    current_vid_name = ''\n",
    "    #print(classes)\n",
    "    SKIPPING = False\n",
    "    SKIPPED_COUNT = 0\n",
    "    for path, im, im0s, vid_cap, s in dataset:\n",
    "        if SKIP_VIDEOS :\n",
    "            if current_vid_name!=path :  # check if moring\n",
    "                SKIPPED_COUNT +=1\n",
    "                current_vid_name = path\n",
    "                #print('skipped ', SKIPPED_COUNT, ' video(s)')\n",
    "            if SKIPPED_COUNT <= NUMBER_SKIP_VIDEOS :\n",
    "\n",
    "                continue\n",
    "        #cv2.waitKey(1000) #1 fps   1000/ value =fps\n",
    "        #vidcap.set(cv2.CAP_PROP_POS_MSEC,sec*1000) \n",
    "        #vid_cap.set(cv2.CV_CAP_PROP_FPS, 1)\n",
    "        #vid_cap.set(cv2.CAP_PROP_FPS, 1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        HAS_COW=False\n",
    "        t1 = time_sync()\n",
    "        im = torch.from_numpy(im).to(device)\n",
    "        im = im.half() if model.fp16 else im.float()  # uint8 to fp16/32\n",
    "        im /= 255  # 0 - 255 to 0.0 - 1.0\n",
    "        if len(im.shape) == 3:\n",
    "            im = im[None]  # expand for batch dim\n",
    "        t2 = time_sync()\n",
    "        dt[0] += t2 - t1\n",
    "        \n",
    "        # Inference\n",
    "        visualize = increment_path(save_dir / Path(path).stem, mkdir=True) if visualize else False\n",
    "        pred = model(im, augment=augment, visualize=visualize)\n",
    "        t3 = time_sync()\n",
    "        dt[1] += t3 - t2\n",
    "\n",
    "        # NMS\n",
    "        pred = non_max_suppression(pred, conf_thres, iou_thres, classes, agnostic_nms, max_det=max_det)\n",
    "        dt[2] += time_sync() - t3\n",
    "        \n",
    "        # Second-stage classifier (optional)\n",
    "        # pred = utils.general.apply_classifier(pred, classifier_model, im, im0s)\n",
    "\n",
    "        # Process predictions\n",
    "        #time_elapsed = time.time() - prev\n",
    "    \n",
    "\n",
    "        #if time_elapsed > 1/frame_rate:\n",
    "            #prev = time.time()\n",
    "            #print(\"Greater\")\n",
    "            #print(prev)\n",
    "        #else:\n",
    "            #print(\"break\")\n",
    "            #\n",
    "        \n",
    "        if (read_after_frame - prev_frame == 0 and not has_seen_cattle):\n",
    "            prev_frame=0\n",
    "            continue\n",
    "        prev_frame +=1\n",
    "        for i, det in enumerate(pred):  # per image\n",
    "           \n",
    "            #det = det.sort(key=lambda row: (row[1]))\n",
    "            #print(time_elapsed)\n",
    "            \n",
    "            seen += 1\n",
    "            if webcam:  # batch_size >= 1\n",
    "                p, im0, frame = path[i], im0s[i].copy(), dataset.count\n",
    "                s += f'{i}: '\n",
    "            else:\n",
    "                p, im0, frame = path, im0s.copy(), getattr(dataset, 'frame', 0)\n",
    "            \n",
    "            #added ROI    \n",
    "            #h,w,c=im0.shape\n",
    "            \n",
    "            #resize\n",
    "            #if(w>640 or h>640):\n",
    "            #  im0=imutils.resize(im0, width = 640)\n",
    "            \n",
    "            \n",
    "            \n",
    "            #check containing frame here\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            #end of checking containing frame\n",
    "            \n",
    "            \n",
    "\n",
    "            #ROI\n",
    "            im0=Demo_DoROI(im0)\n",
    "            h,w,c=im0.shape\n",
    "            #400 to 390\n",
    "            cropped_img = im0.copy()[0 : h,int(NEW_BLACK_X1*(w/default)):int(NEW_BLACK_X2*(w/default))]\n",
    "            \n",
    "            p = Path(p)  # to Path\n",
    "            save_path = str(save_dir / p.name)  # im.jpg\n",
    "            txt_path = str(save_dir / 'labels' / p.stem) + ('' if dataset.mode == 'image' else f'_{frame}')  # im.txt\n",
    "            s += '%gx%g ' % im.shape[2:]  # print string\n",
    "            gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh\n",
    "            imc = im0.copy() if save_crop else im0  # for save_crop\n",
    "            \n",
    "            annotator = Annotator(im0, line_width=line_thickness, example=str(names))\n",
    "            if len(det):\n",
    "                # Rescale boxes from img_size to im0 size\n",
    "                det[:, :4] = scale_coords(im.shape[2:], det[:, :4], im0.shape).round()\n",
    "                #det.sort(key=lambda row: (row[1][0]))\n",
    "                #print(det)\n",
    "                det, b = torch.sort(det, dim=0)\n",
    "                #print('sorted',det)\n",
    "                # Print results\n",
    "                for c in det[:, -1].unique():\n",
    "                    n = (det[:, -1] == c).sum()  # detections per class\n",
    "                    s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \"  # add to string\n",
    "                \n",
    "                \n",
    "                \n",
    "                # Write results\n",
    "                cow_position = 0\n",
    "                counter = 0\n",
    "                has_seen_cattle = False\n",
    "                for *xyxy, conf , cls in (det):#reversed(det):\n",
    "                    if(check_withinROI_NEW(xyxy[0],xyxy[1],xyxy[2],xyxy[3],h,w)):\n",
    "                      #print(cls)\n",
    "                      count+=1\n",
    "                      has_seen_cattle = True\n",
    "                        \n",
    "                      \n",
    "                      box_left = xyxy[0]\n",
    "                      box_top = xyxy[1]\n",
    "                      box_w = xyxy[2] - xyxy[0]\n",
    "                      box_h = xyxy[3] - xyxy[1]\n",
    "                      \n",
    "                      #cow_left.append(box_left)\n",
    "                      #cow_top.append(box_top)\n",
    "                      #cow_width.append(box_w)\n",
    "                      #cow_height.append(box_h)\n",
    "                      #cow_score.append(conf)\n",
    "                      #cow_frame.append(seen)\n",
    "                     \n",
    "                      #feed on cnn and get label\n",
    "                      #save_one_box(xyxy, imc, file=save_dir / 'crops' / names[c] / f'{p.stem}_{count}.jpg', BGR=True)\n",
    "                      \n",
    "                      #crop\n",
    "                      BGR=False\n",
    "                      #print(\"step-3-y\")\n",
    "                      crop = im0[int(xyxy[1]):int(xyxy[3]), int(xyxy[0]):int(xyxy[2])]\n",
    "                      #frame_crop = im0[0 : h,int(200*(w/default)):int(540*(w/default))] \n",
    "                      \n",
    "\n",
    "                      #cropped = torch.tensor(crop, device = 'cpu')\n",
    "                      #image = Image.fromarray(crop)\n",
    "                      #img = image.resize((128, 128), Image.ANTIALIAS)\n",
    "                      \n",
    "                    \n",
    "                      #do some process like testing data in cnn\n",
    "                      img = cv2.resize(crop, (SIZE, SIZE))\n",
    "                      #img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "                      #cv2.imshow('detected cow',img)\n",
    "                      if cv2.waitKey(1) == ord('a'):  # q to quit\n",
    "                          raise StopIteration\n",
    "                      #crop=imutils.resize(crop, width = 224)\n",
    "                      img=img / 255.0\n",
    "                      label = Predict_SVM(img)\n",
    "                      #label = determine_label(img)\n",
    "                      #isknown = isKnownCattle(img) #for unknown\n",
    "                      #print(isknown)\n",
    "                      HAS_COW=True\n",
    "                      #prev_id = Take_Prev_Label(int(xyxy[3]),label,cow_position)\n",
    "                      prev_id = Take_Prev_Label(box_top,box_h,label,cow_position)\n",
    "                      if(prev_id==-1): #skip cattle when prev_id // filter id is -1\n",
    "                          if(count==1):\n",
    "                            has_seen_cattle=False\n",
    "                          count-=1\n",
    "                          continue\n",
    "                      print(prev_id)\n",
    "                      cow_position+=1\n",
    "                      #label = Predict_SVM_test_pro(img)\n",
    "                      cow_id.append(prev_id[0])\n",
    "                      cow_id_original.append(int(label[0]))\n",
    "                      #check cow count here\n",
    "                      h,w,c=im0.shape  \n",
    "                      BATCH_COUNT = prev_id[0] # skip batch count here  \n",
    "                      #BATCH calculator\n",
    "                      if(FIRST_SEEN):\n",
    "                        LAST_SEEN = time.time() #first seen time\n",
    "                        FIRST_SEEN=False\n",
    "                \n",
    "                      if(time.time()-LAST_SEEN>=300): # 3 mins different\n",
    "                        #write excel for each cattle\n",
    "                        # print(len(prevId_record), ' previd_record', prevId_record)\n",
    "                        for csv_index in range(len(prevId_record)):\n",
    "                            df = pd.DataFrame(MAX_prevId[csv_index], columns = ['ID'])\n",
    "                            try:\n",
    "                                org_ids = torch.tensor(MAX_orgId[csv_index], device = 'cpu')\n",
    "                                df[\"Original\"] = org_ids\n",
    "                            except:\n",
    "                                 df[\"Original\"] = MAX_orgId[csv_index]\n",
    "                                    \n",
    "                                    \n",
    "                            try:\n",
    "                                stored_locations = torch.tensor(IMAGE_STORED_LOCATION[csv_index],device = 'cpu')\n",
    "                                df[\"location\"] = stored_locations\n",
    "                            except:\n",
    "                                df[\"location\"]=IMAGE_STORED_LOCATION[csv_index]\n",
    "                                \n",
    "                            df[\"xyxy1\"] = MAX_xyxy1[csv_index]\n",
    "                            df[\"xyxy2\"] = MAX_xyxy2[csv_index]\n",
    "                            df[\"xyxy3\"] = MAX_xyxy3[csv_index]\n",
    "                            df[\"xyxy4\"] = MAX_xyxy4[csv_index]\n",
    "                            \n",
    "                            \n",
    "\n",
    "                            now=str(datetime.now().date())\n",
    "                            \n",
    "                            save_csv_each_path = str(Path(save_dir / str(prevId_record[csv_index]) / str(prevId_record[csv_index]) / f'{str(prevId_record[csv_index])}.csv'))\n",
    "                            #print(save_csv_each_path)\n",
    "                            \n",
    "                            df.to_csv(save_csv_each_path, index= False) ##\n",
    "                            MAX_xyxy1[csv_index]=[]\n",
    "                            MAX_xyxy2[csv_index]=[]\n",
    "                            MAX_xyxy3[csv_index]=[]\n",
    "                            MAX_xyxy4[csv_index]=[]\n",
    "                            MAX_orgId[csv_index]=[]\n",
    "                            MAX_prevId[csv_index]=[]\n",
    "                            IMAGE_STORED_LOCATION[csv_index]=[]\n",
    "                            \n",
    "                        #print(\"new batch\")\n",
    "                        prevId_record = []\n",
    "                        MAX_prevId = []\n",
    "                        MAX_xyxy1 = [] \n",
    "                        MAX_xyxy2 = [] \n",
    "                        MAX_xyxy3 = [] \n",
    "                        MAX_xyxy4 = [] \n",
    "                        MAX_orgId = [] \n",
    "                        IMAGE_STORED_LOCATION = []\n",
    "                  \n",
    "                        \n",
    "                        cattle_ids = []\n",
    "                        #print(len(det))\n",
    "                        \n",
    "                  \n",
    "                        #release video write and reset vid_path\n",
    "                        \n",
    "                        #for index in range(len(demo_vid_path)):\n",
    "                            \n",
    "                        #    if isinstance(demo_vid_writer[index], cv2.VideoWriter):\n",
    "                        #        demo_vid_writer[index].release()  # release previous video writer\n",
    "                        #        print('removed video write ', demo_vid_path[index])\n",
    "                        \n",
    "                        #demo_vid_path = []\n",
    "                        #demo_img_save_path = []\n",
    "                        #end\n",
    "                        \n",
    "                      LAST_SEEN = time.time()\n",
    "                      \n",
    "                      #final_label = compare_with_prev_cow(label[0],int(xyxy[3]),h)\n",
    "                      #label = take_first_appear_lable(label[0],int(xyxy[3]),h,cow_position) #remove\n",
    "                      #print(im0.shape)\n",
    "                      #if(isknown[0] == -1): #open when doing unknonw\n",
    "                      #  label = ['unknown']\n",
    "                      #print(label)\n",
    "                      #if final_label != None: print(\"final label \"+ final_label) \n",
    "                      annotator.box_label(xyxy,prev_id[0], color=(15, 0, 255))#color=colors(c, True))  # change back to prev_id \n",
    "                      #if save_txt:  # Write to file\n",
    "                      #    xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh\n",
    "                      #    line = (cls, *xywh, conf) if save_conf else (cls, *xywh)  # label format\n",
    "                      #    with open(f'{txt_path}.txt', 'a') as f:\n",
    "                      #        f.write(('%g ' * len(line)).rstrip() % line + '\\n')\n",
    "\n",
    "                      #if save_img or save_crop or view_img:  # Add bbox to image\n",
    "                      #    c = int(cls)  # integer class\n",
    "                      #    #label = None if hide_labels else (names[c] if hide_conf else f'{names[c]} {conf:.2f}')  #original\n",
    "                      #    annotator.box_label(xyxy, label, color=colors(c, True))\n",
    "                      \n",
    "                      if save_crop:\n",
    "                           save_one_box(xyxy, imc, file=save_dir /  str(BATCH_COUNT)  / prev_id[0]  / 'cropped' / f'{p.stem}.jpg', BGR=True)\n",
    "                      # change by cattle id here\n",
    "                      #demo_vid_index= 0\n",
    "                      #demo_path = str(Path(str(save_dir)+\"/\"+str(BATCH_COUNT)+\"/\"+prev_id[0]).with_suffix('.mp4'))\n",
    "                      \n",
    "                      #save_one_box(xyxy, im0, file=save_dir / str(BATCH_COUNT) / prev_id[0]  / 'cropped' / f'{p.stem}.jpg', BGR=True)\n",
    "                      #annotated_img = annotator.result()\n",
    "                      \n",
    "                      #fps, fw, fh = 6, annotated_img.shape[1], annotated_img.shape[0] \n",
    "                      #print('width ',fw,' height ',fh)\n",
    "                      base_path = str(Path(save_dir / str(BATCH_COUNT) / prev_id[0]))\n",
    "                      demo_annotated_img_save_path = Path(base_path+ '/' + f'{p.stem}_{str(manual_cow_count).zfill(4)}.jpg')\n",
    "                      #print(demo_annotated_img_save_path)\n",
    "                      #save_one_box(xyxy, imc, file = base_path / prev_id[0]  / f'{p.stem}.jpg', BGR=True)\n",
    "                      cv2.imwrite(demo_annotated_img_save_path, cropped_img)\n",
    "                      #change cropped size here  #230 to 215 410 to 390\n",
    "                      no_tensor_xyxy =[int(xyxy[0]*NEW_BLACK_X1/(2*default)),int(xyxy[1]),int(xyxy[2]*NEW_BLACK_X2/(2*default)),int(xyxy[3])] #to get the crop size\n",
    "                      #print(no_tensor_xyxy)\n",
    "                      try:\n",
    "                        index_prevId = prevId_record.index(int(prev_id[0]))\n",
    "                        #print(index_prevId)\n",
    "                        MAX_prevId[index_prevId].append(int(prev_id[0]))#,int(label[0]),xyxy)\n",
    "                        MAX_xyxy1[index_prevId].append(int(no_tensor_xyxy[0]))\n",
    "                        MAX_xyxy2[index_prevId].append(int(no_tensor_xyxy[1]))\n",
    "                        MAX_xyxy3[index_prevId].append(int(no_tensor_xyxy[2]))\n",
    "                        MAX_xyxy4[index_prevId].append(int(no_tensor_xyxy[3]))\n",
    "                        MAX_orgId[index_prevId].append(int(label[0]))\n",
    "                        \n",
    "                        IMAGE_STORED_LOCATION[index_prevId].append(demo_annotated_img_save_path)\n",
    "                        \n",
    "                      except :\n",
    "                        prevId_record.append(int(prev_id[0]))\n",
    "                        # print(len(prevId_record)-1, 'prevID_record ', len(MAX_prevId) , 'max_previd' )\n",
    "\n",
    "                        #MAX_prevId[len(prevId_record)-1].append(int(prev_id[0]))#,int(label[0]),xyxy)\n",
    "                        #MAX_xyxy[len(MAX_prevId)-1].append(xyxy)\n",
    "                        #MAX_orgId[len(MAX_prevId)-1].append(int(label[0]))\n",
    "                        MAX_prevId.append([int(prev_id[0])])#,int(label[0]),xyxy)\n",
    "                        \n",
    "                        MAX_xyxy1.append([int(no_tensor_xyxy[0])])\n",
    "                        MAX_xyxy2.append([int(no_tensor_xyxy[1])])\n",
    "                        MAX_xyxy3.append([int(no_tensor_xyxy[2])])\n",
    "                        MAX_xyxy4.append([int(no_tensor_xyxy[3])])\n",
    "                        MAX_orgId.append([int(label[0])])\n",
    "                        IMAGE_STORED_LOCATION.append([demo_annotated_img_save_path])\n",
    "                    \n",
    "                      try:\n",
    "                        #demo_vid_index = demo_vid_path.index(demo_path)\n",
    "                        demo_vid_index = demo_img_save_path.index(base_path)\n",
    "                        \n",
    "                        #print(\"path exist\")\n",
    "                      except:\n",
    "                        manual_summarize_ids.append(int(prev_id[0]))\n",
    "                        manual_local_ids.append(manual_id)\n",
    "                        manual_id +=1\n",
    "                        \n",
    "                        \n",
    "                        #demo_vid_path.append(demo_path)\n",
    "                        #print(base_path)\n",
    "                        #print('vid path is new ')\n",
    "                        demo_img_save_path.append(base_path)\n",
    "                        #demo_vid_index = len(demo_vid_path) -1\n",
    "                        #demo_vid_writer[demo_vid_index]=(cv2.VideoWriter(demo_vid_path[demo_vid_index], cv2.VideoWriter_fourcc(*'mp4v'),6, (fw, fh)))\n",
    "                        \n",
    "                     \n",
    "                      write_demo_vide=False\n",
    "                      if write_demo_vide :  \n",
    "                        \n",
    "                        \n",
    "                        #print('vid index is ', demo_vid_index, ' location is ', demo_vid_path[demo_vid_index])\n",
    "                        #print(annotated_img.shape)\n",
    "                        if isinstance(demo_vid_writer[demo_vid_index], cv2.VideoWriter):\n",
    "                            demo_vid_writer[demo_vid_index].write(annotated_img)\n",
    "                      \n",
    "                      manual_cow_count +=1\n",
    "\n",
    "\n",
    "            # Stream results\n",
    "            im0 = cv2.resize(annotator.result(), (1080, 1080))\n",
    "            if view_img and False:\n",
    "                \n",
    "                if(w>1080 or h>1080):\n",
    "                    cv2.imshow('detected cows', imutils.resize(im0, width = 1080,height=720))\n",
    "                else:\n",
    "                    cv2.imshow('detected cows',im0)\n",
    "                if cv2.waitKey(1) == ord('a'):  # q to quit\n",
    "                    raise StopIteration\n",
    "\n",
    "            # Save results (image with detections)\n",
    "            if (save_img or save_video) and HAS_COW:\n",
    "                if dataset.mode == 'image':\n",
    "                    cv2.imwrite(save_path, im0)\n",
    "                else :  # 'video' or 'stream'\n",
    "                    if vid_path[i] != save_path:  # new video\n",
    "                        vid_path[i] = save_path\n",
    "                        if isinstance(vid_writer[i], cv2.VideoWriter):\n",
    "                            vid_writer[i].release()  # release previous video writer\n",
    "                        if vid_cap:  # video\n",
    "                            fps = vid_cap.get(cv2.CAP_PROP_FPS)\n",
    "                            w = 1080#int(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "                            h = 1080#int(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "                            #fps=frame_rate * 2\n",
    "                        else:  # stream\n",
    "                            fps, w, h = 30, im0.shape[1], im0.shape[0]\n",
    "                            #fps=frame_rate\n",
    "                        save_path = str(Path(save_path).with_suffix('.mp4'))  # force *.mp4 suffix on results videos\n",
    "                        all_detected_cow.append('xxxxxxxxxxxxx')\n",
    "                        all_detected_cow.append('xxxxxxxxxxxxx')\n",
    "                        all_detected_cow.append(save_path)\n",
    "                        \n",
    "                        vid_writer[i] = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))\n",
    "                    vid_writer[i].write(im0)\n",
    "\n",
    "        # Print time (inference-only)\n",
    "        LOGGER.info(f'{s}Done. ({t3 - t2:.3f}s)')\n",
    "    cv2.destroyAllWindows()  \n",
    "    \n",
    "    #region release remaining video write\n",
    "    \n",
    "    #for index in range(len(demo_vid_path)):\n",
    "                        \n",
    "    #    if isinstance(demo_vid_writer[index], cv2.VideoWriter):\n",
    "    #        demo_vid_writer[index].release()  # release previous video writer\n",
    "    #        print('removed video write ', demo_vid_path[index])\n",
    "            \n",
    "    #demo_vid_path = []\n",
    "    \n",
    "    ##cmtbyslm\n",
    "    df = pd.DataFrame(cow_id, columns = [\"ID\"])\n",
    "    try:\n",
    "        original_ids = torch.tensor(cow_id_original, device = 'cpu')\n",
    "        df[\"Original\"] = original_ids\n",
    "    except:\n",
    "         df[\"Original\"] = cow_id_original\n",
    "    \n",
    "    \n",
    "    \n",
    "    now=str(datetime.now().date())\n",
    "    try: #ohh is it me?\n",
    "        print(all_detected_cow)\n",
    "        #all_detected_cow = torch.tensor(all_detected_cow,device=\"cpu\")\n",
    "        detected_cow_df = pd.DataFrame(all_detected_cow, columns = ['ID'])\n",
    "        detected_cow_df.to_csv('csv/all_detected_cow_'+str(frame_rate)+'_fps_'+now+'.csv')  \n",
    "        print('result saved to all_detected_cow_'+str(frame_rate)+'_fps_'+now+'.csv')\n",
    "    except :\n",
    "        print (\"couldn't save all_detected_cow\")\n",
    "    \n",
    "    path_to_csv = csv_save_dir+'/detected_cow_vggSVM_'+now+'.csv'\n",
    "    df.to_csv(path_to_csv, index= False) \n",
    "    \n",
    "    # Print results\n",
    "    t = tuple(x / seen * 1E3 for x in dt)  # speeds per image\n",
    "    LOGGER.info(f'Speed: %.1fms pre-process, %.1fms inference, %.1fms NMS per image at shape {(1, 3, *imgsz)}' % t)\n",
    "    \n",
    "    if save_txt or save_img:\n",
    "        s = f\"\\n{len(list(save_dir.glob('labels/*.txt')))} labels saved to {save_dir / 'labels'}\" if save_txt else ''\n",
    "        LOGGER.info(f\"Results saved to {colorstr('bold', save_dir)}{s}\")\n",
    "    if update:\n",
    "        strip_optimizer(weights)  # update model (to fix SourceChangeWarning)\n",
    "    \n",
    "    Generate_Cattle_Id_By_Apperance(path_to_csv,csv_save_dir)\n",
    "    \n",
    "    ########### region save csv for each cattle\n",
    "\n",
    "    for csv_index in range(len(prevId_record)):\n",
    "        df = pd.DataFrame(MAX_prevId[csv_index] , columns = ['ID'])\n",
    "        try:\n",
    "            org_ids = torch.tensor(MAX_orgId[csv_index], device = 'cpu')\n",
    "            df[\"Original\"] = org_ids\n",
    "        except:\n",
    "            df[\"Original\"] = MAX_orgId[csv_index]\n",
    "        \n",
    "        try:\n",
    "            stored_locations = torch.tensor(IMAGE_STORED_LOCATION[csv_index],device = 'cpu')\n",
    "            df[\"location\"] = stored_locations\n",
    "        except:\n",
    "            df[\"location\"]=IMAGE_STORED_LOCATION[csv_index]\n",
    "        df[\"xyxy1\"] = MAX_xyxy1[csv_index]\n",
    "        df[\"xyxy2\"] = MAX_xyxy2[csv_index]\n",
    "        df[\"xyxy3\"] = MAX_xyxy3[csv_index]\n",
    "        df[\"xyxy4\"] = MAX_xyxy4[csv_index]\n",
    "\n",
    "\n",
    "        now=str(datetime.now().date())\n",
    "                            \n",
    "        save_csv_each_path = str(Path(save_dir / str(prevId_record[csv_index]) / str(prevId_record[csv_index]) / f'{str(prevId_record[csv_index])}.csv'))\n",
    "        df.to_csv(save_csv_each_path, index= False)##asdfasdf\n",
    "    prevId_record = []\n",
    "    MAX_prevId = []\n",
    "    MAX_xyxy1 = [] \n",
    "    MAX_xyxy2 = [] \n",
    "    MAX_xyxy3 = [] \n",
    "    MAX_xyxy4 = [] \n",
    "    MAX_orgId = [] \n",
    "    IMAGE_STORED_LOCATION = []\n",
    "                                      \n",
    "    cattle_ids = []\n",
    "    #################################\\\n",
    "    manual_summarize_ids = []\n",
    "    manual_local_ids = []\n",
    "    #### write video after saving csv\n",
    "    final_cattle_count = 1\n",
    "    for loc in range(len(demo_img_save_path)):\n",
    "        print(demo_img_save_path[loc])\n",
    "        final_cattle_id = writeVideo(demo_img_save_path[loc])\n",
    "        if(final_cattle_id != -1):\n",
    "            manual_local_ids.append(final_cattle_count)\n",
    "            manual_summarize_ids.append(final_cattle_id)\n",
    "            final_cattle_count+=1 \n",
    "    \n",
    "    summarize_id_csv = pd.DataFrame(manual_local_ids, columns = [\"Local Id\"])\n",
    "    try:\n",
    "        manual_summarize_ids = torch.tensor(manual_summarize_ids, device = 'cpu')\n",
    "        summarize_id_csv[\"Cow Id\"] = manual_summarize_ids\n",
    "    except:\n",
    "         summarize_id_csv[\"Cow Id\"] = manual_summarize_ids\n",
    "            \n",
    "    summarize_id_csv.to_csv(csv_save_dir+'/summarize_id_'+now+'.csv', index= False) \n",
    "    \n",
    "    \n",
    "    df.to_csv(csv_save_dir+'/detected_cow_vggSVM_'+now+'.csv', index= False) \n",
    "    # Print results\n",
    "    t = tuple(x / seen * 1E3 for x in dt)  # speeds per image\n",
    "    LOGGER.info(f'Speed: %.1fms pre-process, %.1fms inference, %.1fms NMS per image at shape {(1, 3, *imgsz)}' % t)\n",
    "    \n",
    "    if save_txt or save_img:\n",
    "        s = f\"\\n{len(list(save_dir.glob('labels/*.txt')))} labels saved to {save_dir / 'labels'}\" if save_txt else ''\n",
    "        LOGGER.info(f\"Results saved to {colorstr('bold', save_dir)}{s}\")\n",
    "    if update:\n",
    "        strip_optimizer(weights)  # update model (to fix SourceChangeWarning)\n",
    "        \n",
    "def parse_opt():\n",
    "    class Args:\n",
    "        #weights='September_bounding_flip_800\\best.pt' # model.pt path(s) where is weight?\n",
    "        weights=ROOT / 'apirl_weights/v1_bright_dar_noise/best.pt' #'paper_weights/epochs_300_weights/best.pt' #v3\n",
    "        #source= \"C:\\\\Users\\\\thithilab\\\\Desktop\\\\file\\\\New Data\\\\14\\\\first32\\\\20220310_152525_E1E0.mkv\" # file/dir/URL/glob, 0 for webcam  //change your video path here\n",
    "        source= file_location # file/dir/URL/glob, 0 for webcam  //change your video path here\n",
    "        data='data/coco128.yaml'  # dataset.yaml path\n",
    "        imgsz=(640, 640)  # inference size (height, width)\n",
    "        conf_thres=0.2 # confidence threshold\n",
    "        iou_thres=0.001  # NMS IOU threshold 0.45\n",
    "        max_det=4 # maximum detections per image # prev 1000\n",
    "        device='0'  # cuda device, i.e. 0 or 0,1,2,3 or cpu\n",
    "        view_img=True  # show results\n",
    "        save_txt=False  # save results to *.txt\n",
    "        save_conf=False  # save confidences in --save-txt labels\n",
    "        save_crop=True  # save cropped prediction boxes\n",
    "        nosave=False  # do not save images/videos\n",
    "        classes=None  # filter by class: --class 0, or --class 0 2 3 #None is prev value\n",
    "        agnostic_nms=False  # class-agnostic NMS\n",
    "        augment=False  # augmented inference\n",
    "        visualize=False  # visualize features\n",
    "        update=False  # update all models\n",
    "        project='runs/paper/may/vgg_SVM'  # save results to project/name\n",
    "        name='exp'  # save results to project/name\n",
    "        exist_ok=False  # existing project/name ok, do not increment\n",
    "        line_thickness=8  # bounding box thickness (pixels)\n",
    "        hide_labels=False  # hide labels\n",
    "        hide_conf=False  # hide confidences\n",
    "        half=True  # use FP16 half-precision inference #False\n",
    "        dnn=False  # use OpenCV DNN for ONNX inference\n",
    "\n",
    "    return Args()\n",
    "     \n",
    "   #parser here\n",
    "\n",
    "\n",
    "def main(opt):\n",
    "    check_requirements(exclude=('tensorboard', 'thop'))\n",
    "    run(**vars(opt))\n",
    "    #run()\n",
    "\n",
    "#__name__==\"__main__\"\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    frame_rate=3\n",
    "    opt = parse_opt()\n",
    "    t = Timer()\n",
    "    t.start() # timer start \n",
    "    main(opt)\n",
    "    t.stop()  # A few seconds later=\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855c70e0-3f9b-48dc-8843-fb5c1ede67cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LCNN_GNB_CLASSIFIER(image):\n",
    "    test_image = preprocess_input(image)\n",
    "    image = np.expand_dims(test_image, axis=0) \n",
    "    \n",
    "    #feature = base_model.predict(np.array([image]))[0]\n",
    "    \n",
    "    test_feature = base_model.predict(image)[0]\n",
    "    input_img_features=test_feature.reshape(test_feature.shape[0],-1)\n",
    "    predicted_label = nb_classifier.predict(input_img_features)[0]\n",
    "    #prediction_RF = le.inverse_transform([prediction_RF])  #Reverse the label encoder to original name\n",
    "    \n",
    "    \n",
    "    return predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3811f1b4-cb20-43e5-8ec3-d9463ae7bd22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db7f014-2f41-455a-b2bc-bf7bcf77e612",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(prevId_record)\n",
    "#print(MAX_prevId)\n",
    "#MAX_prevId[0].append(3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e73ce4b-15df-4b26-9c96-f38a47d7db37",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5139acf2-ee9e-4f49-a18a-7e106c993efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#python -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfd271f-3b94-4b68-b067-a7962a2c36f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294c06fa-bb7e-44fa-8687-e6e32f9b34aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972b727d-861a-4fbb-922d-389b5bff6f8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a002eb-1e9b-4651-90ea-78c3cf863116",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
