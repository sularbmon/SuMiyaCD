{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431e2944-6816-420b-9e7e-08ec37899098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://youtu.be/9GzfUzJeyi0\n",
    "\n",
    "\"\"\"\n",
    "@author: Sreenivas Bhattiprolu\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "\n",
    "\n",
    "#from keras.layers.normalization import BatchNormalization\n",
    "import os\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "\n",
    "total_classes=0  #to change when mee lay want to add more cows\n",
    "#images_per_validation=5\n",
    "\n",
    "\n",
    "#print(os.listdir(\"../Gold\"))\n",
    "\n",
    "SIZE = 112\n",
    "\n",
    "import csv\n",
    "\n",
    "#data = pd.read_csv('D:\\\\LamenessData\\\\September_6\\\\evening.csv',index_col ='Local_ID')\n",
    "\n",
    "#COW_MAPPER = [list(row) for row in data.values]\n",
    "\n",
    "x_train = []\n",
    "train_labels = [] \n",
    "directory_path = \"D:\\\\LamenessData\\\\yolov8_features\\\\honkawa_yolov8_dataset291\\\\TrainingImages\\\\\"\n",
    "label = \"CATTLE\"\n",
    "\n",
    "t =  os.path.join(directory_path, \"*.jpg\")\n",
    "print(t)\n",
    "for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n",
    "    #print(img_path)\n",
    "    total_classes+=1\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_COLOR)       \n",
    "        \n",
    "    img = cv2.resize(img, (SIZE, SIZE))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    x_train.append(img)\n",
    "    train_labels.append(label)\n",
    "        \n",
    "x_train = np.array(x_train)\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "print(total_classes)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c56531c-129d-4673-8110-e1f1f1910fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# test\n",
    "count = 0\n",
    "y_train = []\n",
    "test_labels = [] \n",
    "images_per_validation =[]\n",
    "directory_path = \"D:\\\\LamenessData\\\\yolov8_features\\\\honkawa_yolov8_dataset291\\\\\\ValidationImages\\\\\"  #to change when baby add new images\n",
    "for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n",
    "    #print(img_path)\n",
    "    total_classes+=1\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_COLOR)       \n",
    "        \n",
    "    img = cv2.resize(img, (SIZE, SIZE))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    y_train.append(img)\n",
    "    test_labels.append(\"Validation\")\n",
    "    count+=1\n",
    "    images_per_validation.append(count)\n",
    "        \n",
    "y_train = np.array(y_train)\n",
    "test_labels = np.array(test_labels)\n",
    "#Encode labels from text to integers.\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(test_labels)\n",
    "test_labels_encoded = le.transform(test_labels)\n",
    "le.fit(train_labels)\n",
    "train_labels_encoded = le.transform(train_labels)\n",
    "print(\"Train lables encoded is here\")\n",
    "#print(train_labels_encoded)\n",
    "#Split data into test and train datasets (already split but assigning to meaningful convention)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eb568a24-1721-476a-8765-540499e16db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 112, 3)\n",
      "Epoch 1/20\n",
      "1250/1250 [==============================] - 38s 30ms/step - loss: 0.6000 - model_14_loss: 0.2000 - model_14_1_loss: 0.2000 - model_14_2_loss: 0.2000\n",
      "Epoch 2/20\n",
      "1250/1250 [==============================] - 36s 29ms/step - loss: 0.6000 - model_14_loss: 0.2000 - model_14_1_loss: 0.2000 - model_14_2_loss: 0.2000\n",
      "Epoch 3/20\n",
      "1250/1250 [==============================] - 38s 30ms/step - loss: 0.6000 - model_14_loss: 0.2000 - model_14_1_loss: 0.2000 - model_14_2_loss: 0.2000\n",
      "Epoch 4/20\n",
      "1250/1250 [==============================] - 38s 31ms/step - loss: 0.6000 - model_14_loss: 0.2000 - model_14_1_loss: 0.2000 - model_14_2_loss: 0.2000\n",
      "Epoch 5/20\n",
      "1250/1250 [==============================] - 38s 31ms/step - loss: 0.6000 - model_14_loss: 0.2000 - model_14_1_loss: 0.2000 - model_14_2_loss: 0.2000\n",
      "Epoch 6/20\n",
      "1250/1250 [==============================] - 38s 31ms/step - loss: 0.6000 - model_14_loss: 0.2000 - model_14_1_loss: 0.2000 - model_14_2_loss: 0.2000\n",
      "Epoch 7/20\n",
      "1250/1250 [==============================] - 38s 31ms/step - loss: 0.6000 - model_14_loss: 0.2000 - model_14_1_loss: 0.2000 - model_14_2_loss: 0.2000\n",
      "Epoch 8/20\n",
      "1250/1250 [==============================] - 37s 29ms/step - loss: 0.6000 - model_14_loss: 0.2000 - model_14_1_loss: 0.2000 - model_14_2_loss: 0.2000\n",
      "Epoch 9/20\n",
      "1250/1250 [==============================] - 38s 30ms/step - loss: 0.6000 - model_14_loss: 0.2000 - model_14_1_loss: 0.2000 - model_14_2_loss: 0.2000\n",
      "Epoch 10/20\n",
      "1250/1250 [==============================] - 38s 31ms/step - loss: 0.6000 - model_14_loss: 0.2000 - model_14_1_loss: 0.2000 - model_14_2_loss: 0.2000\n",
      "Epoch 11/20\n",
      "1250/1250 [==============================] - 38s 31ms/step - loss: 0.6000 - model_14_loss: 0.2000 - model_14_1_loss: 0.2000 - model_14_2_loss: 0.2000\n",
      "Epoch 12/20\n",
      "1250/1250 [==============================] - 38s 31ms/step - loss: 0.6000 - model_14_loss: 0.2000 - model_14_1_loss: 0.2000 - model_14_2_loss: 0.2000\n",
      "Epoch 13/20\n",
      "1250/1250 [==============================] - 38s 31ms/step - loss: 0.6000 - model_14_loss: 0.2000 - model_14_1_loss: 0.2000 - model_14_2_loss: 0.2000\n",
      "Epoch 14/20\n",
      "1250/1250 [==============================] - 38s 31ms/step - loss: 0.6000 - model_14_loss: 0.2000 - model_14_1_loss: 0.2000 - model_14_2_loss: 0.2000\n",
      "Epoch 15/20\n",
      "1250/1250 [==============================] - 38s 31ms/step - loss: 0.6000 - model_14_loss: 0.2000 - model_14_1_loss: 0.2000 - model_14_2_loss: 0.2000\n",
      "Epoch 16/20\n",
      "1250/1250 [==============================] - 36s 29ms/step - loss: 0.6000 - model_14_loss: 0.2000 - model_14_1_loss: 0.2000 - model_14_2_loss: 0.2000\n",
      "Epoch 17/20\n",
      "1250/1250 [==============================] - 38s 30ms/step - loss: 0.6000 - model_14_loss: 0.2000 - model_14_1_loss: 0.2000 - model_14_2_loss: 0.2000\n",
      "Epoch 18/20\n",
      "1250/1250 [==============================] - 38s 31ms/step - loss: 0.6000 - model_14_loss: 0.2000 - model_14_1_loss: 0.2000 - model_14_2_loss: 0.2000\n",
      "Epoch 19/20\n",
      "1250/1250 [==============================] - 38s 31ms/step - loss: 0.6000 - model_14_loss: 0.2000 - model_14_1_loss: 0.2000 - model_14_2_loss: 0.2000\n",
      "Epoch 20/20\n",
      "1250/1250 [==============================] - 38s 31ms/step - loss: 0.6000 - model_14_loss: 0.2000 - model_14_1_loss: 0.2000 - model_14_2_loss: 0.2000\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'done' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 54\u001b[0m\n\u001b[0;32m     51\u001b[0m siamese_model\u001b[38;5;241m.\u001b[39mfit([anchor, positive, negative], y\u001b[38;5;241m=\u001b[39mx_test[:n_triplets], epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# After training, you can use the base_network to extract embeddings for inference.\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdone\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'done' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Sample dataset (you should replace this with your own dataset)\n",
    "#(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train, y_train, x_test, y_test = x_train, train_labels_encoded, y_train, test_labels_encoded\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# Define a Siamese network architecture\n",
    "def create_siamese_network(input_shape):\n",
    "    input = keras.layers.Input(shape=input_shape)\n",
    "    x = keras.layers.Flatten()(input)\n",
    "    x = keras.layers.Dense(128, activation='relu')(x)\n",
    "    x = keras.layers.Dropout(0.5)(x)\n",
    "    output = keras.layers.Dense(64)(x)\n",
    "    return keras.models.Model(input, output)\n",
    "\n",
    "input_shape = x_train.shape[1:]\n",
    "print(input_shape)\n",
    "# Create two identical siamese subnetworks\n",
    "base_network = create_siamese_network(input_shape)\n",
    "\n",
    "input_anchor = keras.layers.Input(shape=input_shape)\n",
    "input_positive = keras.layers.Input(shape=input_shape)\n",
    "input_negative = keras.layers.Input(shape=input_shape)\n",
    "\n",
    "output_anchor = base_network(input_anchor)\n",
    "output_positive = base_network(input_positive)\n",
    "output_negative = base_network(input_negative)\n",
    "\n",
    "# Define the triplet loss\n",
    "def triplet_loss(margin=0.2):\n",
    "    def loss(y_true, y_pred):\n",
    "        anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
    "        distance_positive = tf.reduce_sum(tf.square(anchor - positive), axis=-1)\n",
    "        distance_negative = tf.reduce_sum(tf.square(anchor - negative), axis=-1)\n",
    "        loss_value = tf.maximum(0.0, distance_positive - distance_negative + margin)\n",
    "        return tf.reduce_mean(loss_value)\n",
    "    return loss\n",
    "\n",
    "# Create the Siamese model\n",
    "siamese_model = keras.models.Model(inputs=[input_anchor, input_positive, input_negative], outputs=[output_anchor, output_positive, output_negative])\n",
    "\n",
    "# Compile the model with the triplet loss\n",
    "siamese_model.compile(loss=triplet_loss(), optimizer=keras.optimizers.Adam(learning_rate=0.001))\n",
    "\n",
    "# Train the model using triplets\n",
    "# You need to provide your own triplet data\n",
    "# Here, we'll use dummy data\n",
    "n_triplets = 10000\n",
    "anchor, positive, negative = x_train[:n_triplets], x_train[n_triplets:2*n_triplets], x_train[2*n_triplets:3*n_triplets]\n",
    "#print(anchor)\n",
    "siamese_model.fit([anchor, positive, negative], y=x_test[:n_triplets], epochs=20, batch_size=8)\n",
    "\n",
    "# After training, you can use the base_network to extract embeddings for inference.\n",
    "print(done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba291d2-db5c-4370-8dbd-7cce884a077c",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
