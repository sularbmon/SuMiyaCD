{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b676c638-f48d-49a7-a1a1-6fe98e5b5d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thithilab\\AppData\\Roaming\\Python\\Python39\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16abd98a-5a5c-4d05-b271-eedfed0315ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yolo->engine->model.py93\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "import time\n",
    "from ultralytics.yolo.utils.files import increment_path\n",
    "import torch\n",
    "import gc\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "#from pathlib import Path\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "from ultralytics.yolo.utils.plotting import Annotator\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"D:/Python/SULarbmon/Python/env/yolov8_june/runs/segment/Honkawa_Weights_v1/weights/best.pt\")  # load a custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eba0d22-24e9-4695-9ebd-ef41e852f195",
   "metadata": {},
   "outputs": [],
   "source": [
    "le_filename = '../HONKAWA_VGG_SVM/GENERAL_LE_SUMIYOSHI_1103.le'\n",
    "predictor_filename ='../HONKAWA_VGG_SVM/VGG_SVM_HONKAWA_1103_v1.pkl'\n",
    "\n",
    "predictor = pickle.load(open(predictor_filename, 'rb'))\n",
    "lable_encoder = pickle.load(open(le_filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc46bb71-637a-4054-8201-086685c58da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE=224\n",
    "\n",
    "vgg = VGG16(weights='imagenet', include_top=False, input_shape=(SIZE, SIZE, 3))\n",
    "\n",
    "#Make loaded layers as non-trainable. This is important as we want to work with pre-trained weights\n",
    "for layer in vgg.layers:\n",
    "\tlayer.trainable = False\n",
    "    \n",
    "#vgg.summary()  #Trainable parameters will be 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f235b43-c095-4399-b8b5-547abefd452e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defined predictor\n"
     ]
    }
   ],
   "source": [
    "def Predict_SVM(image):  ## new with vgg\n",
    "    \n",
    "    input_img = np.expand_dims(image, axis=0) #Expand dims so the input is (num images, x, y, c)\n",
    "    input_img_feature=vgg.predict(input_img)\n",
    "    input_img_features=input_img_feature.reshape(input_img_feature.shape[0], -1)\n",
    "    predicted_result = predictor.predict(input_img_features)[0] \n",
    "    predicted_result = lable_encoder.inverse_transform([predicted_result])  #Reverse the label encoder to original name\n",
    "    \n",
    "    return predicted_result\n",
    "print(\"defined predictor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e2d6dec-36da-491e-95ea-896b621be300",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###### load dataset and model\n",
    "\n",
    "\n",
    "def check_withinROI_NEW(x1,y1,x2,y2,h,w):\n",
    "    #print(x1, '  ',y1, '  ',x2, '  ',y2, '  ',h, '  ',w)\n",
    "    #if(x1<int(X1*(w/default)) or x2>int(X2*(w/default)) or y1<int(Y1_NEW*(h/default)) or y2>int(Y2_NEW*(h/default)) or x1>=int(X2*(w/default))):\n",
    "    #    return False\n",
    "    \n",
    "    if(x1<150 or x2>1750):\n",
    "        return False\n",
    "    if(y2-y1<600 or x2-x1 <250): #1400 to 700 Before\n",
    "        return False\n",
    "    return True  \n",
    "\n",
    "def check_withinROI_Resize(x1,y1,x2,y2,h,w):\n",
    "    #print(x1, '  ',y1, '  ',x2, '  ',y2, '  ',h, '  ',w)\n",
    "    resize_x1=850#*(w/2992)\n",
    "    resize_x2=1050#*(w/2992)\n",
    "    resize_y1=Y1_NEW#Y1_NEW*(w/2992)\n",
    "    resize_y2=Y1_NEW#Y2_NEW*(w/2992)\n",
    "    #print(resize_x1, '  ',resize_y1, '  ',resize_x2, '  ',resize_y2)\n",
    "    if(x1<int(resize_x1) or x2>int(resize_x2) or x1>=int(resize_x2)):\n",
    "        return False\n",
    "    if(y2 - y1>1400 or y2-y1<700): #1400 to 700 Before\n",
    "        return False\n",
    "    return True  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "056bd001-9ec5-4d37-8d4f-794eb6d030d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Is_Duplicate_Id(y1,y2,id):\n",
    "    global PREVIOUS_ID\n",
    "    global PREVIOUS_Y1\n",
    "    global PREVIOUS_Y2\n",
    "    global PREVIOUS_LOCAL_IDS\n",
    "    global CATTLE_LOCAL_ID\n",
    "    \n",
    "    try: \n",
    "        index = PREVIOUS_ID.index(id)\n",
    "        print('I reached here')\n",
    "        if(PREVIOUS_Y1[index]+321<=y1 and PREVIOUS_Y2[index]+371<y2): #duplicate from bottom\n",
    "         #   if(id in PREVIOUS_LOCAL_IDS):\n",
    "         #   #print('id: ',id,' LOCAL_ID: ',CATTLE_LOCAL_ID)\n",
    "         #       return PREVIOUS_LOCAL_IDS[id][0]\n",
    "            \n",
    "            #print('except')\n",
    "            PREVIOUS_ID.append(CATTLE_LOCAL_ID)\n",
    "            PREVIOUS_Y1.append(y1)\n",
    "            PREVIOUS_Y2.append(y2)\n",
    "            #print('New Cattle Id')\n",
    "            CATTLE_LOCAL_ID+=1\n",
    "            return CATTLE_LOCAL_ID\n",
    "        #elif(PREVIOUS_Y[index]+400<center): #stepping back\n",
    "        #    if(id in PREVIOUS_LOCAL_IDS):\n",
    "        #        return PREVIOUS_LOCAL_IDS[id][0]\n",
    "        else:\n",
    "            #print('Oh. here ? really?')\n",
    "            PREVIOUS_Y1[index]=y1 #duplicate is solved or no duplicate and just need for last y \n",
    "            PREVIOUS_Y2[index]=y2\n",
    "            #return PREVIOUS_LOCAL_IDS[index][1]\n",
    "            \n",
    "            #update('PREVIOUS Y')\n",
    "            return PREVIOUS_ID[index]\n",
    "    except:\n",
    "        #print(PREVIOUS_ID)\n",
    "        #print(id)\n",
    "        CATTLE_LOCAL_ID += 1\n",
    "        #print('except')\n",
    "        PREVIOUS_ID.append(CATTLE_LOCAL_ID)\n",
    "        PREVIOUS_Y1.append(y1)\n",
    "        PREVIOUS_Y2.append(y2)\n",
    "        return id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ed9d4de-4e94-4b9a-a257-9e571cc441ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Take_Prev_Label(y,h,id,cow_srno):\n",
    "    global STORED_IDS\n",
    "    global STORED_MID_Y\n",
    "    global STORED_MID_Y1\n",
    "    global STORED_MID_Y2\n",
    "    global STORED_MISS\n",
    "    global LAST_SEEN_IDS\n",
    "    global LAST_SEEN_ID_CENTROIDS\n",
    "    global CATTLE_LOCAL_ID\n",
    "    global IS_FIRST_CATTLE \n",
    "    y1 , y2 = y , y+h\n",
    "    \n",
    "    if IS_FIRST_CATTLE:\n",
    "        IS_FIRST_CATTLE = False\n",
    "        id = CATTLE_LOCAL_ID\n",
    "    #mid_y = y2\n",
    "    mid_y = int(2*y + h)/2\n",
    "    IS_NEW = True\n",
    "    last_id = 999\n",
    "    last_y1 = 0\n",
    "    last_y2 = 0\n",
    "    if(len(STORED_IDS)>0): \n",
    "        last_id = STORED_IDS[len(STORED_IDS)-1]\n",
    "        last_y1 = STORED_MID_Y1[len(STORED_MID_Y1)-1]#max(STORED_MID_Y1)\n",
    "        last_y2 = STORED_MID_Y2[len(STORED_MID_Y2)-1]#max(STORED_MID_Y2)\n",
    "        MISSED_LEN = len(STORED_MISS)\n",
    "        #if(IS_NEW):\n",
    "        \n",
    "        #    MISSED_LEN -=1\n",
    "        removed = 0\n",
    "        for i in range(MISSED_LEN):\n",
    "            #print(i, ' missed index checking' )\n",
    "            missed = STORED_MISS[i-removed]\n",
    "            #print('checking ',i-removed, 'to remove')\n",
    "            if(missed>70): #if missed 35 frames\n",
    "    \n",
    "                del STORED_MISS[i-removed]  \n",
    "                del STORED_MID_Y[i-removed]\n",
    "                del STORED_MID_Y1[i-removed]\n",
    "                del STORED_MID_Y2[i-removed]\n",
    "                del STORED_IDS[i-removed]\n",
    "                removed+=1\n",
    "                #print('removed')\n",
    "                \n",
    "    #clear misses\n",
    "   \n",
    "    \n",
    "    threshold_1 = 100 #300\n",
    "    threshold_2 = 100  #230\n",
    "    Distance = 5\n",
    "     \n",
    "    #if mid_y <= 1300 or mid_y >= 700:\n",
    "    #    threshold_1 = 320 #350\n",
    "    #    threshold_2 = 370 #280\n",
    "    for i in range(1,len(STORED_MID_Y)+1):\n",
    "        #print(STORED_IDS[-i-1],STORED_MID_Y[-i-1],' ',i)\n",
    "        \n",
    "        \n",
    "        #if(STORED_MID_Y[-i]+threshold_2>=mid_y and STORED_MID_Y[-i]-threshold_1<=mid_y): # and IS_NEW): #previous 150 #200\n",
    "        if(STORED_MID_Y1[-i]-threshold_1<=y1 and STORED_MID_Y1[-i]+threshold_1>=y1) or (STORED_MID_Y2[-i]-threshold_2<=y2 and STORED_MID_Y2[-i]+threshold_2>=y2): # and IS_NEW): #previous 150 #200\n",
    "            if(IS_NEW):\n",
    "              \n",
    "                \n",
    "                Distance = abs(STORED_MID_Y1[-i] - y1)\n",
    "                if(abs(STORED_MID_Y2[-i] - y2)<Distance):\n",
    "                    Distance = abs(STORED_MID_Y2[-i] - y2)\n",
    "                IS_NEW = False\n",
    "                STORED_MID_Y1[-i] = y1\n",
    "                STORED_MID_Y2[-i] = y2\n",
    "                \n",
    "                STORED_MISS[-i]=1\n",
    "                id= STORED_IDS[-i]\n",
    "                #print(Distance)\n",
    "                #print(id)\n",
    "                \n",
    "            #try:\n",
    "            #    exist_index = LAST_SEEN_IDS.index(id)\n",
    "            #    if(LAST_SEEN_ID_CENTROIDS[exist_index]+200>y): # showing old id\n",
    "            #        LAST_SEEN_ID_CENTROIDS[exist_index] = y\n",
    "            #except:\n",
    "            #print('corrected id :',STORED_IDS[-i])\n",
    "            elif Distance >5:\n",
    "                STORED_MISS[-i]+=1\n",
    "            #else:\n",
    "            #    STORED_MISS[-i]-=1 #reset count to 2 when not moving\n",
    "        #elif(STORED_MID_Y1[-i]<=y1 and STORED_MID_Y2[-i]>=y2):\n",
    "        #        STORED_MISS[-i]=30\n",
    "        else:\n",
    "            STORED_MISS[-i]+=1    \n",
    "     \n",
    "    if(IS_NEW == False):\n",
    "        if(y1>last_y1+20 and y2>last_y2+20):\n",
    "            IS_NEW = True\n",
    "        #elif (y1<last_y1+10 and y2<last_y2+10):\n",
    "        #    print('Skipped first here')\n",
    "        #    return -1\n",
    "    \n",
    "        #elif(cow_srno==1):\n",
    "    if(IS_NEW):\n",
    "        CATTLE_LOCAL_ID+=1\n",
    "        id=CATTLE_LOCAL_ID\n",
    "        if(y1<last_y1+70 and y2<last_y2+70):\n",
    "            CATTLE_LOCAL_ID-=1\n",
    "            print('skipped second here')\n",
    "            for i in range(len(STORED_MID_Y)):\n",
    "                STORED_MISS[i]=5\n",
    "            return -1\n",
    "            \n",
    "        STORED_IDS.append(id)\n",
    "        STORED_MID_Y.append(mid_y)\n",
    "        STORED_MID_Y1.append(y1)\n",
    "        STORED_MID_Y2.append(y2)\n",
    "        STORED_MISS.append(1)\n",
    "    #print(STORED_IDS,' IDS ',STORED_MID_Y,' SMY ',mid_y,' mid_y')\n",
    "    if(IS_NEW) and False:\n",
    "        #print('SMY: ',STORED_MID_Y,', new my:',mid_y) \n",
    "        #print('new id: ',id)\n",
    "        updatedID = Is_Duplicate_Id(y1,y2,id)\n",
    "        if(int(last_id) <int(updatedID) and y1<last_y1-150 and y2<last_y2-150): # duplicate cattle with increased cattleID\n",
    "            CATTLE_LOCAL_ID-=1\n",
    "            for i in range(len(STORED_MID_Y)-1,0,-1):\n",
    "                STORED_MISS[i]=15\n",
    "            return -1\n",
    "        if(int(last_id)-1>int(updatedID)):\n",
    "            return -1\n",
    "            \n",
    "    #if(updatedID!=id):\n",
    "    #    print('orgID: ',id,' updated ID: ',updatedID)\n",
    "        #id = str(updated_ID)+'_'+str(id)\n",
    "        \n",
    "        id=CATTLE_LOCAL_ID\n",
    "        STORED_IDS.append(id)\n",
    "        STORED_MID_Y.append(mid_y)\n",
    "        STORED_MID_Y1.append(y1)\n",
    "        STORED_MID_Y2.append(y2)\n",
    "        STORED_MISS.append(1)\n",
    "    \n",
    "    #print('returned id :',id)\n",
    "    \n",
    "    #print(id)\n",
    "          \n",
    "    result = []\n",
    "    result.append(str(id-1))\n",
    "    \n",
    "    #region remove stored id\n",
    "    removed = 0\n",
    "    print(STORED_MID_Y1,'  <===== y1, y2 =====>  ',STORED_MID_Y2,'    result =====>',result)\n",
    "    #for i in range(len(STORED_MID_Y)-1,0,-1):\n",
    "    #    if(y1>STORED_MID_Y1[i] and y2>STORED_MID_Y2[i]):\n",
    "    #        del STORED_MISS[i-removed]  \n",
    "    #        del STORED_MID_Y[i-removed]\n",
    "    #        del STORED_MID_Y1[i-removed]\n",
    "    #        del STORED_MID_Y2[i-removed]\n",
    "    #        del STORED_IDS[i-removed]\n",
    "    #        removed+=1\n",
    "                 \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3415efa4-0dc9-4cb9-afd0-ea35f35e1671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CALCULATE_MAX_CATTLE_ID(csv_path):\n",
    "    print(csv_path, \" is csv_path and \")\n",
    "\n",
    "    data = pd.read_csv(csv_path)\n",
    "\n",
    "    list_of_csv = [list(row) for row in data.values]\n",
    "\n",
    "    prev_id_record = [] \n",
    "    prev=None\n",
    "\n",
    "    current_cow = []\n",
    "    excel_cow_count = []\n",
    "    boxes = []\n",
    "    file_locations = []\n",
    "\n",
    "    for i in range (len(list_of_csv)):\n",
    "        filtered_id = list_of_csv[i][0]\n",
    "        actual_id = list_of_csv[i][1]\n",
    "        file_locations.append(list_of_csv[i][2])\n",
    "        boxes.append([list_of_csv[i][3],list_of_csv[i][4],list_of_csv[i][5],list_of_csv[i][6]])\n",
    "        try: \n",
    "            index = current_cow.index(actual_id)\n",
    "            excel_cow_count[index]+=1\n",
    "        except:\n",
    "            current_cow.append(actual_id)\n",
    "            excel_cow_count.append(1)\n",
    "\n",
    "    maxpos = excel_cow_count.index(max(excel_cow_count))\n",
    "    cattle_id = current_cow[maxpos]\n",
    "    return cattle_id,file_locations,boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96d5d266-6ce4-4300-8274-43cd35ed541c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def writeVideo(cap,filePath):\n",
    "    img_array = []\n",
    "    size = (1080,1080)\n",
    "    names = ['cow']\n",
    "\n",
    "\n",
    "    vid_name = os.path.basename(os.path.normpath(filePath))\n",
    "    #vid_path = str(Path(filePath + \"/\" + vid_name ).with_suffix('.mp4'))\n",
    "    id,img_locations,*xyxys = CALCULATE_MAX_CATTLE_ID(filePath+\"/\"+vid_name+\".csv\")\n",
    "    #out = cv2.VideoWriter(vid_path,cv2.VideoWriter_fourcc(*'mp4v'), 6, size)\n",
    "    if len(img_locations)<10: \n",
    "        return -1\n",
    "\n",
    "    for ind in range(len(img_locations)):\n",
    "        img = cv2.imread(img_locations[ind])\n",
    "        annotator = Annotator(img, line_width=8, example=str(names))\n",
    "        try:\n",
    "            annotator.box_label(xyxys[0][ind],str(id), color=(15, 0, 255))\n",
    "            annotated_img =cv2.resize(annotator.result(),size) \n",
    "            cap.write(annotated_img)\n",
    "        except:\n",
    "            continue\n",
    "    #ut.release()\n",
    "    img_array=[]\n",
    "    print(\"done \", vid_name)\n",
    "    #v2.destroyAllWindows()\n",
    "    return id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c55fddc-ffc5-432b-bd34-c94d6d711c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to draw a bounding box and annotate the image\n",
    "def draw_bounding_box(image, box, label):\n",
    "    # Extract the coordinates from the box\n",
    "    x1, y1, x2, y2 = box\n",
    "    #print(x1,' ',y1,x2,y2)\n",
    "\n",
    "    # Draw the bounding box rectangle on the image\n",
    "    cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
    "\n",
    "    # Define the text properties\n",
    "    text = f'{label}'\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    font_scale =1\n",
    "    thickness = 2\n",
    "\n",
    "    # Calculate the size of the text\n",
    "    (text_width, text_height), _ = cv2.getTextSize(text, font, font_scale, thickness)\n",
    "\n",
    "    # Calculate the position for placing the text\n",
    "    text_x = x1\n",
    "    text_y = y1 - 10 if y1 >= 20 else y1 + 10 + text_height\n",
    "\n",
    "    # Draw the text background rectangle\n",
    "    cv2.rectangle(image, (text_x, text_y - text_height - 5), (text_x + text_width, text_y), (0, 255, 0), -1)\n",
    "\n",
    "    # Put the label text on the image\n",
    "    cv2.putText(image, text, (text_x, text_y), font, font_scale, (0, 0, 0), thickness, cv2.LINE_AA)\n",
    "\n",
    "# Example usage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8cb6e8e-04e2-40ca-bd07-db6d380a4ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay(image, mask, color, alpha, resize=None):\n",
    "    \"\"\"Combines image and its segmentation mask into a single image.\n",
    "    \n",
    "    Params:\n",
    "        image: Training image. np.ndarray,\n",
    "        mask: Segmentation mask. np.ndarray,\n",
    "        color: Color for segmentation mask rendering.  tuple[int, int, int] = (255, 0, 0)\n",
    "        alpha: Segmentation mask's transparency. float = 0.5,\n",
    "        resize: If provided, both image and its mask are resized before blending them together.\n",
    "        tuple[int, int] = (1024, 1024))\n",
    "\n",
    "    Returns:\n",
    "        image_combined: The combined image. np.ndarray\n",
    "\n",
    "    \"\"\"\n",
    "    # color = color[::-1]\n",
    "    colored_mask = np.expand_dims(mask, 0).repeat(3, axis=0)\n",
    "    colored_mask = np.moveaxis(colored_mask, 0, -1)\n",
    "    masked = np.ma.MaskedArray(image, mask=colored_mask, fill_value=color)\n",
    "    image_overlay = masked.filled()\n",
    "\n",
    "    if resize is not None:\n",
    "        image = cv2.resize(image.transpose(1, 2, 0), resize)\n",
    "        image_overlay = cv2.resize(image_overlay.transpose(1, 2, 0), resize)\n",
    "\n",
    "    image_combined = cv2.addWeighted(image, 1 - alpha, image_overlay, alpha, 0)\n",
    "\n",
    "    return image_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3183ce0c-9532-4cee-9232-15a5689fb143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GET_LEFT_TO_RIGHT_ORDER(x1s):\n",
    "    orders = []\n",
    "    size = len(x1s)\n",
    "    #print(' x1s     ',x1s)\n",
    "    clones = x1s[:]\n",
    "    for i in range(size):\n",
    "        #print(clones)\n",
    "        id = (x1s.index(min(clones)))\n",
    "        #print(id)\n",
    "        orders.append(id)\n",
    "        print(clones.pop(clones.index(min(clones))))\n",
    "    #print(' sorted order :',orders)\n",
    "    return orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b7045a-10a2-4a01-b48e-19a11473fbc7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "X1=200 #same as NEW_BLACK_X1\n",
    "X2=400 #same as NEW_BLACK_X2 # incase of x2 out of bound\n",
    "Y1=120\n",
    "Y2=500\n",
    "\n",
    "Y1_NEW=120 #125  #decrease here to extend, increase to shrink \n",
    "Y2_NEW=510  #500  # redyce here to extend , increase to do vice casa 460 previous\n",
    "FRAME = 1\n",
    "\n",
    "default=640\n",
    "\n",
    "BATCH = 100\n",
    "BATCH_COUNT = 1\n",
    "PREV_BATCH = 0\n",
    "\n",
    "LAST_SEEN = time.time()\n",
    "FIRST_SEEN = True\n",
    "demo_img_save_path = []\n",
    "\n",
    "prevId_record =[]\n",
    "MAX_prevId = [] \n",
    "MAX_xyxy1 = [] \n",
    "MAX_xyxy2 = [] \n",
    "MAX_xyxy3 = [] \n",
    "MAX_xyxy4 = [] \n",
    "MAX_orgId = []\n",
    "IMAGE_STORED_LOCATION = []\n",
    "#end\n",
    "prevId_record =[]\n",
    "\n",
    "#end\n",
    "\n",
    "#region Cattle Tracking\n",
    "STORED_IDS= []\n",
    "STORED_MID_Y = []\n",
    "STORED_MID_Y1 = []\n",
    "STORED_MID_Y2 = []\n",
    "STORED_MISS = []\n",
    "PREVIOUS_ID = [] # keep the record of last seen ids and position\n",
    "PREVIOUS_Y1 = [] \n",
    "PREVIOUS_Y2 = [] \n",
    "PREVIOUS_LOCAL_IDS = []\n",
    "CATTLE_LOCAL_ID= 1\n",
    "IS_FIRST_CATTLE = True\n",
    "# Predict with the model\n",
    "project = 'D:/Python/SULarbmon/Python/env/yolov8_june/ultralytics/runs/segment/honkawa_3fps'\n",
    "name = '3fps_30_july_2023'\n",
    "dataset = \"D:\\\\815_CowDataChecking\\\\Honkawa\\\\2023-07-30\\\\3fps\"\n",
    "#save_vid_name=  dataset.split(\"\\\\\")[-1].replace('.mkv','_track')  #open this when running single video\n",
    "save_vid_name = dataset.split(\"\\\\\")[-1]+\"_track\" # open this when running multiple videos\n",
    "print(save_vid_name)\n",
    "results = model(dataset,imgsz=(960,640),save=False,retina_masks=False,show=False,stream=True,device='0',conf=0.3)\n",
    "#results = model('D:\\\\815_CowDataChecking\\\\20221228\\\\20221228_E_cow\\\\20221228_151533_D474.mkv',imgsz=1088,save=False,retina_masks=False,show=False,stream=True,device='0',conf=0.2)\n",
    "#save_dir = increment_path(Path(project) / name, exist_ok=True)  # increment run\n",
    "save_dir = increment_path(Path(project) / name,mkdir=True)\n",
    "#(save_dir / 'labels' if False else save_dir).mkdir(parents=True, exist_ok=True)  # make dir\n",
    "manual_cow_count = 0\n",
    "\n",
    "#cap.set(4, 480)\n",
    "save_vid_path = str(Path(os.path.join(save_dir, save_vid_name)).with_suffix('.mp4'))\n",
    "print(save_vid_path)\n",
    "cap = cv2.VideoWriter(save_vid_path,cv2.VideoWriter_fourcc(*'mp4v'), 30, (960,640))\n",
    "\n",
    "for result in results:\n",
    "\n",
    "    \n",
    "    #print(result.boxes)\n",
    "    vid_path = result.path\n",
    "    filename = vid_path.split(\"\\\\\")[-1].replace(\".mp4\",\"\")\n",
    "    \n",
    "    boxes = result.boxes.cpu().numpy()\n",
    "    detections = boxes.xyxy.tolist()\n",
    "    #print(detections)\n",
    "    # Sort the detections based on the x1 coordinate (i.e., left-to-right)\n",
    "    #detections.sort(key=lambda x: x[0])\n",
    "    left_to_right = GET_LEFT_TO_RIGHT_ORDER([t[0] for t in detections])\n",
    "    #print('xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx')\n",
    "    #print(left_to_right)\n",
    "    #print(detections)\n",
    "    \n",
    "    ori_img = cv2.resize(result.orig_img, (640,384), interpolation = cv2.INTER_AREA)\n",
    "    annotator = Annotator(ori_img)\n",
    "    box_count = 0\n",
    "    cow_position = 1\n",
    "    \n",
    "    h,w = result.orig_shape\n",
    "    count = 1\n",
    "    b_boxes = []\n",
    "    masks = []\n",
    "    ids = []\n",
    "    has_cattle = False\n",
    "    if  result.masks != None:\n",
    "        \n",
    "        #result_masks = result.masks.cpu().numpy().masks.astype(bool)\n",
    "        #for m in result.masks.cpu().numpy().masks.astype(bool):\n",
    "        result_masks = result.masks.cpu().numpy().masks.astype(bool)\n",
    "        \n",
    "        for LR_index in left_to_right:\n",
    "            m = result_masks[LR_index]\n",
    "        #for i in range(1,len(result_masks)+1):\n",
    "        #for m in result.masks.masks.astype(bool):\n",
    "            \n",
    "            xyxy = boxes[LR_index].xyxy[0]\n",
    "            #print('LR  INDEX  ',LR_index)\n",
    "            #print(xyxy)\n",
    "        #   m = result_masks[-1]\n",
    "            #print(xyxy)\n",
    "            #print(m.shape)\n",
    "            box_count += 1\n",
    "            x1= int(xyxy[0])\n",
    "            y1= int(xyxy[1])\n",
    "            x2= int(xyxy[2])\n",
    "            y2= int(xyxy[3])\n",
    "            #print(xyxy)\n",
    "            #print(m.shape)\n",
    "            \n",
    "            ################## Validate  #####################\n",
    "            if(check_withinROI_NEW(x1,y1,x2,y2,h,w)==False):\n",
    "                #print(\"I was skipped\")\n",
    "                continue\n",
    "            #print(\"not skipped\")\n",
    "            has_cattle = True\n",
    "            #new_results.append(result)\n",
    "            box_left = x1\n",
    "            box_top = y1\n",
    "            box_w = x2 - x1\n",
    "            box_h = y2 - y1\n",
    "\n",
    "            new = np.zeros_like(ori_img, dtype=np.uint8)\n",
    "            new[m] = ori_img[m]\n",
    "            \n",
    "           \n",
    "            x1= int(x1 * (640/1920))\n",
    "            x2= int(x2 * (640/1920))\n",
    "            y1= int(y1 * (384/1080))\n",
    "            y2= int(y2 * (384/1080))\n",
    "\n",
    "            \n",
    "            \n",
    "            ###### LABEL\n",
    "            crop = cv2.resize(new[y1:y2, x1:x2], (SIZE, SIZE))\n",
    "            #img=img / 255.0\n",
    "            #print(box_left,'    xxxxxx     ' ,box_w)\n",
    "            prev_id = Take_Prev_Label(box_left,box_w,3000,cow_position) ## just passing x values instead of y\n",
    "          #########################################  \n",
    "            HAS_COW=True\n",
    "            #has_cattle = True\n",
    "            if(prev_id==-1): #skip cattle when prev_id // filter id is -1\n",
    "                if(count==1):\n",
    "                    has_seen_cattle=False\n",
    "                    count-=1\n",
    "                #print('skipped')\n",
    "                continue\n",
    "            has_cattle = True\n",
    "            ids.append(prev_id[0])\n",
    "            masks.append(m)\n",
    "            b_boxes.append([x1,y1,x2,y2])\n",
    "            #print(prev_id)\n",
    "            cow_position+=1 \n",
    "            BATCH_COUNT = prev_id[0] # skip batch count here  \n",
    "            \n",
    "            ###################### CREATE dir to save img\n",
    "            #print(prev_id)\n",
    "            base_path = str(Path(save_dir / prev_id[0]))\n",
    "            if not os.path.exists(base_path):\n",
    "                os.makedirs(base_path)\n",
    "\n",
    "\n",
    "            demo_annotated_img_save_path = Path(base_path+ '/' + f'{filename}_{str(manual_cow_count).zfill(4)}.jpg')\n",
    "\n",
    "            try:\n",
    "                cv2.imwrite(str(demo_annotated_img_save_path), crop) #save ori_img\n",
    "                #print(demo_annotated_img_save_path)\n",
    "            except:\n",
    "                print('cannot save ',demo_annotated_img_save_path)\n",
    "            #change cropped size here  #230 to 215 410 to 390\n",
    "\n",
    "            manual_cow_count += 1\n",
    "\n",
    "    #frame = annotator.result() \n",
    "    frame = cv2.resize(ori_img, (1920,1080), interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    if has_cattle:\n",
    "        #ori_img = cv2.resize(ori_img,(1088,1088))\n",
    "        for i in range(len(b_boxes)):\n",
    "            box = b_boxes[i]\n",
    "            mask = masks[i]\n",
    "            #print(\"drawing\")\n",
    "            #print(ids)\n",
    "            \n",
    "            draw_bounding_box(ori_img,(box[0],box[1],box[2],box[3]),str(ids[i]))\n",
    "            ori_img = overlay(ori_img,mask,(0,0,255),0.3)\n",
    "        frame = cv2.resize(ori_img, (960,640), interpolation = cv2.INTER_AREA)\n",
    "        cap.write(frame)\n",
    "    \n",
    "    \n",
    "    cv2.imshow('YOLO V8 Detection', frame)\n",
    "    cv2.rectangle(frame, (100, 60), (800, 540), (0, 255, 0), 5)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(' '):\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(\"Total Duration: \",elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8ebfe1-b310-4d49-9376-cd19b2896c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()\n",
    "print(\"Total Duration: \",elapsed_time)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9584cfe2-4f0d-4187-b5dc-33c675a684e7",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### FOR DETECTION + TRACKING + IDENTIFICAION THAT WILL COME LATER\n",
    "\n",
    "X1=200 #same as NEW_BLACK_X1\n",
    "X2=400 #same as NEW_BLACK_X2 # incase of x2 out of bound\n",
    "Y1=120\n",
    "Y2=500\n",
    "SIZE =224\n",
    "Y1_NEW=120 #125  #decrease here to extend, increase to shrink \n",
    "Y2_NEW=510  #500  # redyce here to extend , increase to do vice casa 460 previous\n",
    "FRAME = 1\n",
    "\n",
    "default=640\n",
    "\n",
    "BATCH = 100\n",
    "BATCH_COUNT = 1\n",
    "PREV_BATCH = 0\n",
    "\n",
    "LAST_SEEN = time.time()\n",
    "FIRST_SEEN = True\n",
    "demo_img_save_path = []\n",
    "\n",
    "prevId_record =[]\n",
    "MAX_prevId = [] \n",
    "MAX_xyxy1 = [] \n",
    "MAX_xyxy2 = [] \n",
    "MAX_xyxy3 = [] \n",
    "MAX_xyxy4 = [] \n",
    "MAX_orgId = []\n",
    "IMAGE_STORED_LOCATION = []\n",
    "#end\n",
    "prevId_record =[]\n",
    "\n",
    "#end\n",
    "\n",
    "#region Cattle Tracking\n",
    "STORED_IDS= []\n",
    "STORED_MID_Y = []\n",
    "STORED_MID_Y1 = []\n",
    "STORED_MID_Y2 = []\n",
    "STORED_MISS = []\n",
    "PREVIOUS_ID = [] # keep the record of last seen ids and position\n",
    "PREVIOUS_Y1 = [] \n",
    "PREVIOUS_Y2 = [] \n",
    "PREVIOUS_LOCAL_IDS = []\n",
    "CATTLE_LOCAL_ID= 1\n",
    "IS_FIRST_CATTLE = True\n",
    "# Predict with the model\n",
    "project = 'D:/Python/SULarbmon/Python/env/yolov8_june/ultralytics/runs/segment/honkawa'\n",
    "name = 'predict-vgg-svm'\n",
    "dataset = \"D:\\\\815_CowDataChecking\\\\Honkawa\\\\20230730-030000-030500.mp4\"\n",
    "#save_vid_name=  dataset.split(\"\\\\\")[-1].replace('.mkv','_track')  #open this when running single video\n",
    "save_vid_name = dataset.split(\"\\\\\")[-1]+\"_track\" # open this when running multiple videos\n",
    "print(save_vid_name)\n",
    "results = model(dataset,imgsz=(1920,1080),save=False,retina_masks=False,show=False,stream=True,device='0',conf=0.3)\n",
    "#results = model('D:\\\\815_CowDataChecking\\\\20221228\\\\20221228_E_cow\\\\20221228_151533_D474.mkv',imgsz=1088,save=False,retina_masks=False,show=False,stream=True,device='0',conf=0.2)\n",
    "#save_dir = increment_path(Path(project) / name, exist_ok=True)  # increment run\n",
    "save_dir = increment_path(Path(project) / name,mkdir=True)\n",
    "#(save_dir / 'labels' if False else save_dir).mkdir(parents=True, exist_ok=True)  # make dir\n",
    "manual_cow_count = 0\n",
    "\n",
    "#cap.set(4, 480)\n",
    "save_vid_path = str(Path(os.path.join(save_dir, save_vid_name)).with_suffix('.mp4'))\n",
    "print(save_vid_path)\n",
    "cap = cv2.VideoWriter(save_vid_path,cv2.VideoWriter_fourcc(*'mp4v'), 13, (1920,1080))\n",
    "\n",
    "for result in results:\n",
    "    #print(result.boxes)\n",
    "    vid_path = result.path\n",
    "    filename = vid_path.split(\"\\\\\")[-1].replace(\".mkv\",\"\")\n",
    "    \n",
    "    \n",
    "    boxes = result.boxes.cpu().numpy()\n",
    "    ori_img = cv2.resize(result.orig_img, (1920,1088), interpolation = cv2.INTER_AREA)\n",
    "    annotator = Annotator(ori_img)\n",
    "    box_count = 0\n",
    "    cow_position = 1\n",
    "    \n",
    "    h,w = result.orig_shape\n",
    "    count = 1\n",
    "    b_boxes = []\n",
    "    masks = []\n",
    "    ids = []\n",
    "    has_cattle = False\n",
    "    if  result.masks != None:\n",
    "        \n",
    "        #result_masks = result.masks.cpu().numpy().masks.astype(bool)\n",
    "        for m in result.masks.cpu().numpy().masks.astype(bool):\n",
    "        #for i in range(1,len(result_masks)+1):\n",
    "        #for m in result.masks.masks.astype(bool):\n",
    "            xyxy = boxes[box_count].xyxy[0]\n",
    "        #   m = result_masks[-1]\n",
    "            #print(xyxy)\n",
    "            #print(m.shape)\n",
    "            box_count += 1\n",
    "            x1= int(xyxy[0])\n",
    "            y1= int(xyxy[1])\n",
    "            x2= int(xyxy[2])\n",
    "            y2= int(xyxy[3])\n",
    "\n",
    "            ################## Validate  #####################\n",
    "            if(check_withinROI_NEW(x1,y1,x2,y2,h,w)==False):\n",
    "                continue\n",
    "            #print(\"not skipped\")\n",
    "            #new_results.append(result)\n",
    "            box_left = x1\n",
    "            box_top = y1\n",
    "            box_w = x2 - x1\n",
    "            box_h = y2 - y1\n",
    "\n",
    "            new = np.zeros_like(ori_img, dtype=np.uint8)\n",
    "            new[m] = ori_img[m]\n",
    "            #masks.append(m)\n",
    "            \n",
    "            x1= int(x1 * (1088/1920))\n",
    "            x2= int(x2 * (1088/1920))\n",
    "            #y1= int(y1 * (1088/2992))\n",
    "            #y2= int(y2 * (1088/2992))\n",
    "\n",
    "            crop = new[y1:y2, x1:x2]\n",
    "            ###### LABEL\n",
    "            img = cv2.resize(crop, (SIZE, SIZE))\n",
    "            img=img / 255.0\n",
    "            label = Predict_SVM(img)\n",
    "            \n",
    "            prev_id = Take_Prev_Label(box_top,box_h,label,cow_position)\n",
    "          #########################################  \n",
    "\n",
    "\n",
    "            HAS_COW=True\n",
    "            #has_cattle = True\n",
    "            if(prev_id==-1): #skip cattle when prev_id // filter id is -1\n",
    "                if(count==1):\n",
    "                    has_seen_cattle=False\n",
    "                    count-=1\n",
    "                #print('skipped')\n",
    "                continue\n",
    "            has_cattle = True\n",
    "            ids.append(prev_id[0])\n",
    "            #print(prev_id)\n",
    "            cow_position+=1 \n",
    "            BATCH_COUNT = prev_id[0] # skip batch count here  \n",
    "            #BATCH calculator\n",
    "            \n",
    "\n",
    "            ##### save crop image for writing video\n",
    "            BATCH_COUNT = prev_id[0] # skip batch count here  \n",
    "            #BATCH calculator\n",
    "            if(FIRST_SEEN):\n",
    "                LAST_SEEN = time.time() #first seen time\n",
    "                FIRST_SEEN=False\n",
    "\n",
    "            if(time.time()-LAST_SEEN>=300): # 3 mins different\n",
    "                #write excel for each cattle\n",
    "                # print(len(prevId_record), ' previd_record', prevId_record)\n",
    "                for csv_index in range(len(prevId_record)):\n",
    "                    df = pd.DataFrame(MAX_prevId[csv_index], columns = ['ID'])\n",
    "                    try:\n",
    "                        org_ids = torch.tensor(MAX_orgId[csv_index], device = 'cpu')\n",
    "                        df[\"Original\"] = org_ids\n",
    "                    except:\n",
    "                         df[\"Original\"] = MAX_orgId[csv_index]\n",
    "\n",
    "\n",
    "                    try:\n",
    "                        stored_locations = torch.tensor(IMAGE_STORED_LOCATION[csv_index],device = 'cpu')\n",
    "                        df[\"location\"] = stored_locations\n",
    "                    except:\n",
    "                        df[\"location\"]=IMAGE_STORED_LOCATION[csv_index]\n",
    "\n",
    "                    df[\"xyxy1\"] = MAX_xyxy1[csv_index]\n",
    "                    df[\"xyxy2\"] = MAX_xyxy2[csv_index]\n",
    "                    df[\"xyxy3\"] = MAX_xyxy3[csv_index]\n",
    "                    df[\"xyxy4\"] = MAX_xyxy4[csv_index]\n",
    "\n",
    "\n",
    "\n",
    "                    now=str(datetime.now().date())\n",
    "\n",
    "                    save_csv_each_path = str(Path(save_dir / str(prevId_record[csv_index]) / f'{str(prevId_record[csv_index])}.csv'))\n",
    "                    #print(save_csv_each_path)\n",
    "\n",
    "                    df.to_csv(save_csv_each_path, index= False) ##\n",
    "                    MAX_xyxy1[csv_index]=[]\n",
    "                    MAX_xyxy2[csv_index]=[]\n",
    "                    MAX_xyxy3[csv_index]=[]\n",
    "                    MAX_xyxy4[csv_index]=[]\n",
    "                    MAX_orgId[csv_index]=[]\n",
    "                    MAX_prevId[csv_index]=[]\n",
    "                    IMAGE_STORED_LOCATION[csv_index]=[]\n",
    "\n",
    "                #print(\"new batch\")\n",
    "                prevId_record = []\n",
    "                MAX_prevId = []\n",
    "                MAX_xyxy1 = [] \n",
    "                MAX_xyxy2 = [] \n",
    "                MAX_xyxy3 = [] \n",
    "                MAX_xyxy4 = [] \n",
    "                MAX_orgId = [] \n",
    "                IMAGE_STORED_LOCATION = []\n",
    "\n",
    "\n",
    "                cattle_ids = []\n",
    "\n",
    "            LAST_SEEN = time.time()\n",
    "            \n",
    "            \n",
    "            ######\n",
    "            \n",
    "            \n",
    "            ### annotate ######\n",
    "            b = xyxy  # get box coordinates in (top, left, bottom, right) format\n",
    "            #c = box.cls\n",
    "            #annotator.box_label(b, str(prev_id[0]))\n",
    "            b_boxes.append([x1,y1,x2,y2])\n",
    "            \n",
    "\n",
    "            ###################### CREATE dir to save img\n",
    "            base_path = str(Path(save_dir / prev_id[0]))\n",
    "            if not os.path.exists(base_path):\n",
    "                os.makedirs(base_path)\n",
    "\n",
    "            LAST_SEEN = time.time()\n",
    "\n",
    "            FRAME+=1\n",
    "            #save each images for taking max label later\n",
    "            ######################################\n",
    "\n",
    "            demo_annotated_img_save_path = Path(save_dir+ '/' + f'{filename}_{str(manual_cow_count).zfill(4)}.jpg')\n",
    "            try:\n",
    "                index_prevId = prevId_record.index(int(prev_id[0]))\n",
    "                #print(index_prevId)\n",
    "                MAX_prevId[index_prevId].append(int(prev_id[0]))#,int(label[0]),xyxy)\n",
    "                MAX_xyxy1[index_prevId].append(x1)\n",
    "                MAX_xyxy2[index_prevId].append(y1)\n",
    "                MAX_xyxy3[index_prevId].append(x2)\n",
    "                MAX_xyxy4[index_prevId].append(y2)\n",
    "                MAX_orgId[index_prevId].append(int(label[0]))\n",
    "\n",
    "                IMAGE_STORED_LOCATION[index_prevId].append(demo_annotated_img_save_path)\n",
    "\n",
    "            except :\n",
    "                prevId_record.append(int(prev_id[0]))\n",
    "                # print(len(prevId_record)-1, 'prevID_record ', len(MAX_prevId) , 'max_previd' )\n",
    "\n",
    "                #MAX_prevId[len(prevId_record)-1].append(int(prev_id[0]))#,int(label[0]),xyxy)\n",
    "                #MAX_xyxy[len(MAX_prevId)-1].append(xyxy)\n",
    "                #MAX_orgId[len(MAX_prevId)-1].append(int(label[0]))\n",
    "                MAX_prevId.append([int(prev_id[0])])#,int(label[0]),xyxy)\n",
    "\n",
    "                MAX_xyxy1.append([x1])\n",
    "                MAX_xyxy2.append([y1])\n",
    "                MAX_xyxy3.append([x2])\n",
    "                MAX_xyxy4.append([y2])\n",
    "                MAX_orgId.append([int(label[0])])\n",
    "                IMAGE_STORED_LOCATION.append([demo_annotated_img_save_path])\n",
    "\n",
    "            try:\n",
    "                #demo_vid_index = demo_vid_path.index(demo_path)\n",
    "                demo_vid_index = demo_img_save_path.index(base_path)\n",
    "\n",
    "                #print(\"path exist\")\n",
    "            except:\n",
    "                #manual_summarize_ids.append(int(prev_id[0]))\n",
    "                #manual_local_ids.append(manual_id)\n",
    "                #manual_id +=1\n",
    "                demo_img_save_path.append(base_path)\n",
    "                \n",
    "            try:\n",
    "                ori_img = overlay(ori_img,m,(0,0,255),0.3)\n",
    "                cv2.imwrite(str(demo_annotated_img_save_path), ori_img) #save ori_img\n",
    "                #print(demo_annotated_img_save_path)\n",
    "            except:\n",
    "                print('cannot save ',demo_annotated_img_save_path)\n",
    "            #change cropped size here  #230 to 215 410 to 390\n",
    "\n",
    "            manual_cow_count += 1\n",
    "\n",
    "    #frame = annotator.result() \n",
    "    frame = cv2.resize(ori_img, (1080,1080), interpolation = cv2.INTER_AREA)\n",
    "    if has_cattle:\n",
    "        #ori_img = cv2.resize(ori_img,(1088,1088))\n",
    "        for i in range(len(b_boxes)):\n",
    "            box = b_boxes[i]\n",
    "            #mask = masks[i]\n",
    "            prev_id = ids[i]\n",
    "            draw_bounding_box(ori_img,(box[0],box[1],box[2],box[3]),str(prev_id))\n",
    "            #ori_img = overlay(ori_img,mask,(0,0,255),0.3)\n",
    "        frame = cv2.resize(ori_img, (1080,1080), interpolation = cv2.INTER_AREA)\n",
    "        cap.write(frame)\n",
    "    \n",
    "    \n",
    "    cv2.imshow('YOLO V8 Detection', frame)     \n",
    "    if cv2.waitKey(1) & 0xFF == ord(' '):\n",
    "        break\n",
    "\n",
    "###### write final csv\n",
    "for csv_index in range(len(prevId_record)):\n",
    "    df = pd.DataFrame(MAX_prevId[csv_index] , columns = ['ID'])\n",
    "    try:\n",
    "        org_ids = torch.tensor(MAX_orgId[csv_index], device = 'cpu')\n",
    "        df[\"Original\"] = org_ids\n",
    "    except:\n",
    "        df[\"Original\"] = MAX_orgId[csv_index]\n",
    "\n",
    "    try:\n",
    "        stored_locations = torch.tensor(IMAGE_STORED_LOCATION[csv_index],device = 'cpu')\n",
    "        df[\"location\"] = stored_locations\n",
    "    except:\n",
    "        df[\"location\"]=IMAGE_STORED_LOCATION[csv_index]\n",
    "    df[\"xyxy1\"] = MAX_xyxy1[csv_index]\n",
    "    df[\"xyxy2\"] = MAX_xyxy2[csv_index]\n",
    "    df[\"xyxy3\"] = MAX_xyxy3[csv_index]\n",
    "    df[\"xyxy4\"] = MAX_xyxy4[csv_index]\n",
    "\n",
    "\n",
    "    now=str(datetime.now().date())\n",
    "\n",
    "    save_csv_each_path = str(Path(save_dir / str(prevId_record[csv_index]) / f'{str(prevId_record[csv_index])}.csv'))\n",
    "    df.to_csv(save_csv_each_path, index= False)##asdfasdf\n",
    "prevId_record = []\n",
    "MAX_prevId = []\n",
    "MAX_xyxy1 = [] \n",
    "MAX_xyxy2 = [] \n",
    "MAX_xyxy3 = [] \n",
    "MAX_xyxy4 = [] \n",
    "MAX_orgId = [] \n",
    "IMAGE_STORED_LOCATION = []\n",
    "\n",
    "cattle_ids = []\n",
    "#################################\\\n",
    "manual_summarize_ids = []\n",
    "manual_local_ids = []\n",
    "\n",
    "manual_summarize_ids = []\n",
    "manual_local_ids = []\n",
    "#### write video after saving csv\n",
    "final_cattle_count = 1\n",
    "\n",
    "cap.release() #tracking video\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "save_vid_name=  dataset.split(\"\\\\\")[-1].replace('.mkv','')+'_classification'\n",
    "save_vid_path = str(Path(os.path.join(save_dir, save_vid_name)).with_suffix('.mp4'))\n",
    "classification_vid = cv2.VideoWriter(save_vid_path,cv2.VideoWriter_fourcc(*'mp4v'), 13, (1080,1080))\n",
    "\n",
    "for loc in range(len(demo_img_save_path)):\n",
    "    print(demo_img_save_path[loc])\n",
    "    final_cattle_id = writeVideo(classification_vid,demo_img_save_path[loc])\n",
    "    if(final_cattle_id != -1):\n",
    "        manual_local_ids.append(final_cattle_count)\n",
    "        manual_summarize_ids.append(final_cattle_id)\n",
    "        final_cattle_count+=1 \n",
    "\n",
    "classification_vid.release() #tracking video\n",
    "print(save_vid_path)\n",
    "#### write video after saving csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ee745d-1e26-4f99-aeb7-a454fce0698c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78864315-f639-44bd-8c69-6a9454f9e098",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"D:\\\\815_CowDataChecking\\\\20220704\\\\20220704_M_Cow\" #don't add \\\\ at the end\n",
    "#save_vid_name=  dataset.split(\"\\\\\")[-1].replace('.mkv','_track')  #open this when running single video\n",
    "save_vid_name = dataset.split(\"\\\\\")[-1] # open this when running multiple videos\n",
    "print(save_vid_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fe5233-4b20-4570-a9fc-312d3a591930",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
