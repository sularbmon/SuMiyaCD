{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5099ec81-b427-40ee-bd81-671d3f5b6941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://youtu.be/9GzfUzJeyi0\n",
    "\n",
    "\"\"\"\n",
    "@author: Sreenivas Bhattiprolu\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "#from keras.layers.normalization import BatchNormalization\n",
    "import os\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f669d5-b254-4061-a946-bdadd09de6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "total_classes=0  #to change when mee lay want to add more cows\n",
    "#images_per_validation=5\n",
    "\n",
    "\n",
    "#print(os.listdir(\"../Gold\"))\n",
    "\n",
    "SIZE = 224\n",
    "\n",
    "import csv\n",
    "\n",
    "#data = pd.read_csv('D:\\\\LamenessData\\\\September_6\\\\evening.csv',index_col ='Local_ID')\n",
    "\n",
    "#COW_MAPPER = [list(row) for row in data.values]\n",
    "\n",
    "train_images = []\n",
    "train_labels = [] \n",
    "for directory_path in glob.glob(\"D:\\LamenessData\\September_6\\DataByGroup\\\\AllCows\\\\Training/*\"):\n",
    "    label = directory_path.split(\"\\\\\")[-1]\n",
    "    #print(label)\n",
    "    total_classes+=1\n",
    "    for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n",
    "        #print(img_path)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)       \n",
    "        \n",
    "        \n",
    "        img = cv2.resize(img, (SIZE, SIZE))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        train_images.append(img)\n",
    "        train_labels.append(label)\n",
    "        \n",
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "print(total_classes)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7571ec9-6ec6-4988-96e9-34e42f05eb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# test\n",
    "test_images = []\n",
    "test_labels = [] \n",
    "images_per_validation =[]\n",
    "for directory_path in glob.glob(\"D:\\LamenessData\\September_6\\DataByGroup\\\\AllCows\\\\Validation/*\"):  #to change when baby add new images\n",
    "    fruit_label = directory_path.split(\"\\\\\")[-1]\n",
    "    count=0\n",
    "    for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        img = cv2.resize(img, (SIZE, SIZE))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        test_images.append(img)\n",
    "        test_labels.append(fruit_label)\n",
    "        count+=1\n",
    "    images_per_validation.append(count)\n",
    "        \n",
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)\n",
    "#Encode labels from text to integers.\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(test_labels)\n",
    "test_labels_encoded = le.transform(test_labels)\n",
    "le.fit(train_labels)\n",
    "train_labels_encoded = le.transform(train_labels)\n",
    "print(\"Train lables encoded is here\")\n",
    "#print(train_labels_encoded)\n",
    "#Split data into test and train datasets (already split but assigning to meaningful convention)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7255eec1-2f46-4204-85af-3af189cc6446",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train, y_train, x_test, y_test = train_images, train_labels_encoded, test_images, test_labels_encoded\n",
    "\n",
    "###################################################################\n",
    "# Normalize pixel values to between 0 and 1\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "#One hot encode y values for neural network. \n",
    "from keras.utils import to_categorical\n",
    "y_train_one_hot = to_categorical(y_train)\n",
    "y_test_one_hot = to_categorical(y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7f24d8-42da-4406-8399-c1b2431404f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#############################\n",
    "#Load model wothout classifier/fully connected layers\n",
    "VGG_model = VGG16(weights='imagenet', include_top=False, input_shape=(SIZE, SIZE, 3))\n",
    "\n",
    "#Make loaded layers as non-trainable. This is important as we want to work with pre-trained weights\n",
    "for layer in VGG_model.layers:\n",
    "\tlayer.trainable = False\n",
    "    \n",
    "VGG_model.summary()  #Trainable parameters will be 0\n",
    "\n",
    "\n",
    "#Now, let us use features from convolutional network for RF\n",
    "feature_extractor=VGG_model.predict(x_train)\n",
    "\n",
    "features = feature_extractor.reshape(feature_extractor.shape[0], -1)\n",
    "\n",
    "\n",
    "X_for_RF = features #This is our X input to RF\n",
    "\n",
    "print(\"generated featured\")\n",
    "\n",
    "#############################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421c47c0-1f19-4c39-9a28-c108de490015",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ytrain_name_filename = 'May_Weights/Y_TRAIN_V1.pkl'\n",
    "features_filename = 'May_Weights/GENERAL_FEATURES_v1.pkl'\n",
    "y_train = pickle.load(open(ytrain_name_filename, 'rb'))\n",
    "features = pickle.load(open(features_filename, 'rb'))\n",
    "#le = pickle.load(open(le_filename, 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79ded78-6e95-46d8-9354-b73779f561c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "x_train = pickle.load(open('../June_Weights_HOG/GENERAL_X_TRAIN.pkl','rb'))\n",
    "y_train = pickle.load(open('../June_Weights_HOG/GENERAL_Y_TRAIN.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3156a0-aa2f-4808-979b-5ac21bfbe0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "lgb_train = lgb.Dataset(x_train, y_train)\n",
    "\n",
    "# Set LightGBM parameters\n",
    "params = {\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': 146,  # Replace 'num_classes' with the actual number of classes in your dataset\n",
    "    'metric': 'multi_logloss',\n",
    "}\n",
    "\n",
    "# Train the LightGBM model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8bbcc9-675a-4b15-a291-f88f6a8f5458",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = lgb.train(params, lgb_train, num_boost_round=100)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6eaa0d4-78eb-4e5e-b44b-7d2dc5c13742",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model_name ='../June_Weights_HOG/HOG_LIGHTGBM.pkl'\n",
    "pickle.dump(model,open(model_name,'wb'))\n",
    "\n",
    "print(\"done\")\n",
    "\n",
    "\n",
    "#########################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5052d22c-6951-41ca-b4f3-0f74b0f21e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG_model.save('May_Weights/GENERAL_VGG_v1.h5')\n",
    "\n",
    "\n",
    "le_filename = 'May_Weights/GENERAL_LABEL_v1.le'\n",
    "pickle.dump(le, open(le_filename, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b8addb-f384-4e57-adec-a56cd3beb79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_filename = 'May_Weights/GENERAL_FEATURES_v1.pkl'\n",
    "pickle.dump(features, open(features_filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bed6af-8bd0-4387-a5a1-f2156a0fb914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b09e7c-7501-4528-a3dc-41db5c21e92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load modelsavedModels\n",
    "#vgg_filename = 'vgg16_model.sav'\n",
    "#svm_filename ='svm.sav'\n",
    "#VGG_model = pickle.load(open(vgg_filename, 'rb'))\n",
    "#clf = pickle.load(open(svm_filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56ed492-0342-4565-91cf-2be02cffeacd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d34cb07-e050-4e68-9f50-0d2513f48518",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c4b1d2-7456-4dcf-9199-7de099d2833b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead9d88d-25c3-4ac2-841b-89a4fdcf97f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "0e361806-ec6a-4626-81ac-c039c4880bbb",
   "metadata": {},
   "source": [
    "One Class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db7f014-2f41-455a-b2bc-bf7bcf77e612",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run second part here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e73ce4b-15df-4b26-9c96-f38a47d7db37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9f10cc-ca66-4801-9d45-c8adb2e777ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ipkernel_launcher.py --source \"D:\\Python\\env\\Lameness\\Frames\\Videos\\20220201_145508_7108.mp4\"  --yolo-weights weights_slm/best_6_23_gpu.pt --view-img --save-crop --device 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5139acf2-ee9e-4f49-a18a-7e106c993efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#python -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7debfd9a-a80d-46f8-8cc7-862b4a779647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfd271f-3b94-4b68-b067-a7962a2c36f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21048563-d565-4833-97c1-879c8471da0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X_For_RF) ## print me"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
