{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5099ec81-b427-40ee-bd81-671d3f5b6941",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This ipynb is using Yolov5_VGG_SVM , taking first frame from the start\n",
    "#taking first frame and all frame to calculate the max show ups cattle id\n",
    "#No black box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f669d5-b254-4061-a946-bdadd09de6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://youtu.be/9GzfUzJeyi0\n",
    "\n",
    "\"\"\"\n",
    "@author: Sreenivas Bhattiprolu\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "#from keras.layers.normalization import BatchNormalization\n",
    "import os\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "\n",
    "total_classes=0  #to change when mee lay want to add more cows\n",
    "#images_per_validation=5\n",
    "\n",
    "\n",
    "#print(os.listdir(\"../Gold\"))\n",
    "\n",
    "SIZE = 224\n",
    "\n",
    "import csv\n",
    "\n",
    "#data = pd.read_csv('D:\\\\LamenessData\\\\September_6\\\\evening.csv',index_col ='Local_ID')\n",
    "\n",
    "#COW_MAPPER = [list(row) for row in data.values]\n",
    "\n",
    "train_images = []\n",
    "train_labels = [] \n",
    "for directory_path in glob.glob(\"D:\\LamenessData\\September_6\\DataByGroup\\\\AllCows\\\\Training/*\"):\n",
    "    label = directory_path.split(\"\\\\\")[-1]\n",
    "    #print(label)\n",
    "    total_classes+=1\n",
    "    for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n",
    "        #print(img_path)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)       \n",
    "        \n",
    "        \n",
    "        img = cv2.resize(img, (SIZE, SIZE))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        train_images.append(img)\n",
    "        train_labels.append(label)\n",
    "        \n",
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "print(total_classes)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7571ec9-6ec6-4988-96e9-34e42f05eb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# test\n",
    "test_images = []\n",
    "test_labels = [] \n",
    "images_per_validation =[]\n",
    "for directory_path in glob.glob(\"D:\\LamenessData\\September_6\\DataByGroup\\\\AllCows\\\\Validation/*\"):  #to change when baby add new images\n",
    "    fruit_label = directory_path.split(\"\\\\\")[-1]\n",
    "    count=0\n",
    "    for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        img = cv2.resize(img, (SIZE, SIZE))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        test_images.append(img)\n",
    "        test_labels.append(fruit_label)\n",
    "        count+=1\n",
    "    images_per_validation.append(count)\n",
    "        \n",
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)\n",
    "#Encode labels from text to integers.\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(test_labels)\n",
    "test_labels_encoded = le.transform(test_labels)\n",
    "le.fit(train_labels)\n",
    "train_labels_encoded = le.transform(train_labels)\n",
    "print(\"Train lables encoded is here\")\n",
    "#print(train_labels_encoded)\n",
    "#Split data into test and train datasets (already split but assigning to meaningful convention)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7255eec1-2f46-4204-85af-3af189cc6446",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train, y_train, x_test, y_test = train_images, train_labels_encoded, test_images, test_labels_encoded\n",
    "\n",
    "###################################################################\n",
    "# Normalize pixel values to between 0 and 1\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "#One hot encode y values for neural network. \n",
    "from keras.utils import to_categorical\n",
    "y_train_one_hot = to_categorical(y_train)\n",
    "y_test_one_hot = to_categorical(y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7f24d8-42da-4406-8399-c1b2431404f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#############################\n",
    "#Load model wothout classifier/fully connected layers\n",
    "VGG_model = VGG16(weights='imagenet', include_top=False, input_shape=(SIZE, SIZE, 3))\n",
    "\n",
    "#Make loaded layers as non-trainable. This is important as we want to work with pre-trained weights\n",
    "for layer in VGG_model.layers:\n",
    "\tlayer.trainable = False\n",
    "    \n",
    "VGG_model.summary()  #Trainable parameters will be 0\n",
    "\n",
    "\n",
    "#Now, let us use features from convolutional network for RF\n",
    "feature_extractor=VGG_model.predict(x_train)\n",
    "\n",
    "features = feature_extractor.reshape(feature_extractor.shape[0], -1)\n",
    "\n",
    "\n",
    "X_for_RF = features #This is our X input to RF\n",
    "\n",
    "print(\"generated featured\")\n",
    "\n",
    "#############################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8a040e9-fd48-448b-b11d-55b48f3c9c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "x_train = pickle.load(open('../June_Weights_HOG/GENERAL_X_TRAIN.pkl','rb'))\n",
    "y_train = pickle.load(open('../June_Weights_HOG/GENERAL_Y_TRAIN.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df3156a0-aa2f-4808-979b-5ac21bfbe0d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#RANDOM FOREST\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[0;32m      3\u001b[0m RF_model \u001b[38;5;241m=\u001b[39m RandomForestClassifier(n_estimators \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m300\u001b[39m, random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m72\u001b[39m) \u001b[38;5;66;03m#75-68%  #100 86%  #72-93%\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefined rf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\ensemble\\__init__.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mThe :mod:`sklearn.ensemble` module includes ensemble-based methods for\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mclassification, regression and anomaly detection.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseEnsemble\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_forest\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_forest\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestRegressor\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\ensemble\\_base.py:18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseEstimator\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MetaEstimatorMixin\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     19\u001b[0m     DecisionTreeRegressor,\n\u001b[0;32m     20\u001b[0m     BaseDecisionTree,\n\u001b[0;32m     21\u001b[0m     DecisionTreeClassifier,\n\u001b[0;32m     22\u001b[0m )\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Bunch, _print_elapsed_time, deprecated\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_random_state\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\tree\\__init__.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mThe :mod:`sklearn.tree` module includes decision tree-based models for\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mclassification and regression.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_classes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseDecisionTree\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_classes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DecisionTreeClassifier\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_classes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DecisionTreeRegressor\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\tree\\_classes.py:42\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_is_fitted\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Hidden, Interval, StrOptions\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_criterion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Criterion\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_splitter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Splitter\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DepthFirstTreeBuilder\n",
      "File \u001b[1;32msklearn\\tree\\_criterion.pyx:1\u001b[0m, in \u001b[0;36minit sklearn.tree._criterion\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msklearn\\tree\\_splitter.pyx:1\u001b[0m, in \u001b[0;36minit sklearn.tree._splitter\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msklearn\\tree\\_tree.pyx:1\u001b[0m, in \u001b[0;36minit sklearn.tree._tree\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neighbors\\__init__.py:17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_kde\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KernelDensity\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lof\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LocalOutlierFactor\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_nca\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NeighborhoodComponentsAnalysis\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sort_graph_by_row_values\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VALID_METRICS, VALID_METRICS_SPARSE\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\neighbors\\_nca.py:19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseEstimator, TransformerMixin, ClassNamePrefixFeaturesOutMixin\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecomposition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PCA\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmulticlass\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_classification_targets\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrandom\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_random_state\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\decomposition\\__init__.py:16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_incremental_pca\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IncrementalPCA\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_kernel_pca\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KernelPCA\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sparse_pca\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparsePCA, MiniBatchSparsePCA\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_truncated_svd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TruncatedSVD\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fastica\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FastICA, fastica\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\decomposition\\_sparse_pca.py:13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Hidden, Interval, StrOptions\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_array, check_is_fitted\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ridge_regression\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseEstimator, TransformerMixin, ClassNamePrefixFeaturesOutMixin\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dict_learning\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dict_learning, MiniBatchDictionaryLearning\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\__init__.py:37\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_stochastic_gradient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SGDClassifier, SGDRegressor, SGDOneClassSVM\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ridge\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Ridge, RidgeCV, RidgeClassifier, RidgeClassifierCV, ridge_regression\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_logistic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression, LogisticRegressionCV\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_omp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     39\u001b[0m     orthogonal_mp,\n\u001b[0;32m     40\u001b[0m     orthogonal_mp_gram,\n\u001b[0;32m     41\u001b[0m     OrthogonalMatchingPursuit,\n\u001b[0;32m     42\u001b[0m     OrthogonalMatchingPursuitCV,\n\u001b[0;32m     43\u001b[0m )\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_passive_aggressive\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PassiveAggressiveClassifier\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:29\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_loss\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HalfBinomialLoss, HalfMultinomialLoss\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder, LabelBinarizer\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msvm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _fit_liblinear\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_array, check_consistent_length, compute_class_weight\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_random_state\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\svm\\__init__.py:13\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mThe :mod:`sklearn.svm` module includes Support Vector Machine algorithms.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# See http://scikit-learn.sourceforge.net/modules/svm.html for complete\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# documentation.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#         of their respective owners.\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# License: BSD 3 clause (C) INRIA 2010\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_classes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SVC, NuSVC, SVR, NuSVR, OneClassSVM, LinearSVC, LinearSVR\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bounds\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m l1_min_c\n\u001b[0;32m     16\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLinearSVC\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLinearSVR\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml1_min_c\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     25\u001b[0m ]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\svm\\_classes.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumbers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Integral, Real\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _fit_liblinear, BaseSVC, BaseLibSVM\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseEstimator, RegressorMixin, OutlierMixin\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearClassifierMixin, SparseCoefMixin, LinearModel\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\svm\\_base.py:12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _libsvm \u001b[38;5;28;01mas\u001b[39;00m libsvm  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _liblinear \u001b[38;5;28;01mas\u001b[39;00m liblinear  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _libsvm_sparse \u001b[38;5;28;01mas\u001b[39;00m libsvm_sparse  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseEstimator, ClassifierMixin\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:398\u001b[0m, in \u001b[0;36mparent\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#RANDOM FOREST\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF_model = RandomForestClassifier(n_estimators = 300, random_state = 72) #75-68%  #100 86%  #72-93%\n",
    "print(\"defined rf\")\n",
    "# Train the model on training data\n",
    "RF_model.fit(x_train, y_train) #For sklearn no one hot encoding\n",
    "print(\"RF_model.fit is done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c4aa6b-421d-4ebc-a007-4e705aa28bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_filename ='../June_Weights_HOG/HOG_RF.pkl'\n",
    "pickle.dump(RF_model,open(rf_filename,'wb'))\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231d175d-2d70-46cd-84d6-18a0556674c9",
   "metadata": {},
   "source": [
    "#SVM\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( features, \n",
    "                                                     labels, \n",
    "                                                     test_size=0.30)\n",
    "                                         \n",
    "    \n",
    "#clf = LinearSVC(random_state=21, tol=0.0005,max_iter=1500) #rs=10 maxiter=500  tol=0.01   # SVM\n",
    "#clf = CalibratedClassifierCV(clf)  #added\n",
    "#clf.fit(X_for_RF, y_train)  # SVM\n",
    "\n",
    "\n",
    "#print(x_test.shape)\n",
    "#x_test_svm=x_test.reshape(32786,256)\n",
    "#x_test_svm = (x_test.reshape(x_test.shape[0], x_test.shape[1] * x_test.shape[2] * x_test.shape[3]))\n",
    "#target_x = (target_x.reshape(target_x.shape[0], target_x.shape[1] * target_x.shape[2] * target_x.shape[3]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61abc1a0-93dc-41a4-813f-0d1ba28efb88",
   "metadata": {},
   "source": [
    "X_test_feature = VGG_model.predict(x_test)\n",
    "X_test_features = X_test_feature.reshape(X_test_feature.shape[0], -1)\n",
    "\n",
    "#prediction_SVM = clf.predict(X_test_features)\n",
    "\n",
    "#print(prediction_SVM)\n",
    "# get the accuracy\n",
    "from sklearn import metrics\n",
    "#print (\"Accuracy = \", metrics.accuracy_score(test_labels, prediction_SVM))\n",
    "#added to save prediction RF \n",
    "import pandas as pd\n",
    "#pd.DataFrame(prediction_SVM, columns=['predictions']).to_csv('csv/prediction_SVM_vgg_sep_26_epochs.csv')\n",
    "\n",
    "#Print overall accuracy\n",
    "#from sklearn import metrics\n",
    "#print (\"Accuracy = \", metrics.accuracy_score(test_labels, prediction_SVM))\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Confusion Matrix - verify accuracy of each class\n",
    "#cm = confusion_matrix(test_labels, prediction_SVM)\n",
    "#print(cm)\n",
    "#sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6eaa0d4-78eb-4e5e-b44b-7d2dc5c13742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#saving VGG and SVM trained models\n",
    "\n",
    "VGG_model.save('May_Weights/VGG_KNN/all_cows_vgg_v1.h5')\n",
    "\n",
    "\n",
    "le_filename = 'May_Weights/VGG_KNN/all_cows_le_v1.le'\n",
    "pickle.dump(le, open(le_filename, 'wb'))\n",
    "\n",
    "knn_filename ='May_Weights/VGG_KNN/all_cows_KNN_v1.pkl'\n",
    "pickle.dump(knn,open(knn_filename,'wb'))\n",
    "\n",
    "print(\"done\")\n",
    "\n",
    "\n",
    "#########################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5052d22c-6951-41ca-b4f3-0f74b0f21e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG_model.save('May_Weights/GENERAL_VGG_v1.h5')\n",
    "\n",
    "\n",
    "le_filename = 'May_Weights/GENERAL_LABEL_v1.le'\n",
    "pickle.dump(le, open(le_filename, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b8addb-f384-4e57-adec-a56cd3beb79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_filename = 'May_Weights/GENERAL_FEATURES_v1.pkl'\n",
    "pickle.dump(features, open(features_filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72ddc38-56e6-4193-81e0-511cc98989d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain_name_filename = 'May_Weights/Y_TRAIN_V1.pkl'\n",
    "pickle.dump(y_train, open(ytrain_name_filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bed6af-8bd0-4387-a5a1-f2156a0fb914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b09e7c-7501-4528-a3dc-41db5c21e92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load modelsavedModels\n",
    "#vgg_filename = 'vgg16_model.sav'\n",
    "#svm_filename ='svm.sav'\n",
    "#VGG_model = pickle.load(open(vgg_filename, 'rb'))\n",
    "#clf = pickle.load(open(svm_filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56ed492-0342-4565-91cf-2be02cffeacd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d34cb07-e050-4e68-9f50-0d2513f48518",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c4b1d2-7456-4dcf-9199-7de099d2833b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "644361be-3126-4072-8cc9-2f204949cc0e",
   "metadata": {},
   "source": [
    "#testing OneClass VGG\n",
    "from sklearn.svm import OneClassSVM\n",
    "outlier_fraction = 0.028\n",
    "RANDOM_STATE = 123\n",
    "\n",
    "known_images = []\n",
    "known_labels = [\"known\"]\n",
    "all_directory_path = \"D:\\\\Research\\\\Datasets\\\\cow_datasets_227_only\\\\all\\\\\"\n",
    "for img_path in glob.glob(os.path.join(all_directory_path, \"*.jpg\")):\n",
    "    #print(img_path)\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_COLOR)       \n",
    "    img = cv2.resize(img, (SIZE, SIZE))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    known_images.append(img)\n",
    "    \n",
    "print(len(known_images))\n",
    "    \n",
    "known_images = np.array(known_images)\n",
    "known_lables = np.array(known_labels)\n",
    "known_images = known_images / 255.0\n",
    "\n",
    "#print(known_images)\n",
    "\n",
    "VGG_model_OneClass = VGG16(weights='imagenet', include_top=False, input_shape=(SIZE, SIZE, 3))\n",
    "\n",
    "#Make loaded layers as non-trainable. This is important as we want to work with pre-trained weights\n",
    "for layer in VGG_model_OneClass.layers:\n",
    "\tlayer.trainable = False\n",
    "    \n",
    "VGG_model_OneClass.summary()  #Trainable parameters will be 0\n",
    "\n",
    "\n",
    "#Now, let us use features from convolutional network for RF\n",
    "oc_featureExtractor=VGG_model_OneClass.predict(known_images)\n",
    "\n",
    "oc_features = oc_featureExtractor.reshape(oc_featureExtractor.shape[0], -1)\n",
    "\n",
    "X_for_oneclass = oc_features #This is our X input to RF\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead9d88d-25c3-4ac2-841b-89a4fdcf97f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "faf11fe2-7883-49d9-bf10-78dfe3e3e386",
   "metadata": {},
   "source": [
    "#testing IsolationForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "# generate dataset\n",
    "#X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,\n",
    "\t#n_clusters_per_class=1, weights=[0.999], flip_y=0, random_state=4)\n",
    "# split into train/test sets\n",
    "#trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=2, stratify=y)\n",
    "# define outlier detection model\n",
    "IsoF_model = IsolationForest(contamination=0.1)\n",
    "# fit on majority class\n",
    "#trainX = trainX[trainy==0]\n",
    "IsoF_model.fit(X_for_RF)\n",
    "# detect outliers in the test set\n",
    "#yhat = model.predict(testX)\n",
    "# mark inliers 1, outliers -1\n",
    "#testy[testy == 1] = -1\n",
    "#testy[testy == 0] = 1\n",
    "# calculate score\n",
    "#score = f1_score(testy, yhat, pos_label=-1)\n",
    "#print('F1 Score: %.3f' % score)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "90cbd003-dd2c-492c-9df8-78516719348e",
   "metadata": {},
   "source": [
    "def Isolation_Forest(img):\n",
    "    input_img = np.expand_dims(img, axis=0) #Expand dims so the input is (num images, x, y, c)\n",
    "    oc_input_img_feature=VGG_model_OneClass.predict(input_img)\n",
    "    oc_input_img_features=oc_input_img_feature.reshape(oc_input_img_feature.shape[0], -1)\n",
    "    predicted_result = IsoF_model.predict(oc_input_img_features)[0]\n",
    "    #probs_svc = (decision - decision.min()) / (decision.max() - decision.min())\n",
    "    \n",
    "    #print(predicted_result)\n",
    "    #prediction =  IsoF_model.predict_proba(oc_input_img_features)\n",
    "    #print(\"decision function \" + str(decision))\n",
    "    print( \" prediction \"+ str(predicted_result))\n",
    "    return predicted_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e3c3b5-475f-498e-a685-3942135afa0e",
   "metadata": {},
   "source": [
    "def Predict_SVM(image):  ## new with vgg\n",
    "    \n",
    "#Check results on a few select images\n",
    "    #n=np.random.randint(0, x_test.shape[0])\n",
    "    img = image\n",
    "\n",
    "    #plt.imshow(img)\n",
    "    input_img = np.expand_dims(img, axis=0) #Expand dims so the input is (num images, x, y, c)\n",
    "    input_img_feature=VGG_model.predict(input_img)\n",
    "    input_img_features=input_img_feature.reshape(input_img_feature.shape[0], -1)\n",
    "    prediction_RF = clf.predict(input_img_features)[0] \n",
    "    prediction_RF = le.inverse_transform([prediction_RF])  #Reverse the label encoder to original name\n",
    "    #label = [str(COW_MAPPER[int(prediction_RF)][0])]\n",
    "    print(\"The prediction for this image is: \", prediction_RF)\n",
    "    #predict_proba= clf.predict_proba(input_img_features)\n",
    "    #print(predict_proba)\n",
    "    #print(\"max predict value is \"+str(predict_proba.max()) )\n",
    "    \n",
    "    #decision_svc= clf.predict_proba(input_img_features)\n",
    "    #probs_svc = (decision_svc - decision_svc.min()) / (decision_svc.max() - decision_svc.min())\n",
    "    #print(\"decision probability \"+str(probs_svc))\n",
    "    \n",
    "    return prediction_RF\n",
    "print(\"defined RF new VGG SVM\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0e361806-ec6a-4626-81ac-c039c4880bbb",
   "metadata": {},
   "source": [
    "One Class SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fc4ee7-489c-438b-a635-bb757e1120aa",
   "metadata": {},
   "source": [
    "#testing OneClass VGG\n",
    "from sklearn.svm import OneClassSVM\n",
    "outlier_fraction = 0.028\n",
    "RANDOM_STATE = 123\n",
    "\n",
    "known_images = []\n",
    "known_labels = [\"known\"]\n",
    "all_directory_path = \"C:/Users/thithilab/Python/SULarbmon/Python/Datasets/cow_datasets/all/\"\n",
    "for img_path in glob.glob(os.path.join(all_directory_path, \"*.jpg\")):\n",
    "    #print(img_path)\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_COLOR)       \n",
    "    img = cv2.resize(img, (SIZE, SIZE))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    known_images.append(img)\n",
    "    \n",
    "print(len(known_images))\n",
    "    \n",
    "known_images = np.array(known_images)\n",
    "known_lables = np.array(known_labels)\n",
    "known_images = known_images / 255.0\n",
    "\n",
    "#print(known_images)\n",
    "\n",
    "VGG_model_OneClass = VGG16(weights='imagenet', include_top=False, input_shape=(SIZE, SIZE, 3))\n",
    "\n",
    "#Make loaded layers as non-trainable. This is important as we want to work with pre-trained weights\n",
    "for layer in VGG_model_OneClass.layers:\n",
    "\tlayer.trainable = False\n",
    "    \n",
    "VGG_model_OneClass.summary()  #Trainable parameters will be 0\n",
    "\n",
    "\n",
    "#Now, let us use features from convolutional network for RF\n",
    "oc_featureExtractor=VGG_model_OneClass.predict(known_images)\n",
    "\n",
    "oc_features = oc_featureExtractor.reshape(oc_featureExtractor.shape[0], -1)\n",
    "\n",
    "X_for_oneclass = oc_features #This is our X input to RF\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2293981c-1ca2-454e-a98b-956988792086",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One class SVM\n",
    "#model =  OneClassSVM(nu=0.1, degree=3, kernel='rbf',gamma='scale')\n",
    "#data_new_clean = known_images.loc[known_images.total_count <=known_images.total_count.quantile(1-outlier_fraction)]\n",
    "#model.fit(X_for_oneclass)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "65db305a-ff94-492f-9828-0862d7bc0a05",
   "metadata": {},
   "source": [
    "def isKnownCattle (image):\n",
    "    input_img = np.expand_dims(image, axis=0) #Expand dims so the input is (num images, x, y, c)\n",
    "    oc_input_img_feature=VGG_model_OneClass.predict(input_img)\n",
    "    oc_input_img_features=oc_input_img_feature.reshape(oc_input_img_feature.shape[0], -1)\n",
    "    decision = model.decision_function(oc_input_img_features)\n",
    "    probs_svc = (decision - decision.min()) / (decision.max() - decision.min())\n",
    "    print(probs_svc)\n",
    "    prediction =  model.predict(oc_input_img_features)\n",
    "    print(\"decision function \" + str(decision))\n",
    "    print( \" prediction \"+ str(prediction))\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7080613c-3de4-4517-93a0-f0d51cc64ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "STORED_IDS= []\n",
    "STORED_MID_Y = []\n",
    "STORED_MISS = []\n",
    "PREVIOUS_ID = [] # keep the record of last seen ids and position\n",
    "PREVIOUS_Y = [] \n",
    "PREVIOUS_LOCAL_IDS = []\n",
    "LOCAL_ID= 1000\n",
    "\n",
    "def Take_Prev_Label(y,h,id,cow_srno):\n",
    "    global STORED_IDS\n",
    "    global STORED_MID_Y\n",
    "    global STORED_MISS\n",
    "    global LAST_SEEN_IDS\n",
    "    global LAST_SEEN_ID_CENTROIDS\n",
    "    global LOCAL_ID\n",
    "    \n",
    "    mid_y = int(2*y + h)/2\n",
    "    IS_NEW = True\n",
    "    \n",
    "    #print('cow_srno',cow_srno,' original id ',id)\n",
    "    #updatedID = Is_Duplicate_Id(mid_y,id)\n",
    "    #if(updatedID!=id):\n",
    "    #    print('orgID: ',id,' updated ID: ',updatedID)\n",
    "    #id=updatedID\n",
    "    #clear old records \n",
    "    if(len(STORED_IDS)>0):\n",
    "        #print('removed ',STORED_IDS[0])\n",
    "        #del STORED_MISS[0]\n",
    "        #del STORED_MID_Y[0]\n",
    "        \n",
    "        #del STORED_IDS[0]\n",
    "        #STORED_MISS= STORED_MISS[1:]\n",
    "        #STORED_MID_Y= STORED_MID_Y[1:]\n",
    "        #STORED_IDS= STORED_IDS[1:]\n",
    "        #print(STORED_MISS)\n",
    "        MISSED_LEN = len(STORED_MISS)\n",
    "        #if(IS_NEW):\n",
    "        \n",
    "        #    MISSED_LEN -=1\n",
    "        removed = 0\n",
    "        for i in range(MISSED_LEN):\n",
    "            #print(i, ' missed index checking' )\n",
    "            missed = STORED_MISS[i-removed]\n",
    "            #print('checking ',i-removed, 'to remove')\n",
    "            if(missed>7 and len(STORED_MISS)>0): #if missed 35 frames\n",
    "                #print('removed ID',STORED_IDS[i-removed])\n",
    "                #print('removed MID_Y',STORED_MID_Y[i-removed])\n",
    "                #print('removed STORED_ID',STORED_IDS[i-removed])\n",
    "                del STORED_MISS[i-removed]  \n",
    "                del STORED_MID_Y[i-removed]\n",
    "                del STORED_IDS[i-removed]\n",
    "                removed+=1\n",
    "                #print('removed')\n",
    "                \n",
    "    #clear misses\n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(1,len(STORED_MID_Y)+1):\n",
    "        #print(STORED_IDS[-i-1],STORED_MID_Y[-i-1],' ',i)\n",
    "        if(STORED_MID_Y[-i]+70>=mid_y and STORED_MID_Y[-i]-200<=mid_y): # and IS_NEW): #previous 150 #200\n",
    "            if(IS_NEW):\n",
    "                print('mid_y ',mid_y,'existing y ',STORED_MID_Y[-i])\n",
    "                print('all mid_y ',STORED_MID_Y) \n",
    "                IS_NEW = False\n",
    "                STORED_MID_Y[-i] = mid_y\n",
    "                STORED_MISS[-i]=1\n",
    "                id= STORED_IDS[-i]\n",
    "                print(id)\n",
    "            \n",
    "            #try:\n",
    "            #    exist_index = LAST_SEEN_IDS.index(id)\n",
    "            #    if(LAST_SEEN_ID_CENTROIDS[exist_index]+200>y): # showing old id\n",
    "            #        LAST_SEEN_ID_CENTROIDS[exist_index] = y\n",
    "            #except:\n",
    "            #print('corrected id :',STORED_IDS[-i])\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "                \n",
    "        #elif(cow_srno==1):\n",
    "        else:\n",
    "            STORED_MISS[-i]+=1\n",
    "                \n",
    "                \n",
    "    #print(STORED_IDS,' IDS ',STORED_MID_Y,' SMY ',mid_y,' mid_y')\n",
    "    if(IS_NEW):\n",
    "        #print('SMY: ',STORED_MID_Y,', new my:',mid_y) \n",
    "        #print('new id: ',id)\n",
    "        STORED_IDS.append(id)\n",
    "        STORED_MID_Y.append(mid_y)\n",
    "        STORED_MISS.append(1)\n",
    "    \n",
    "    #print('returned id :',id)\n",
    "    return id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04e79fa-89b0-4a18-9748-07c69e56ff30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_most_cattle_id():\n",
    "    global current_cow\n",
    "    global excel_cow_count\n",
    "    global final_result\n",
    "    global fial_total\n",
    "    global final_percentage\n",
    "    maxpos = excel_cow_count.index(max(excel_cow_count))\n",
    "    #or i in range (len(current_cow)):\n",
    "    #   print('cattle ',current_cow[i],' id is ',excel_cow_count[i] , ' count(s)')\n",
    "    cattle_id = current_cow[maxpos]\n",
    "    \n",
    "    final_total.append(sum(excel_cow_count))\n",
    "    final_percentage.append(max(excel_cow_count)/sum(excel_cow_count))\n",
    "    final_result.append(cattle_id)\n",
    "    excel_cow_count = [] #reset\n",
    "    current_cow = [] #reset\n",
    "    \n",
    "\n",
    "def Generate_Cattle_Id_By_Apperance(csv_path,save_dir):\n",
    "    print(csv_path, \" is csv_path and \", save_dir , \" is save_dir\")\n",
    "\n",
    "    data = pd.read_csv(csv_path)\n",
    "\n",
    "    list_of_csv = [list(row) for row in data.values]\n",
    "    global  final_result \n",
    "    global final_percentage\n",
    "    global final_total\n",
    "    global current_cow\n",
    "    global excel_cow_count\n",
    "    prev=None\n",
    "\n",
    "\n",
    "\n",
    "    for i in range (len(list_of_csv)):\n",
    "        #rint('from ',list_of_csv[i][1],' to ',list_of_csv[i][0])\n",
    "        filtered_id = list_of_csv[i][0]\n",
    "        actual_id = list_of_csv[i][1]\n",
    "        if(prev!=filtered_id):\n",
    "            if(prev is not None):\n",
    "                calculate_most_cattle_id()\n",
    "            prev = filtered_id\n",
    "\n",
    "        try: \n",
    "            index = current_cow.index(actual_id)\n",
    "            #print('I reached here')\n",
    "            excel_cow_count[index]+=1\n",
    "        except:\n",
    "            current_cow.append(actual_id)\n",
    "            excel_cow_count.append(1)\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(final_result, columns = [\"ID\"])\n",
    "    try:\n",
    "        final_percentage = torch.tensor(final_percentage, device = 'cpu')\n",
    "        final_total = torch.tensor(final_total, device = 'cpu')\n",
    "\n",
    "        df[\"total\"] = final_total\n",
    "        df[\"percentage\"] = final_percentage\n",
    "    except:\n",
    "        df[\"total\"] = final_total\n",
    "        df[\"percentage\"] = final_percentage\n",
    "    now=str(datetime.now().date())\n",
    "\n",
    "    df.to_csv(save_dir+\"/MaxCattleId_ \"+now+'.csv', index= False)\n",
    "    print(\"successfully saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29b96bd-1eda-436f-b806-3fcc1f4dda91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def writeVideo(filePath):\n",
    "    img_array = []\n",
    "    size = (0,0)\n",
    "    for filename in glob.glob(filePath+'/*.jpg'):\n",
    "        img = cv2.imread(filename)\n",
    "        print(filename)\n",
    "        height, width, layers = img.shape\n",
    "        size = (width,height)\n",
    "        img_array.append(img)\n",
    "    \n",
    "    vid_name = os.path.basename(os.path.normpath(filePath))\n",
    "    vid_path = str(Path(filePath + \"/\" + vid_name ).with_suffix('.mp4'))\n",
    "    \n",
    "    \n",
    "    \n",
    "    out = cv2.VideoWriter(vid_path,cv2.VideoWriter_fourcc(*'mp4v'), 6, size)\n",
    "    \n",
    "    for ind in range(len(img_array)):\n",
    "        out.write(img_array[ind])\n",
    "    out.release()\n",
    "    print(\"done \", vid_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa4bb81-65fc-4aa4-a41e-08a2f48ad939",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%%python --source \"D:\\Python\\env\\Lameness\\Frames\\Videos\\20220201_145508_7108.mp4\"  --yolo-weights weights_slm/best_6_23_gpu.pt --view-img --save-crop --device 0\n",
    "\n",
    "\n",
    "# YOLOv5 🚀 by Ultralytics, GPL-3.0 license\n",
    "\"\"\"\n",
    "Run inference on images, videos, directories, streams, etc.\n",
    "\n",
    "Usage - sources:\n",
    "    $ python path/to/detect.py --weights yolov5s.pt --source 0              # webcam\n",
    "                                                             img.jpg        # image\n",
    "                                                             vid.mp4        # video\n",
    "                                                             path/          # directory\n",
    "                                                             path/*.jpg     # glob\n",
    "                                                             'https://youtu.be/Zgi9g1ksQHc'  # YouTube\n",
    "                                                             'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream\n",
    "\n",
    "Usage - formats:\n",
    "    $ python path/to/detect.py --weights yolov5s.pt                 # PyTorch\n",
    "                                         yolov5s.torchscript        # TorchScript\n",
    "                                         yolov5s.onnx               # ONNX Runtime or OpenCV DNN with --dnn\n",
    "                                         yolov5s.xml                # OpenVINO\n",
    "                                         yolov5s.engine             # TensorRT\n",
    "                                         yolov5s.mlmodel            # CoreML (macOS-only)\n",
    "                                         yolov5s_saved_model        # TensorFlow SavedModel\n",
    "                                         yolov5s.pb                 # TensorFlow GraphDef\n",
    "                                         yolov5s.tflite             # TensorFlow Lite\n",
    "                                         yolov5s_edgetpu.tflite     # TensorFlow Edge TPU\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import imutils\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import math\n",
    "from collections import deque\n",
    "import cv2\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "FILE = Path(\"__file__\").resolve()\n",
    "ROOT = FILE.parents[0]  # YOLOv5 root directory\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))  # add ROOT to PATH\n",
    "ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative\n",
    "print(ROOT)\n",
    "from models.common import DetectMultiBackend\n",
    "from utils.dataloaders import IMG_FORMATS, VID_FORMATS, LoadImages, LoadStreams\n",
    "from utils.general import (LOGGER, check_file, check_img_size, check_imshow, check_requirements, colorstr, cv2,\n",
    "                           increment_path, non_max_suppression, print_args, scale_coords, strip_optimizer, xyxy2xywh)\n",
    "from utils.plots import Annotator, colors, save_one_box\n",
    "from utils.torch_utils import select_device, time_sync\n",
    "\n",
    "from datetime import datetime\n",
    "from timer import Timer\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "X1=240\n",
    "X2=400\n",
    "Y1=94\n",
    "Y2=590\n",
    "\n",
    "\n",
    "default=640\n",
    "save_video=True\n",
    "file_location=\"D:\\\\815_CowDataChecking\\\\20221119\\\\1119_E_all\"\n",
    "#file_location = \"\\\\172.16.4.111\\\\Public\\\\訓子府L5G_2020\\生データ　original data\\\\360カメラ\\\\A\\\\20220907\\\\13\"\n",
    "\n",
    "\n",
    "#file_location=\"D:\\\\815_CowDataChecking\\\\20220906\\\\360\\A\\\\20220906\\\\13\\\\20220906_135955_2249_ACCC8EEE85E1\\\\20220906_16\\\\20220906_161102_E42D.mkv\"\n",
    "#file_location = \"C:\\\\Users\\\\thithilab\\\\Desktop\\\\Cow Data (22~28)\\\\20220722\\\\all\\\\20220722_152539_53E5.mkv\"\n",
    "#filename=\"20220705_135955_4D30\"\n",
    "file_path = \"D:\\\\CheckFrame\\\\file_path.txt\"\n",
    "deep_test ='C:/Users/thithilab/Desktop/20220705/m_videos_5_7/DEEP1/DEEP2'\n",
    "multifile = 'D:/CheckFrame/14B8/20220704_145523_14B8.mkv,C:/Users/thithilab/Desktop/20220705/m_videos_5_7/20220705_053512_A9B0.mkv'\n",
    "#Y1_NEW=110\n",
    "#Y2_NEW=530\n",
    "Y1_NEW=95  #decrease here to extend, increase to shrink \n",
    "Y2_NEW=430  # redyce here to extend , increase to do vice casa\n",
    "\n",
    "Y1_PRECISE=100\n",
    "Y2_PRECISE=400  #where cow is most precise  August 7 2022\n",
    "HAS_COW=False  # to save video when has cow\n",
    "\n",
    "cow_order=[]\n",
    "cow_count = []\n",
    "cow_label=[]\n",
    "frame_rate=3\n",
    " \n",
    "prev_label_store=[None] * 5\n",
    "prev_cow_position=[None] * 5\n",
    "\n",
    "\n",
    "all_detected_cow=[]\n",
    "\n",
    "local_id=1\n",
    "\n",
    "\n",
    "#for max apperance cattle id \n",
    "final_result = []\n",
    "final_percentage = []\n",
    "final_total = []\n",
    "current_cow = []\n",
    "excel_cow_count=[]\n",
    "#end\n",
    "\n",
    "#demo video write\n",
    "BATCH = 100\n",
    "BATCH_COUNT = 1\n",
    "PREV_BATCH = 0\n",
    "LAST_SEEN = time.time()\n",
    "FIRST_SEEN = True\n",
    "demo_img_save_path = []\n",
    "#end\n",
    "\n",
    "def DoROI(image):\n",
    "    h,w,c = image.shape\n",
    "    img_arr = np.array(image)\n",
    "    img_arr[0 : int(94*(h/default)), 0 : h] = (0, 0, 0)   #top\n",
    "    img_arr[0 : h, 0 : int(240*(w/default))] = (0, 0, 0)   #left\n",
    "    img_arr[0 : h, int(400*(w/default)) : w] = (0, 0, 0)   #right\n",
    "    img_arr[int(590*(h/default)) : h,0 : w] = (0, 0, 0)   #bottom\n",
    "    return img_arr\n",
    "\n",
    "def Demo_DoROI(image):\n",
    "    h,w,c = image.shape\n",
    "    img_arr = np.array(image)\n",
    "    #img_arr[0 : int(94*(h/default)), 0 : h] = (0, 0, 0)   #top\n",
    "    img_arr[0 : h, 0 : int(230*(w/default))] = (0, 0, 0)   #left\n",
    "    img_arr[0 : h, int(410*(w/default)) : w] = (0, 0, 0)   #right\n",
    "    #img_arr[int(590*(h/default)) : h,0 : w] = (0, 0, 0)   #bottom\n",
    "    return img_arr\n",
    "\n",
    "\n",
    "def DoROI_640(image):\n",
    "    img_arr = np.array(image)\n",
    "    img_arr[0 : 94, 0 : 640] = (0, 0, 0)   #top\n",
    "    img_arr[0 : 640, 0 : 240] = (0, 0, 0)   #left\n",
    "    img_arr[0 : 640, 400 : 640] = (0, 0, 0)   #right\n",
    "    img_arr[590 : 640,0 : 640] = (0, 0, 0)   #bottom\n",
    "    return img_arr\n",
    "  \n",
    "def check_withinROI(x1,y1,x2,y2,h,w):\n",
    "    if(x1<int(X1*(w/default)) or x2>int(X2*(w/default)) or y1<int(Y1*(h/default)) or y2>int(Y2*(h/default)) or x1>=int(X2*(w/default))):\n",
    "      return False\n",
    "    return True  \n",
    "\n",
    "def check_withinROI_NEW(x1,y1,x2,y2,h,w):\n",
    "    if(x1<int(X1*(w/default)) or x2>int(X2*(w/default)) or y1<int(Y1_NEW*(h/default)) or y2>int(Y2_NEW*(h/default)) or x1>=int(X2*(w/default))):\n",
    "      return False\n",
    "    return True  \n",
    "\n",
    "def check_withinROI_PRECISE(x1,y1,x2,y2,h,w):\n",
    "    if(x1<int(X1*(w/default)) or x2>int(X2*(w/default)) or y1<int(Y1_PRECISE*(h/default)) or y2>int(Y2_PRECISE*(h/default)) or x1>=int(X2*(w/default))):\n",
    "      return False\n",
    "    return True  \n",
    "\n",
    "def check_cow_Count(label):\n",
    "    global cow_label\n",
    "    global cow_count\n",
    "    print(\"inserting label\")\n",
    "    if label in cow_label: #check exist\n",
    "        cow_count[cow_label.index(label)]+=1  #start counting of the newly inserted cow\n",
    "        \n",
    "    else:\n",
    "        cow_label.append(label)  # if not exist then add the cow label to array\n",
    "        cow_count.append(1)  #start counting of the newly inserted cow\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def determine_label(img):\n",
    "    \n",
    "    #if Isolation_Forest(img) != 1:\n",
    "    #    res = ['unknown']\n",
    "    #    check_cow_Count(res[0])\n",
    "    #    return res\n",
    "    global all_detected_cow\n",
    "    label = Predict_SVM(img)\n",
    "    HAS_COW=True\n",
    "    check_cow_Count(label[0])\n",
    "    all_detected_cow.append(label[0])\n",
    "    return label\n",
    "\n",
    "#label for cow label, y for y2 postion of cow, h for total height if image, position for 1st cow of the frame, 2nd cow of the frame etc,...\n",
    "def take_first_appear_lable(label,y,h,nth_cows):\n",
    "    \n",
    "    global prev_label_store\n",
    "    global prev_cow_position\n",
    "    \n",
    "\n",
    "    #prev_label_length = len(prev_label_store)\n",
    "    #prev_position_length = len(prev_label_store)\n",
    "    #print(prev_label_length)\n",
    "    \n",
    "    #first\n",
    "    print(\"cow position :\"+str(nth_cows))\n",
    "    print(\"label \"+label)\n",
    "    if(prev_label_store[nth_cows]==None and prev_label_store[nth_cows+1]==None):\n",
    "        prev_label_store[nth_cows]=label\n",
    "        prev_cow_position[nth_cows]=y\n",
    "        res = [label]\n",
    "        return res\n",
    "        \n",
    "    if(prev_label_store[nth_cows]!=None):\n",
    "        if(y<prev_cow_position[nth_cows]+35) : #check if prev_cow\n",
    "            prev_cow_position[nth_cows]=y\n",
    "            res = [prev_label_store[nth_cows] ]\n",
    "            return res\n",
    "        elif(prev_cow_position[nth_cows+1]!=None and y<prev_cow_position[nth_cows+1]+35) : #check if prev_cow second cow \n",
    "            #2nd one become 1st cow\n",
    "            prev_cow_position[nth_cows]=None\n",
    "            prev_label_store[nth_cows]=None\n",
    "            \n",
    "            prev_label_store = deque(prev_label_store)\n",
    "            prev_label_store(1)\n",
    "            prev_label_store = list(prev_label_store)\n",
    "            \n",
    "            \n",
    "            prev_cow_position = deque(prev_cow_position)\n",
    "            prev_cow_position(1)\n",
    "            prev_cow_position = list(prev_cow_position)\n",
    "            \n",
    "            \n",
    "            prev_cow_position[nth_cows]=y\n",
    "            res = [prev_label_store[nth_cows]]\n",
    "            return res  #move 2nd index to first index\n",
    "        elif(prev_cow_position[nth_cows+1] == None) : #new cows in first place\n",
    "            prev_cow_position[nth_cows]=y\n",
    "            prev_label_store[nth_cows] = label\n",
    "            res = [label]\n",
    "            return res\n",
    "           \n",
    "    res = [label]\n",
    "    return res\n",
    "    \n",
    "    \n",
    "    \n",
    "prev_labels=[]  #keep last records to compare y pixel value    \n",
    "prev_y1s=[]    \n",
    "\n",
    "\n",
    "def compare_with_prev_cow(label,y,h):\n",
    "    prev_labels.append(label)\n",
    "    prev_y1s.append(y)\n",
    "    has_100_record = len(prev_labels)\n",
    "    start = 0\n",
    "    end = 0\n",
    "    ceiling = h-int(h*(Y1_NEW/default))\n",
    "    #print(ceiling )\n",
    "    #print(h)\n",
    "    #print(y)\n",
    "    if(y+100>=ceiling) :   #checking if the image reach the top\n",
    "        if has_100_record>=20:\n",
    "            start=has_100_record - 20 - 1 #only check last 20 values\n",
    "            end = has_100_record - 1\n",
    "        cow_count_c=[]\n",
    "        cow_label_c=[]\n",
    "        prev_y_value=y\n",
    "        total_frames=0\n",
    "        global cow_order\n",
    "        for i in range(end,start,-1):\n",
    "            if(prev_y1s[i]>=h/2 +50 ):  #check only for half of screen\n",
    "                #for l in range(len(label[i].split(',')):\n",
    "                #split_label = label[i].split(',')[l]\n",
    "                #if split_label in cow_label: #check exist\n",
    "                if(prev_y1s[i]>prev_y_value):\n",
    "                    prev_y_value=prev_y1s[i] #go with 30 pixel different\n",
    "                    total_frames += 1\n",
    "                    if prev_labels[i] in cow_label_c:\n",
    "                        cow_count_c[cow_label_c.index(prev_labels[i])]+=1  #start counting of the newly inserted cow\n",
    "        \n",
    "                    else:\n",
    "                        cow_label_c.append(prev_labels[i])  # if not exist then add the cow label to array\n",
    "                        cow_count_c.append(1)  #start counting of the newly inserted cow\n",
    "                #else:\n",
    "                    \n",
    "                \n",
    "        #prediction_RF = np.argmax(prop)         \n",
    "        #get max cow id\n",
    "        if(len(cow_count_c)<1):\n",
    "            return None\n",
    "        max_count = max(cow_count_c)\n",
    "        threshold_50_percent = math.floor(total_frames*0.5)\n",
    "        if(max_count>threshold_50_percent + 1):\n",
    "            index = np.argmax(cow_count_c)\n",
    "            cow_order.append(cow_label_c[index])\n",
    "            print(\" cow label \"+str(cow_label_c[index]))\n",
    "            return cow_label_c[index]\n",
    "        else:\n",
    "            print(\" cow label unknown\")\n",
    "            cow_order.append(\"unknown\")\n",
    "            return \"unknown\"\n",
    "    \n",
    "    if(len(prev_y1s) >700): # delete first 500 when greater than 800\n",
    "        del prev_labels[:500]\n",
    "        del prev_y1s[:500]    \n",
    "         \n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def run(\n",
    "    \n",
    "        weights=ROOT / 'Sept_no_alien_weight_v1/best.pt',  # model.pt path(s)  #july_weight\n",
    "        source=ROOT / file_location,  #file_location,  # file/dir/URL/glob, 0 for webcam\n",
    "        data=ROOT / 'data/coco128.yaml',  # dataset.yaml path\n",
    "        imgsz=(640, 640),  # inference size (height, width)\n",
    "        conf_thres=0.60,  # confidence threshold\n",
    "        iou_thres=0.45,  # NMS IOU threshold\n",
    "        max_det=1000,  # maximum detections per image\n",
    "        device='0',  # cuda device, i.e. 0 or 0,1,2,3 or cpu\n",
    "        view_img=True,  # show results\n",
    "        save_txt=False,  # save results to *.txt\n",
    "        save_conf=False,  # save confidences in --save-txt labels\n",
    "        save_crop=True,  # save cropped prediction boxes\n",
    "        nosave=False,  # do not save images/videos\n",
    "        classes=None,  # filter by class: --class 0, or --class 0 2 3\n",
    "        agnostic_nms=False,  # class-agnostic NMS\n",
    "        augment=False,  # augmented inference\n",
    "        visualize=False,  # visualize features\n",
    "        update=False,  # update all models\n",
    "        project=ROOT / 'runs/detect_SVM_NV_demo_center',  # save results to project/name\n",
    "        name='exp_'+str(frame_rate)+'_fps',  # save results to project/name\n",
    "        exist_ok=False,  # existing project/name ok, do not increment\n",
    "        line_thickness=8,  # bounding box thickness (pixels)\n",
    "        hide_labels=False,  # hide labels\n",
    "        hide_conf=False,  # hide confidences\n",
    "        half=False,  # use FP16 half-precision inference\n",
    "        dnn=False,  # use OpenCV DNN for ONNX inference\n",
    "    \n",
    "):\n",
    "    \n",
    "    global all_detected_cow\n",
    "    global frame_rate\n",
    "    #added\n",
    "    sec=0\n",
    "    global cow_lable\n",
    "    global cow_count\n",
    "    global cow_order\n",
    "    global FIRST_SEEN\n",
    "    global BATCH\n",
    "    global BATCH_COUNT\n",
    "    global PREV_BATCH\n",
    "    global LAST_SEEN\n",
    "    global demo_img_save_path\n",
    "    cow_id = []\n",
    "    cow_id_original =[]\n",
    "    cow_top = []\n",
    "    cow_left = []\n",
    "    cow_width = []\n",
    "    cow_height = []\n",
    "    cow_score = []\n",
    "    cow_frame = []\n",
    "    \n",
    "    manual_summarize_ids = []\n",
    "    manual_local_ids = []\n",
    "    manual_id = 1\n",
    "    \n",
    "    read_after_frame = 1\n",
    "    manual_cow_count = 1\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    cf = 0  \n",
    "    count=0\n",
    "    \n",
    "    source = str(source)\n",
    "    #vid_path = []\n",
    "    #vid_path.append(\"D:\\\\CheckFrame\\\\14B8\")\n",
    "    #vid_path.append(source)\n",
    "    #source = vid_path\n",
    "    #save_img = not nosave and not source.endswith('.txt')  # save inference images\n",
    "    #added\n",
    "    save_img=True\n",
    "    \n",
    "    is_file = Path(source).suffix[1:] in (IMG_FORMATS + VID_FORMATS)\n",
    "    is_url = source.lower().startswith(('rtsp://', 'rtmp://', 'http://', 'https://'))\n",
    "    webcam = source.isnumeric() or source.endswith('.txt') or (is_url and not is_file)\n",
    "    if is_url and is_file:\n",
    "        source = check_file(source)  # download\n",
    "\n",
    "    # Directories\n",
    "    save_dir = increment_path(Path(project) / name, exist_ok=exist_ok)  # increment run\n",
    "    print(save_dir)\n",
    "    csv_save_dir = str(save_dir)\n",
    "    print(csv_save_dir)\n",
    "    (save_dir / 'labels' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # make dir\n",
    "\n",
    "    \n",
    "    \n",
    "    # Load model\n",
    "    device = select_device(device)\n",
    "    model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=half)\n",
    "    stride, names, pt = model.stride, model.names, model.pt\n",
    "    imgsz = check_img_size(imgsz, s=stride)  # check image size\n",
    "\n",
    "    # Dataloader\n",
    "    if webcam and False:\n",
    "        view_img = check_imshow()\n",
    "        cudnn.benchmark = True  # set True to speed up constant image size inference\n",
    "        dataset = LoadStreams(source, img_size=imgsz, stride=stride, auto=pt)\n",
    "        bs = len(dataset)  # batch_size\n",
    "    else:\n",
    "        dataset = LoadImages(source, img_size=imgsz, stride=stride, auto=pt)\n",
    "        bs = 1  # batch_size\n",
    "    vid_path, vid_writer = [None] * bs, [None] * bs\n",
    "    \n",
    "    demo_vid_path ,demo_vid_writer = [] ,[None]  * 12\n",
    "    \n",
    "    demo_vid_save_path = str(save_dir)\n",
    "\n",
    "    # Run inference\n",
    "    model.warmup(imgsz=(1 if pt else bs, 3, *imgsz))  # warmup\n",
    "    dt, seen = [0.0, 0.0, 0.0], 0\n",
    "    #frame_rate = 4    #frame rate here\n",
    "    prev = 0\n",
    "    prev_frame = 0\n",
    "    for path, im, im0s, vid_cap, s in dataset:\n",
    "        #print(path)\n",
    "        #cv2.waitKey(1000) #1 fps   1000/ value =fps\n",
    "        #vidcap.set(cv2.CAP_PROP_POS_MSEC,sec*1000) \n",
    "        #vid_cap.set(cv2.CV_CAP_PROP_FPS, 1)\n",
    "        #vid_cap.set(cv2.CAP_PROP_FPS, 1)\n",
    "        \n",
    "        HAS_COW=False\n",
    "        t1 = time_sync()\n",
    "        im = torch.from_numpy(im).to(device)\n",
    "        im = im.half() if model.fp16 else im.float()  # uint8 to fp16/32\n",
    "        im /= 255  # 0 - 255 to 0.0 - 1.0\n",
    "        if len(im.shape) == 3:\n",
    "            im = im[None]  # expand for batch dim\n",
    "        t2 = time_sync()\n",
    "        dt[0] += t2 - t1\n",
    "        \n",
    "        # Inference\n",
    "        visualize = increment_path(save_dir / Path(path).stem, mkdir=True) if visualize else False\n",
    "        pred = model(im, augment=augment, visualize=visualize)\n",
    "        t3 = time_sync()\n",
    "        dt[1] += t3 - t2\n",
    "\n",
    "        # NMS\n",
    "        pred = non_max_suppression(pred, conf_thres, iou_thres, classes, agnostic_nms, max_det=max_det)\n",
    "        dt[2] += time_sync() - t3\n",
    "        \n",
    "        # Second-stage classifier (optional)\n",
    "        # pred = utils.general.apply_classifier(pred, classifier_model, im, im0s)\n",
    "\n",
    "        # Process predictions\n",
    "        #time_elapsed = time.time() - prev\n",
    "    \n",
    "\n",
    "        #if time_elapsed > 1/frame_rate:\n",
    "            #prev = time.time()\n",
    "            #print(\"Greater\")\n",
    "            #print(prev)\n",
    "        #else:\n",
    "            #print(\"break\")\n",
    "            #continue\n",
    "        \n",
    "        if (read_after_frame-prev_frame == 0):\n",
    "            prev_frame=0\n",
    "            continue\n",
    "        prev_frame +=1\n",
    "        for i, det in enumerate(pred):  # per image\n",
    "           \n",
    "            #det = det.sort(key=lambda row: (row[1]))\n",
    "            #print(time_elapsed)\n",
    "            \n",
    "            seen += 1\n",
    "            if webcam:  # batch_size >= 1\n",
    "                p, im0, frame = path[i], im0s[i].copy(), dataset.count\n",
    "                s += f'{i}: '\n",
    "            else:\n",
    "                p, im0, frame = path, im0s.copy(), getattr(dataset, 'frame', 0)\n",
    "            \n",
    "            #added ROI    \n",
    "            #h,w,c=im0.shape\n",
    "            \n",
    "            #resize\n",
    "            #if(w>640 or h>640):\n",
    "            #  im0=imutils.resize(im0, width = 640)\n",
    "            \n",
    "            \n",
    "            \n",
    "            #check containing frame here\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            #end of checking containing frame\n",
    "            \n",
    "            \n",
    "\n",
    "            #ROI\n",
    "            im0=Demo_DoROI(im0)\n",
    "            h,w,c=im0.shape\n",
    "            \n",
    "            \n",
    "            p = Path(p)  # to Path\n",
    "            save_path = str(save_dir / p.name)  # im.jpg\n",
    "            txt_path = str(save_dir / 'labels' / p.stem) + ('' if dataset.mode == 'image' else f'_{frame}')  # im.txt\n",
    "            s += '%gx%g ' % im.shape[2:]  # print string\n",
    "            gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh\n",
    "            imc = im0.copy() if save_crop else im0  # for save_crop\n",
    "            annotator = Annotator(im0, line_width=line_thickness, example=str(names))\n",
    "            if len(det):\n",
    "                # Rescale boxes from img_size to im0 size\n",
    "                det[:, :4] = scale_coords(im.shape[2:], det[:, :4], im0.shape).round()\n",
    "                #det.sort(key=lambda row: (row[1][0]))\n",
    "                #print(det)\n",
    "                det, b = torch.sort(det, dim=0)\n",
    "                #print('sorted',det)\n",
    "                # Print results\n",
    "                for c in det[:, -1].unique():\n",
    "                    n = (det[:, -1] == c).sum()  # detections per class\n",
    "                    s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \"  # add to string\n",
    "                \n",
    "                \n",
    "                \n",
    "                # Write results\n",
    "                cow_position = 0\n",
    "                counter = 0\n",
    "                \n",
    "                for *xyxy, conf , cls in (det):#reversed(det):\n",
    "                    if(check_withinROI_NEW(xyxy[0],xyxy[1],xyxy[2],xyxy[3],h,w)):\n",
    "                      #print(\"valid image\")\n",
    "                      count+=1\n",
    "                 \n",
    "                        \n",
    "                      #BATCH calculator\n",
    "                      if(FIRST_SEEN):\n",
    "                        LAST_SEEN = time.time() #first seen time\n",
    "                        FIRST_SEEN=False\n",
    "                \n",
    "                \n",
    "                      if(time.time()-LAST_SEEN>=300): # 3 mins different\n",
    "                        BATCH += 100\n",
    "                        BATCH_COUNT += 1\n",
    "                        cattle_ids = []\n",
    "                        print(len(det))\n",
    "                        LAST_SEEN = time.time()\n",
    "                        #release video write and reset vid_path\n",
    "                        \n",
    "                        #for index in range(len(demo_vid_path)):\n",
    "                            \n",
    "                        #    if isinstance(demo_vid_writer[index], cv2.VideoWriter):\n",
    "                        #        demo_vid_writer[index].release()  # release previous video writer\n",
    "                        #        print('removed video write ', demo_vid_path[index])\n",
    "                        \n",
    "                        #demo_vid_path = []\n",
    "                        #demo_img_save_path = []\n",
    "                        #end\n",
    "                        \n",
    "                    \n",
    "                      box_left = xyxy[0]\n",
    "                      box_top = xyxy[1]\n",
    "                      box_w = xyxy[2] - xyxy[0]\n",
    "                      box_h = xyxy[3] - xyxy[1]\n",
    "                      #cow_left.append(box_left)\n",
    "                      #cow_top.append(box_top)\n",
    "                      #cow_width.append(box_w)\n",
    "                      #cow_height.append(box_h)\n",
    "                      #cow_score.append(conf)\n",
    "                      #cow_frame.append(seen)\n",
    "                     \n",
    "                      #feed on cnn and get label\n",
    "                      #save_one_box(xyxy, imc, file=save_dir / 'crops' / names[c] / f'{p.stem}_{count}.jpg', BGR=True)\n",
    "                      \n",
    "                      #crop\n",
    "                      BGR=False\n",
    "                      #print(\"step-3-y\")\n",
    "                      crop = im0[int(xyxy[1]):int(xyxy[3]), int(xyxy[0]):int(xyxy[2])]\n",
    "                      #frame_crop = im0[0 : h,int(200*(w/default)):int(540*(w/default))] \n",
    "                      \n",
    "\n",
    "                      #cropped = torch.tensor(crop, device = 'cpu')\n",
    "                      #image = Image.fromarray(crop)\n",
    "                      #img = image.resize((128, 128), Image.ANTIALIAS)\n",
    "                      \n",
    "                    \n",
    "                      #do some process like testing data in cnn\n",
    "                      img = cv2.resize(crop, (SIZE, SIZE))\n",
    "                      img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "                      #cv2.imshow('detected cow',img)\n",
    "                      if cv2.waitKey(1) == ord('a'):  # q to quit\n",
    "                          raise StopIteration\n",
    "                      #crop=imutils.resize(crop, width = 224)\n",
    "                      img=img / 255.0\n",
    "                      label = Predict_SVM(img)\n",
    "                      #label = determine_label(img)\n",
    "                      #isknown = isKnownCattle(img) #for unknown\n",
    "                      #print(isknown)\n",
    "                      HAS_COW=True\n",
    "                      prev_id = Take_Prev_Label(box_top,box_h,label,cow_position)\n",
    "                      cow_position+=1\n",
    "                      #label = Predict_SVM_test_pro(img)\n",
    "                      cow_id.append(prev_id[0])\n",
    "                      cow_id_original.append(int(label[0]))\n",
    "                      #check cow count here\n",
    "                      h,w,c=im0.shape  \n",
    "                      #final_label = compare_with_prev_cow(label[0],int(xyxy[3]),h)\n",
    "                      #label = take_first_appear_lable(label[0],int(xyxy[3]),h,cow_position) #remove\n",
    "                      #print(im0.shape)\n",
    "                      #if(isknown[0] == -1): #open when doing unknonw\n",
    "                      #  label = ['unknown']\n",
    "                      #print(label)\n",
    "                      #if final_label != None: print(\"final label \"+ final_label)\n",
    "                      annotator.box_label(xyxy,prev_id[0], color=(15, 0, 255))#color=colors(c, True))\n",
    "                      #if save_txt:  # Write to file\n",
    "                      #    xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh\n",
    "                      #    line = (cls, *xywh, conf) if save_conf else (cls, *xywh)  # label format\n",
    "                      #    with open(f'{txt_path}.txt', 'a') as f:\n",
    "                      #        f.write(('%g ' * len(line)).rstrip() % line + '\\n')\n",
    "\n",
    "                      #if save_img or save_crop or view_img:  # Add bbox to image\n",
    "                      #    c = int(cls)  # integer class\n",
    "                      #    #label = None if hide_labels else (names[c] if hide_conf else f'{names[c]} {conf:.2f}')  #original\n",
    "                      #    annotator.box_label(xyxy, label, color=colors(c, True))\n",
    "                      \n",
    "                      if save_crop:\n",
    "                           save_one_box(xyxy, imc, file=save_dir /  str(BATCH_COUNT)  / prev_id[0]  / 'cropped' / f'{p.stem}.jpg', BGR=True)\n",
    "                      # change by cattle id here\n",
    "                      #demo_vid_index= 0\n",
    "                      #demo_path = str(Path(str(save_dir)+\"/\"+str(BATCH_COUNT)+\"/\"+prev_id[0]).with_suffix('.mp4'))\n",
    "                      \n",
    "                      #save_one_box(xyxy, im0, file=save_dir / str(BATCH_COUNT) / prev_id[0]  / 'cropped' / f'{p.stem}.jpg', BGR=True)\n",
    "                      annotated_img = annotator.result()\n",
    "                      annotated_img = annotated_img[0 : h,int(230*(w/default)):int(410*(w/default))] \n",
    "                      #fps, fw, fh = 6, annotated_img.shape[1], annotated_img.shape[0] \n",
    "                      #print('width ',fw,' height ',fh)\n",
    "                      base_path = str(Path(save_dir / str(BATCH_COUNT) / prev_id[0]))\n",
    "                      demo_annotated_img_save_path = Path(base_path+ '/' + f'{p.stem}_{str(manual_cow_count).zfill(4)}.jpg')\n",
    "                      #print(demo_annotated_img_save_path)\n",
    "                      #save_one_box(xyxy, imc, file = base_path / prev_id[0]  / f'{p.stem}.jpg', BGR=True)\n",
    "                      cv2.imwrite(demo_annotated_img_save_path, annotated_img)\n",
    "                      \n",
    "                    \n",
    "                      try:\n",
    "                        #demo_vid_index = demo_vid_path.index(demo_path)\n",
    "                        demo_vid_index = demo_img_save_path.index(base_path)\n",
    "                        \n",
    "                        #print(\"path exist\")\n",
    "                      except:\n",
    "                        manual_summarize_ids.append(int(prev_id[0]))\n",
    "                        manual_local_ids.append(manual_id)\n",
    "                        manual_id +=1\n",
    "                        #demo_vid_path.append(demo_path)\n",
    "                        #print(base_path)\n",
    "                        #print('vid path is new ')\n",
    "                        demo_img_save_path.append(base_path)\n",
    "                        #demo_vid_index = len(demo_vid_path) -1\n",
    "                        #demo_vid_writer[demo_vid_index]=(cv2.VideoWriter(demo_vid_path[demo_vid_index], cv2.VideoWriter_fourcc(*'mp4v'),6, (fw, fh)))\n",
    "                        \n",
    "                     \n",
    "                      write_demo_vide=False\n",
    "                      if write_demo_vide :  \n",
    "                        \n",
    "                        \n",
    "                        print('vid index is ', demo_vid_index, ' location is ', demo_vid_path[demo_vid_index])\n",
    "                        print(annotated_img.shape)\n",
    "                        if isinstance(demo_vid_writer[demo_vid_index], cv2.VideoWriter):\n",
    "                            demo_vid_writer[demo_vid_index].write(annotated_img)\n",
    "                      \n",
    "                      manual_cow_count +=1\n",
    "\n",
    "\n",
    "            # Stream results\n",
    "            im0 = annotator.result()\n",
    "            if view_img or True:\n",
    "                \n",
    "                if(w>1080 or h>1080):\n",
    "                    cv2.imshow('detected cows', imutils.resize(im0, width = 1080,height=720))\n",
    "                else:\n",
    "                    cv2.imshow('detected cows',im0)\n",
    "                if cv2.waitKey(1) == ord('a'):  # q to quit\n",
    "                    raise StopIteration\n",
    "\n",
    "            # Save results (image with detections)\n",
    "            if (save_img or save_video) and HAS_COW:\n",
    "                if dataset.mode == 'image':\n",
    "                    cv2.imwrite(save_path, im0)\n",
    "                else :  # 'video' or 'stream'\n",
    "                    if vid_path[i] != save_path:  # new video\n",
    "                        vid_path[i] = save_path\n",
    "                        if isinstance(vid_writer[i], cv2.VideoWriter):\n",
    "                            vid_writer[i].release()  # release previous video writer\n",
    "                        if vid_cap:  # video\n",
    "                            fps = vid_cap.get(cv2.CAP_PROP_FPS)\n",
    "                            w = int(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "                            h = int(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "                            fps=frame_rate\n",
    "                        else:  # stream\n",
    "                            fps, w, h = 30, im0.shape[1], im0.shape[0]\n",
    "                            #fps=frame_rate\n",
    "                        save_path = str(Path(save_path).with_suffix('.mp4'))  # force *.mp4 suffix on results videos\n",
    "                        all_detected_cow.append('xxxxxxxxxxxxx')\n",
    "                        all_detected_cow.append('xxxxxxxxxxxxx')\n",
    "                        all_detected_cow.append(save_path)\n",
    "                        \n",
    "                        vid_writer[i] = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))\n",
    "                    vid_writer[i].write(im0)\n",
    "\n",
    "        # Print time (inference-only)\n",
    "        LOGGER.info(f'{s}Done. ({t3 - t2:.3f}s)')\n",
    "    cv2.destroyAllWindows()  \n",
    "    \n",
    "    #region release remaining video write\n",
    "    \n",
    "    #for index in range(len(demo_vid_path)):\n",
    "                        \n",
    "    #    if isinstance(demo_vid_writer[index], cv2.VideoWriter):\n",
    "    #        demo_vid_writer[index].release()  # release previous video writer\n",
    "    #        print('removed video write ', demo_vid_path[index])\n",
    "            \n",
    "    #demo_vid_path = []\n",
    "    \n",
    "    ##cmtbyslm\n",
    "\n",
    "    for loc in range(len(demo_img_save_path)):\n",
    "        print(demo_img_save_path[loc])\n",
    "        writeVideo(demo_img_save_path[loc])\n",
    "        \n",
    "    df = pd.DataFrame(cow_id, columns = [\"ID\"])\n",
    "    try:\n",
    "        original_ids = torch.tensor(cow_id_original, device = 'cpu')\n",
    "        df[\"Original\"] = original_ids\n",
    "    except:\n",
    "         df[\"Original\"] = cow_id_original\n",
    "    \n",
    "    \n",
    "    \n",
    "    now=str(datetime.now().date())\n",
    "    try:\n",
    "        print(all_detected_cow)\n",
    "        #all_detected_cow = torch.tensor(all_detected_cow,device=\"cpu\")\n",
    "        detected_cow_df = pd.DataFrame(all_detected_cow, columns = ['ID'])\n",
    "        detected_cow_df.to_csv('csv/all_detected_cow_'+str(frame_rate)+'_fps_'+now+'.csv')  \n",
    "        print('result saved to all_detected_cow_'+str(frame_rate)+'_fps_'+now+'.csv')\n",
    "    except :\n",
    "        print (\"couldn't save all_detected_cow\")\n",
    "    \n",
    "    path_to_csv = csv_save_dir+'/detected_cow_vggSVM_'+now+'.csv'\n",
    "    df.to_csv(path_to_csv, index= False) \n",
    "    \n",
    "    # Print results\n",
    "    t = tuple(x / seen * 1E3 for x in dt)  # speeds per image\n",
    "    LOGGER.info(f'Speed: %.1fms pre-process, %.1fms inference, %.1fms NMS per image at shape {(1, 3, *imgsz)}' % t)\n",
    "    \n",
    "    if save_txt or save_img:\n",
    "        s = f\"\\n{len(list(save_dir.glob('labels/*.txt')))} labels saved to {save_dir / 'labels'}\" if save_txt else ''\n",
    "        LOGGER.info(f\"Results saved to {colorstr('bold', save_dir)}{s}\")\n",
    "    if update:\n",
    "        strip_optimizer(weights)  # update model (to fix SourceChangeWarning)\n",
    "    \n",
    "    Generate_Cattle_Id_By_Apperance(path_to_csv,csv_save_dir)\n",
    "    \n",
    "    ##cmtbyslm_end\n",
    "    \n",
    "         #summarize ids\n",
    "    \n",
    "    summarize_id_csv = pd.DataFrame(manual_local_ids, columns = [\"Local Id\"])\n",
    "    try:\n",
    "        manual_summarize_ids = torch.tensor(manual_summarize_ids, device = 'cpu')\n",
    "        summarize_id_csv[\"Cow Id\"] = manual_summarize_ids\n",
    "    except:\n",
    "         summarize_id_csv[\"Cow Id\"] = manual_summarize_ids\n",
    "            \n",
    "    summarize_id_csv.to_csv(csv_save_dir+'/summarize_id_'+now+'.csv', index= False) \n",
    "    \n",
    "    \n",
    "    df.to_csv(csv_save_dir+'/detected_cow_vggSVM_'+now+'.csv', index= False) \n",
    "    # Print results\n",
    "    t = tuple(x / seen * 1E3 for x in dt)  # speeds per image\n",
    "    LOGGER.info(f'Speed: %.1fms pre-process, %.1fms inference, %.1fms NMS per image at shape {(1, 3, *imgsz)}' % t)\n",
    "    \n",
    "    if save_txt or save_img:\n",
    "        s = f\"\\n{len(list(save_dir.glob('labels/*.txt')))} labels saved to {save_dir / 'labels'}\" if save_txt else ''\n",
    "        LOGGER.info(f\"Results saved to {colorstr('bold', save_dir)}{s}\")\n",
    "    if update:\n",
    "        strip_optimizer(weights)  # update model (to fix SourceChangeWarning)\n",
    "        \n",
    "def parse_opt():\n",
    "    class Args:\n",
    "        weights='Sept_no_alien_weight_v1\\best.pt' # model.pt path(s) where is weight?\n",
    "        #source= \"C:\\\\Users\\\\thithilab\\\\Desktop\\\\file\\\\New Data\\\\14\\\\first32\\\\20220310_152525_E1E0.mkv\" # file/dir/URL/glob, 0 for webcam  //change your video path here\n",
    "        source= file_location # file/dir/URL/glob, 0 for webcam  //change your video path here\n",
    "        data='data/coco128.yaml'  # dataset.yaml path\n",
    "        imgsz=(640, 640)  # inference size (height, width)\n",
    "        conf_thres=0.60  # confidence threshold\n",
    "        iou_thres=0.45  # NMS IOU threshold\n",
    "        max_det=1000 # maximum detections per image\n",
    "        device='0'  # cuda device, i.e. 0 or 0,1,2,3 or cpu\n",
    "        view_img=True  # show results\n",
    "        save_txt=False  # save results to *.txt\n",
    "        save_conf=False  # save confidences in --save-txt labels\n",
    "        save_crop=True  # save cropped prediction boxes\n",
    "        nosave=False  # do not save images/videos\n",
    "        classes=None  # filter by class: --class 0, or --class 0 2 3\n",
    "        agnostic_nms=False  # class-agnostic NMS\n",
    "        augment=False  # augmented inference\n",
    "        visualize=False  # visualize features\n",
    "        update=False  # update all models\n",
    "        project='runs/detect_SVM_NV_demo_center'  # save results to project/name\n",
    "        name='exp'  # save results to project/name\n",
    "        exist_ok=False  # existing project/name ok, do not increment\n",
    "        line_thickness=8  # bounding box thickness (pixels)\n",
    "        hide_labels=False  # hide labels\n",
    "        hide_conf=False  # hide confidences\n",
    "        half=False  # use FP16 half-precision inference\n",
    "        dnn=False  # use OpenCV DNN for ONNX inference\n",
    "\n",
    "    return Args()\n",
    "     \n",
    "   #parser here\n",
    "\n",
    "\n",
    "def main(opt):\n",
    "    check_requirements(exclude=('tensorboard', 'thop'))\n",
    "    run(**vars(opt))\n",
    "    #run()\n",
    "\n",
    "#__name__==\"__main__\"\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    frame_rate=3\n",
    "    opt = parse_opt()\n",
    "    t = Timer()\n",
    "    t.start() # timer start\n",
    "    main(opt)\n",
    "    t.stop()  # A few seconds later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db7f014-2f41-455a-b2bc-bf7bcf77e612",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run second part here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04cc499-f330-4968-a479-4417ee596072",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "file_location=\"D:\\\\815_CowDataChecking\\\\20221116\\\\only_cow_1611_M\"\n",
    "\n",
    "\n",
    "def parse_opt():\n",
    "    class Args:\n",
    "        weights='Sept_no_alien_weight_v1\\best.pt' # model.pt path(s) where is weight?\n",
    "        #source= \"C:\\\\Users\\\\thithilab\\\\Desktop\\\\file\\\\New Data\\\\14\\\\first32\\\\20220310_152525_E1E0.mkv\" # file/dir/URL/glob, 0 for webcam  //change your video path here\n",
    "        source= file_location # file/dir/URL/glob, 0 for webcam  //change your video path here\n",
    "        data='data/coco128.yaml'  # dataset.yaml path\n",
    "        imgsz=(640, 640)  # inference size (height, width)\n",
    "        conf_thres=0.50  # confidence threshold\n",
    "        iou_thres=0.45  # NMS IOU threshold\n",
    "        max_det=1000 # maximum detections per image\n",
    "        device='0'  # cuda device, i.e. 0 or 0,1,2,3 or cpu\n",
    "        view_img=True  # show results\n",
    "        save_txt=False  # save results to *.txt\n",
    "        save_conf=False  # save confidences in --save-txt labels\n",
    "        save_crop=True  # save cropped prediction boxes\n",
    "        nosave=False  # do not save images/videos\n",
    "        classes=None  # filter by class: --class 0, or --class 0 2 3\n",
    "        agnostic_nms=False  # class-agnostic NMS\n",
    "        augment=False  # augmented inference\n",
    "        visualize=False  # visualize features\n",
    "        update=False  # update all models\n",
    "        project='runs/detect_SVM_NV_demo_center'  # save results to project/name\n",
    "        name='exp'  # save results to project/name\n",
    "        exist_ok=False  # existing project/name ok, do not increment\n",
    "        line_thickness=8  # bounding box thickness (pixels)\n",
    "        hide_labels=False  # hide labels\n",
    "        hide_conf=False  # hide confidences\n",
    "        half=False  # use FP16 half-precision inference\n",
    "        dnn=False  # use OpenCV DNN for ONNX inference\n",
    "\n",
    "    return Args()\n",
    "     \n",
    "   #parser here\n",
    "\n",
    "def main(opt):\n",
    "    check_requirements(exclude=('tensorboard', 'thop'))\n",
    "    run(**vars(opt))\n",
    "    #run()\n",
    "\n",
    "#__name__==\"__main__\"\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    frame_rate=3\n",
    "    opt = parse_opt()\n",
    "    t = Timer()\n",
    "    t.start() # timer start\n",
    "    main(opt)\n",
    "    t.stop()  # A few seconds later\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e73ce4b-15df-4b26-9c96-f38a47d7db37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9f10cc-ca66-4801-9d45-c8adb2e777ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ipkernel_launcher.py --source \"D:\\Python\\env\\Lameness\\Frames\\Videos\\20220201_145508_7108.mp4\"  --yolo-weights weights_slm/best_6_23_gpu.pt --view-img --save-crop --device 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5139acf2-ee9e-4f49-a18a-7e106c993efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#python -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69060ff2-8066-4d40-96e4-35aba19296dd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#second part is here\n",
    "file_location=\"D:\\\\815_CowDataChecking\\\\20221116\\\\only_cow_1611_E\"   #this is second\n",
    "#file_location = \"\\\\172.16.4.111\\\\Public\\\\訓子府L5G_2020\\生データ　original data\\\\360カメラ\\\\A\\\\20220907\\\\13\"\n",
    "\n",
    "def parse_opt():\n",
    "    class Args:\n",
    "        weights='Sept_no_alien_weight_v1\\best.pt' # model.pt path(s) where is weight?\n",
    "        #source= \"C:\\\\Users\\\\thithilab\\\\Desktop\\\\file\\\\New Data\\\\14\\\\first32\\\\20220310_152525_E1E0.mkv\" # file/dir/URL/glob, 0 for webcam  //change your video path here\n",
    "        source= file_location # file/dir/URL/glob, 0 for webcam  //change your video path here\n",
    "        data='data/coco128.yaml'  # dataset.yaml path\n",
    "        imgsz=(640, 640)  # inference size (height, width)\n",
    "        conf_thres=0.50  # confidence threshold\n",
    "        iou_thres=0.45  # NMS IOU threshold\n",
    "        max_det=1000 # maximum detections per image\n",
    "        device='0'  # cuda device, i.e. 0 or 0,1,2,3 or cpu\n",
    "        view_img=True  # show results\n",
    "        save_txt=False  # save results to *.txt\n",
    "        save_conf=False  # save confidences in --save-txt labels\n",
    "        save_crop=True  # save cropped prediction boxes\n",
    "        nosave=False  # do not save images/videos\n",
    "        classes=None  # filter by class: --class 0, or --class 0 2 3\n",
    "        agnostic_nms=False  # class-agnostic NMS\n",
    "        augment=False  # augmented inference\n",
    "        visualize=False  # visualize features\n",
    "        update=False  # update all models\n",
    "        project='runs/detect_SVM_NV_demo_center'  # save results to project/name\n",
    "        name='exp'  # save results to project/name\n",
    "        exist_ok=False  # existing project/name ok, do not increment\n",
    "        line_thickness=8  # bounding box thickness (pixels)\n",
    "        hide_labels=False  # hide labels\n",
    "        hide_conf=False  # hide confidences\n",
    "        half=False  # use FP16 half-precision inference\n",
    "        dnn=False  # use OpenCV DNN for ONNX inference\n",
    "\n",
    "    return Args()\n",
    "     \n",
    "   #parser here\n",
    "\n",
    "\n",
    "def main(opt):\n",
    "    check_requirements(exclude=('tensorboard', 'thop'))\n",
    "    run(**vars(opt))\n",
    "    #run()\n",
    "\n",
    "#__name__==\"__main__\"\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    frame_rate=3\n",
    "    opt = parse_opt()\n",
    "    t = Timer()\n",
    "    t.start() # timer start\n",
    "    main(opt)\n",
    "    t.stop()  # A few seconds later\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7debfd9a-a80d-46f8-8cc7-862b4a779647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2862305f-5eb4-423e-89c1-764167507e9b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#third part is here\n",
    "file_location=\"D:\\\\815_CowDataChecking\\\\20221117\\\\only_cow_1711_M\"   #this is second\n",
    "#file_location = \"\\\\172.16.4.111\\\\Public\\\\訓子府L5G_2020\\生データ　original data\\\\360カメラ\\\\A\\\\20220907\\\\13\"\n",
    "\n",
    "def parse_opt():\n",
    "    class Args:\n",
    "        weights='Sept_no_alien_weight_v1\\best.pt' # model.pt path(s) where is weight?\n",
    "        #source= \"C:\\\\Users\\\\thithilab\\\\Desktop\\\\file\\\\New Data\\\\14\\\\first32\\\\20220310_152525_E1E0.mkv\" # file/dir/URL/glob, 0 for webcam  //change your video path here\n",
    "        source= file_location # file/dir/URL/glob, 0 for webcam  //change your video path here\n",
    "        data='data/coco128.yaml'  # dataset.yaml path\n",
    "        imgsz=(640, 640)  # inference size (height, width)\n",
    "        conf_thres=0.50  # confidence threshold\n",
    "        iou_thres=0.45  # NMS IOU threshold\n",
    "        max_det=1000 # maximum detections per image\n",
    "        device='0'  # cuda device, i.e. 0 or 0,1,2,3 or cpu\n",
    "        view_img=True  # show results\n",
    "        save_txt=False  # save results to *.txt\n",
    "        save_conf=False  # save confidences in --save-txt labels\n",
    "        save_crop=True  # save cropped prediction boxes\n",
    "        nosave=False  # do not save images/videos\n",
    "        classes=None  # filter by class: --class 0, or --class 0 2 3\n",
    "        agnostic_nms=False  # class-agnostic NMS\n",
    "        augment=False  # augmented inference\n",
    "        visualize=False  # visualize features\n",
    "        update=False  # update all models\n",
    "        project='runs/detect_SVM_NV_demo_center'  # save results to project/name\n",
    "        name='exp'  # save results to project/name\n",
    "        exist_ok=False  # existing project/name ok, do not increment\n",
    "        line_thickness=8  # bounding box thickness (pixels)\n",
    "        hide_labels=False  # hide labels\n",
    "        hide_conf=False  # hide confidences\n",
    "        half=False  # use FP16 half-precision inference\n",
    "        dnn=False  # use OpenCV DNN for ONNX inference\n",
    "\n",
    "    return Args()\n",
    "     \n",
    "   #parser here\n",
    "\n",
    "\n",
    "def main(opt):\n",
    "    check_requirements(exclude=('tensorboard', 'thop'))\n",
    "    run(**vars(opt))\n",
    "    #run()\n",
    "\n",
    "#__name__==\"__main__\"\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    frame_rate=3\n",
    "    opt = parse_opt()\n",
    "    t = Timer()\n",
    "    t.start() # timer start\n",
    "    main(opt)\n",
    "    t.stop()  # A few seconds later\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfd271f-3b94-4b68-b067-a7962a2c36f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56c8956-5c00-4a6b-a715-e19c67b1277c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#fourth part is here\n",
    "file_location=\"D:\\\\815_CowDataChecking\\\\20221117\\\\only_cow_1711_E\"   #this is second\n",
    "#file_location = \"\\\\172.16.4.111\\\\Public\\\\訓子府L5G_2020\\生データ　original data\\\\360カメラ\\\\A\\\\20220907\\\\13\"\n",
    "\n",
    "def parse_opt():\n",
    "    class Args:\n",
    "        weights='Sept_no_alien_weight_v1\\best.pt' # model.pt path(s) where is weight?\n",
    "        #source= \"C:\\\\Users\\\\thithilab\\\\Desktop\\\\file\\\\New Data\\\\14\\\\first32\\\\20220310_152525_E1E0.mkv\" # file/dir/URL/glob, 0 for webcam  //change your video path here\n",
    "        source= file_location # file/dir/URL/glob, 0 for webcam  //change your video path here\n",
    "        data='data/coco128.yaml'  # dataset.yaml path\n",
    "        imgsz=(640, 640)  # inference size (height, width)\n",
    "        conf_thres=0.50  # confidence threshold\n",
    "        iou_thres=0.45  # NMS IOU threshold\n",
    "        max_det=1000 # maximum detections per image\n",
    "        device='0'  # cuda device, i.e. 0 or 0,1,2,3 or cpu\n",
    "        view_img=True  # show results\n",
    "        save_txt=False  # save results to *.txt\n",
    "        save_conf=False  # save confidences in --save-txt labels\n",
    "        save_crop=True  # save cropped prediction boxes\n",
    "        nosave=False  # do not save images/videos\n",
    "        classes=None  # filter by class: --class 0, or --class 0 2 3\n",
    "        agnostic_nms=False  # class-agnostic NMS\n",
    "        augment=False  # augmented inference\n",
    "        visualize=False  # visualize features\n",
    "        update=False  # update all models\n",
    "        project='runs/detect_SVM_NV_demo_center'  # save results to project/name\n",
    "        name='exp'  # save results to project/name\n",
    "        exist_ok=False  # existing project/name ok, do not increment\n",
    "        line_thickness=8  # bounding box thickness (pixels)\n",
    "        hide_labels=False  # hide labels\n",
    "        hide_conf=False  # hide confidences\n",
    "        half=False  # use FP16 half-precision inference\n",
    "        dnn=False  # use OpenCV DNN for ONNX inference\n",
    "\n",
    "    return Args()\n",
    "     \n",
    "   #parser here\n",
    "\n",
    "\n",
    "def main(opt):\n",
    "    check_requirements(exclude=('tensorboard', 'thop'))\n",
    "    run(**vars(opt))\n",
    "    #run()\n",
    "\n",
    "#__name__==\"__main__\"\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    frame_rate=3\n",
    "    opt = parse_opt()\n",
    "    t = Timer()\n",
    "    t.start() # timer start\n",
    "    main(opt)\n",
    "    t.stop()  # A few seconds later\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da990bc-7c29-4e4d-b7ca-6626287b5ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#third part is here\n",
    "file_location=\"D:\\\\815_CowDataChecking\\\\20221118\\\\only_cow_1811_M\"   #this is second\n",
    "#file_location = \"\\\\172.16.4.111\\\\Public\\\\訓子府L5G_2020\\生データ　original data\\\\360カメラ\\\\A\\\\20220907\\\\13\"\n",
    "\n",
    "def parse_opt():\n",
    "    class Args:\n",
    "        weights='Sept_no_alien_weight_v1\\best.pt' # model.pt path(s) where is weight?\n",
    "        #source= \"C:\\\\Users\\\\thithilab\\\\Desktop\\\\file\\\\New Data\\\\14\\\\first32\\\\20220310_152525_E1E0.mkv\" # file/dir/URL/glob, 0 for webcam  //change your video path here\n",
    "        source= file_location # file/dir/URL/glob, 0 for webcam  //change your video path here\n",
    "        data='data/coco128.yaml'  # dataset.yaml path\n",
    "        imgsz=(640, 640)  # inference size (height, width)\n",
    "        conf_thres=0.50  # confidence threshold\n",
    "        iou_thres=0.45  # NMS IOU threshold\n",
    "        max_det=1000 # maximum detections per image\n",
    "        device='0'  # cuda device, i.e. 0 or 0,1,2,3 or cpu\n",
    "        view_img=True  # show results\n",
    "        save_txt=False  # save results to *.txt\n",
    "        save_conf=False  # save confidences in --save-txt labels\n",
    "        save_crop=True  # save cropped prediction boxes\n",
    "        nosave=False  # do not save images/videos\n",
    "        classes=None  # filter by class: --class 0, or --class 0 2 3\n",
    "        agnostic_nms=False  # class-agnostic NMS\n",
    "        augment=False  # augmented inference\n",
    "        visualize=False  # visualize features\n",
    "        update=False  # update all models\n",
    "        project='runs/detect_SVM_NV_demo_center'  # save results to project/name\n",
    "        name='exp'  # save results to project/name\n",
    "        exist_ok=False  # existing project/name ok, do not increment\n",
    "        line_thickness=8  # bounding box thickness (pixels)\n",
    "        hide_labels=False  # hide labels\n",
    "        hide_conf=False  # hide confidences\n",
    "        half=False  # use FP16 half-precision inference\n",
    "        dnn=False  # use OpenCV DNN for ONNX inference\n",
    "\n",
    "    return Args()\n",
    "     \n",
    "   #parser here\n",
    "\n",
    "\n",
    "def main(opt):\n",
    "    check_requirements(exclude=('tensorboard', 'thop'))\n",
    "    run(**vars(opt))\n",
    "    #run()\n",
    "\n",
    "#__name__==\"__main__\"\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    frame_rate=3\n",
    "    opt = parse_opt()\n",
    "    t = Timer()\n",
    "    t.start() # timer start\n",
    "    main(opt)\n",
    "    t.stop()  # A few seconds later\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0a62a2-2314-4d4d-af7a-73972631959a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#third part is here\n",
    "file_location=\"D:\\\\815_CowDataChecking\\\\20221118\\\\only_cow_1811_E\"   #this is second\n",
    "#file_location = \"\\\\172.16.4.111\\\\Public\\\\訓子府L5G_2020\\生データ　original data\\\\360カメラ\\\\A\\\\20220907\\\\13\"\n",
    "\n",
    "def parse_opt():\n",
    "    class Args:\n",
    "        weights='Sept_no_alien_weight_v1\\best.pt' # model.pt path(s) where is weight?\n",
    "        #source= \"C:\\\\Users\\\\thithilab\\\\Desktop\\\\file\\\\New Data\\\\14\\\\first32\\\\20220310_152525_E1E0.mkv\" # file/dir/URL/glob, 0 for webcam  //change your video path here\n",
    "        source= file_location # file/dir/URL/glob, 0 for webcam  //change your video path here\n",
    "        data='data/coco128.yaml'  # dataset.yaml path\n",
    "        imgsz=(640, 640)  # inference size (height, width)\n",
    "        conf_thres=0.50  # confidence threshold\n",
    "        iou_thres=0.45  # NMS IOU threshold\n",
    "        max_det=1000 # maximum detections per image\n",
    "        device='0'  # cuda device, i.e. 0 or 0,1,2,3 or cpu\n",
    "        view_img=True  # show results\n",
    "        save_txt=False  # save results to *.txt\n",
    "        save_conf=False  # save confidences in --save-txt labels\n",
    "        save_crop=True  # save cropped prediction boxes\n",
    "        nosave=False  # do not save images/videos\n",
    "        classes=None  # filter by class: --class 0, or --class 0 2 3\n",
    "        agnostic_nms=False  # class-agnostic NMS\n",
    "        augment=False  # augmented inference\n",
    "        visualize=False  # visualize features\n",
    "        update=False  # update all models\n",
    "        project='runs/detect_SVM_NV_demo_center'  # save results to project/name\n",
    "        name='exp'  # save results to project/name\n",
    "        exist_ok=False  # existing project/name ok, do not increment\n",
    "        line_thickness=8  # bounding box thickness (pixels)\n",
    "        hide_labels=False  # hide labels\n",
    "        hide_conf=False  # hide confidences\n",
    "        half=False  # use FP16 half-precision inference\n",
    "        dnn=False  # use OpenCV DNN for ONNX inference\n",
    "\n",
    "    return Args()\n",
    "     \n",
    "   #parser here\n",
    "\n",
    "\n",
    "def main(opt):\n",
    "    check_requirements(exclude=('tensorboard', 'thop'))\n",
    "    run(**vars(opt))\n",
    "    #run()\n",
    "\n",
    "#__name__==\"__main__\"\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    frame_rate=3\n",
    "    opt = parse_opt()\n",
    "    t = Timer()\n",
    "    t.start() # timer start\n",
    "    main(opt)\n",
    "    t.stop()  # A few seconds later\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211d17a6-e24d-40d2-aae9-d7a85fda8c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import cv2\n",
    "#print(cv2. __version__) # previous version 4.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37758d6-3698-4102-8c29-509297193956",
   "metadata": {},
   "outputs": [],
   "source": [
    "#p.set_printoptions(threshold=sys.maxsize)  #run me before printing , to find the meaning of variable, you can just find and print them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7f3d53-7d99-41a9-9b25-79fbb3488db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X_test_feature) #print me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972b727d-861a-4fbb-922d-389b5bff6f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X_test_features)  #print me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21048563-d565-4833-97c1-879c8471da0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X_For_RF) ## print me"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
