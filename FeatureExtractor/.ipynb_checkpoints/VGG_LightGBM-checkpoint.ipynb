{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5099ec81-b427-40ee-bd81-671d3f5b6941",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thithilab\\AppData\\Roaming\\Python\\Python39\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# https://youtu.be/9GzfUzJeyi0\n",
    "\n",
    "\"\"\"\n",
    "@author: Sreenivas Bhattiprolu\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "#from keras.layers.normalization import BatchNormalization\n",
    "import os\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75f669d5-b254-4061-a946-bdadd09de6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thithilab\\AppData\\Roaming\\Python\\Python37\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "total_classes=0  #to change when mee lay want to add more cows\n",
    "#images_per_validation=5\n",
    "\n",
    "\n",
    "#print(os.listdir(\"../Gold\"))\n",
    "\n",
    "SIZE = 224\n",
    "\n",
    "import csv\n",
    "\n",
    "#data = pd.read_csv('D:\\\\LamenessData\\\\September_6\\\\evening.csv',index_col ='Local_ID')\n",
    "\n",
    "#COW_MAPPER = [list(row) for row in data.values]\n",
    "\n",
    "train_images = []\n",
    "train_labels = [] \n",
    "for directory_path in glob.glob(\"D:\\LamenessData\\September_6\\DataByGroup\\\\AllCows\\\\Training/*\"):\n",
    "    label = directory_path.split(\"\\\\\")[-1]\n",
    "    #print(label)\n",
    "    total_classes+=1\n",
    "    for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n",
    "        #print(img_path)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)       \n",
    "        \n",
    "        \n",
    "        img = cv2.resize(img, (SIZE, SIZE))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        train_images.append(img)\n",
    "        train_labels.append(label)\n",
    "        \n",
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "print(total_classes)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7571ec9-6ec6-4988-96e9-34e42f05eb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train lables encoded is here\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# test\n",
    "test_images = []\n",
    "test_labels = [] \n",
    "images_per_validation =[]\n",
    "for directory_path in glob.glob(\"D:\\LamenessData\\September_6\\DataByGroup\\\\AllCows\\\\Validation/*\"):  #to change when baby add new images\n",
    "    fruit_label = directory_path.split(\"\\\\\")[-1]\n",
    "    count=0\n",
    "    for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        img = cv2.resize(img, (SIZE, SIZE))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        test_images.append(img)\n",
    "        test_labels.append(fruit_label)\n",
    "        count+=1\n",
    "    images_per_validation.append(count)\n",
    "        \n",
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)\n",
    "#Encode labels from text to integers.\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(test_labels)\n",
    "test_labels_encoded = le.transform(test_labels)\n",
    "le.fit(train_labels)\n",
    "train_labels_encoded = le.transform(train_labels)\n",
    "print(\"Train lables encoded is here\")\n",
    "#print(train_labels_encoded)\n",
    "#Split data into test and train datasets (already split but assigning to meaningful convention)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7255eec1-2f46-4204-85af-3af189cc6446",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train, y_train, x_test, y_test = train_images, train_labels_encoded, test_images, test_labels_encoded\n",
    "\n",
    "###################################################################\n",
    "# Normalize pixel values to between 0 and 1\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "#One hot encode y values for neural network. \n",
    "from keras.utils import to_categorical\n",
    "y_train_one_hot = to_categorical(y_train)\n",
    "y_test_one_hot = to_categorical(y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe7f24d8-42da-4406-8399-c1b2431404f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "1091/1091 [==============================] - 1121s 1s/step\n",
      "generated featured\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#############################\n",
    "#Load model wothout classifier/fully connected layers\n",
    "VGG_model = VGG16(weights='imagenet', include_top=False, input_shape=(SIZE, SIZE, 3))\n",
    "\n",
    "#Make loaded layers as non-trainable. This is important as we want to work with pre-trained weights\n",
    "for layer in VGG_model.layers:\n",
    "\tlayer.trainable = False\n",
    "    \n",
    "VGG_model.summary()  #Trainable parameters will be 0\n",
    "\n",
    "\n",
    "#Now, let us use features from convolutional network for RF\n",
    "feature_extractor=VGG_model.predict(x_train)\n",
    "\n",
    "features = feature_extractor.reshape(feature_extractor.shape[0], -1)\n",
    "\n",
    "\n",
    "X_for_RF = features #This is our X input to RF\n",
    "\n",
    "print(\"generated featured\")\n",
    "\n",
    "#############################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "421c47c0-1f19-4c39-9a28-c108de490015",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ytrain_name_filename = 'May_Weights/Y_TRAIN_V1.pkl'\n",
    "features_filename = 'May_Weights/GENERAL_FEATURES_v1.pkl'\n",
    "y_train = pickle.load(open(ytrain_name_filename, 'rb'))\n",
    "features = pickle.load(open(features_filename, 'rb'))\n",
    "#le = pickle.load(open(le_filename, 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c79ded78-6e95-46d8-9354-b73779f561c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "x_train = pickle.load(open('../June_Weights_HOG/GENERAL_X_TRAIN.pkl','rb'))\n",
    "y_train = pickle.load(open('../June_Weights_HOG/GENERAL_Y_TRAIN.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df3156a0-aa2f-4808-979b-5ac21bfbe0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "lgb_train = lgb.Dataset(x_train, y_train)\n",
    "\n",
    "# Set LightGBM parameters\n",
    "params = {\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': 146,  # Replace 'num_classes' with the actual number of classes in your dataset\n",
    "    'metric': 'multi_logloss',\n",
    "}\n",
    "\n",
    "# Train the LightGBM model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8bbcc9-675a-4b15-a291-f88f6a8f5458",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.584474 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 881280\n",
      "[LightGBM] [Info] Number of data points in the train set: 31451, number of used features: 3456\n",
      "[LightGBM] [Info] Start training from score -3.853396\n",
      "[LightGBM] [Info] Start training from score -5.585501\n",
      "[LightGBM] [Info] Start training from score -5.692747\n",
      "[LightGBM] [Info] Start training from score -6.197303\n",
      "[LightGBM] [Info] Start training from score -5.428932\n",
      "[LightGBM] [Info] Start training from score -4.757764\n",
      "[LightGBM] [Info] Start training from score -6.245312\n",
      "[LightGBM] [Info] Start training from score -4.141578\n",
      "[LightGBM] [Info] Start training from score -5.287282\n",
      "[LightGBM] [Info] Start training from score -6.404942\n",
      "[LightGBM] [Info] Start training from score -5.577063\n",
      "[LightGBM] [Info] Start training from score -5.232222\n",
      "[LightGBM] [Info] Start training from score -6.136678\n",
      "[LightGBM] [Info] Start training from score -6.484985\n",
      "[LightGBM] [Info] Start training from score -5.400359\n",
      "[LightGBM] [Info] Start training from score -6.093506\n",
      "[LightGBM] [Info] Start training from score -5.421712\n",
      "[LightGBM] [Info] Start training from score -3.929698\n",
      "[LightGBM] [Info] Start training from score -5.287282\n",
      "[LightGBM] [Info] Start training from score -4.867248\n",
      "[LightGBM] [Info] Start training from score -5.802309\n",
      "[LightGBM] [Info] Start training from score -4.450824\n",
      "[LightGBM] [Info] Start training from score -6.079520\n",
      "[LightGBM] [Info] Start training from score -4.461783\n",
      "[LightGBM] [Info] Start training from score -6.229052\n",
      "[LightGBM] [Info] Start training from score -5.450911\n",
      "[LightGBM] [Info] Start training from score -6.330834\n",
      "[LightGBM] [Info] Start training from score -6.136678\n",
      "[LightGBM] [Info] Start training from score -5.256320\n",
      "[LightGBM] [Info] Start training from score -3.741460\n",
      "[LightGBM] [Info] Start training from score -4.918107\n",
      "[LightGBM] [Info] Start training from score -5.974159\n",
      "[LightGBM] [Info] Start training from score -5.293591\n",
      "[LightGBM] [Info] Start training from score -5.208692\n",
      "[LightGBM] [Info] Start training from score -4.533140\n",
      "[LightGBM] [Info] Start training from score -6.052121\n",
      "[LightGBM] [Info] Start training from score -4.672606\n",
      "[LightGBM] [Info] Start training from score -3.094259\n",
      "[LightGBM] [Info] Start training from score -4.994894\n",
      "[LightGBM] [Info] Start training from score -6.038698\n",
      "[LightGBM] [Info] Start training from score -4.971691\n",
      "[LightGBM] [Info] Start training from score -4.632601\n",
      "[LightGBM] [Info] Start training from score -4.940086\n",
      "[LightGBM] [Info] Start training from score -5.428932\n",
      "[LightGBM] [Info] Start training from score -5.428932\n",
      "[LightGBM] [Info] Start training from score -6.166531\n",
      "[LightGBM] [Info] Start training from score -5.834397\n",
      "[LightGBM] [Info] Start training from score -5.602596\n",
      "[LightGBM] [Info] Start training from score -4.693226\n",
      "[LightGBM] [Info] Start training from score -5.611254\n",
      "[LightGBM] [Info] Start training from score -4.442683\n",
      "[LightGBM] [Info] Start training from score -4.450824\n",
      "[LightGBM] [Info] Start training from score -4.037218\n",
      "[LightGBM] [Info] Start training from score -3.548251\n",
      "[LightGBM] [Info] Start training from score -5.103913\n",
      "[LightGBM] [Info] Start training from score -6.181799\n",
      "[LightGBM] [Info] Start training from score -5.414544\n",
      "[LightGBM] [Info] Start training from score -5.552165\n",
      "[LightGBM] [Info] Start training from score -4.686305\n",
      "[LightGBM] [Info] Start training from score -6.038698\n",
      "[LightGBM] [Info] Start training from score -5.771219\n",
      "[LightGBM] [Info] Start training from score -4.238089\n",
      "[LightGBM] [Info] Start training from score -6.348853\n",
      "[LightGBM] [Info] Start training from score -5.585501\n",
      "[LightGBM] [Info] Start training from score -5.287282\n",
      "[LightGBM] [Info] Start training from score -5.262436\n",
      "[LightGBM] [Info] Start training from score -4.842757\n",
      "[LightGBM] [Info] Start training from score -6.136678\n",
      "[LightGBM] [Info] Start training from score -4.626086\n",
      "[LightGBM] [Info] Start training from score -3.854896\n",
      "[LightGBM] [Info] Start training from score -6.829826\n",
      "[LightGBM] [Info] Start training from score -5.256320\n",
      "[LightGBM] [Info] Start training from score -4.244719\n",
      "[LightGBM] [Info] Start training from score -4.900865\n",
      "[LightGBM] [Info] Start training from score -5.585501\n",
      "[LightGBM] [Info] Start training from score -4.859018\n",
      "[LightGBM] [Info] Start training from score -6.444163\n",
      "[LightGBM] [Info] Start training from score -4.606793\n",
      "[LightGBM] [Info] Start training from score -4.031827\n",
      "[LightGBM] [Info] Start training from score -5.999477\n",
      "[LightGBM] [Info] Start training from score -4.264876\n",
      "[LightGBM] [Info] Start training from score -4.962559\n",
      "[LightGBM] [Info] Start training from score -6.618516\n",
      "[LightGBM] [Info] Start training from score -4.545045\n",
      "[LightGBM] [Info] Start training from score -6.954989\n",
      "[LightGBM] [Info] Start training from score -5.721457\n",
      "[LightGBM] [Info] Start training from score -5.731213\n",
      "[LightGBM] [Info] Start training from score -4.129649\n",
      "[LightGBM] [Info] Start training from score -4.645759\n",
      "[LightGBM] [Info] Start training from score -4.649076\n",
      "[LightGBM] [Info] Start training from score -5.220388\n",
      "[LightGBM] [Info] Start training from score -4.057237\n",
      "[LightGBM] [Info] Start training from score -6.025453\n",
      "[LightGBM] [Info] Start training from score -5.202894\n",
      "[LightGBM] [Info] Start training from score -3.514571\n",
      "[LightGBM] [Info] Start training from score -4.799358\n",
      "[LightGBM] [Info] Start training from score -6.988890\n",
      "[LightGBM] [Info] Start training from score -5.130439\n",
      "[LightGBM] [Info] Start training from score -4.584745\n",
      "[LightGBM] [Info] Start training from score -7.265144\n",
      "[LightGBM] [Info] Start training from score -6.197303\n",
      "[LightGBM] [Info] Start training from score -5.450911\n",
      "[LightGBM] [Info] Start training from score -6.954989\n",
      "[LightGBM] [Info] Start training from score -5.802309\n",
      "[LightGBM] [Info] Start training from score -6.424360\n",
      "[LightGBM] [Info] Start training from score -5.731213\n",
      "[LightGBM] [Info] Start training from score -6.025453\n",
      "[LightGBM] [Info] Start training from score -3.382643\n",
      "[LightGBM] [Info] Start training from score -7.178132\n",
      "[LightGBM] [Info] Start training from score -6.527545\n",
      "[LightGBM] [Info] Start training from score -5.646656\n",
      "[LightGBM] [Info] Start training from score -5.856376\n",
      "[LightGBM] [Info] Start training from score -6.829826\n",
      "[LightGBM] [Info] Start training from score -5.949467\n",
      "[LightGBM] [Info] Start training from score -5.674055\n",
      "[LightGBM] [Info] Start training from score -3.868502\n",
      "[LightGBM] [Info] Start training from score -5.057869\n",
      "[LightGBM] [Info] Start training from score -5.208692\n",
      "[LightGBM] [Info] Start training from score -6.424360\n",
      "[LightGBM] [Info] Start training from score -6.348853\n",
      "[LightGBM] [Info] Start training from score -4.606793\n",
      "[LightGBM] [Info] Start training from score -5.949467\n",
      "[LightGBM] [Info] Start training from score -5.109162\n",
      "[LightGBM] [Info] Start training from score -6.922199\n",
      "[LightGBM] [Info] Start training from score -5.925369\n",
      "[LightGBM] [Info] Start training from score -7.265144\n",
      "[LightGBM] [Info] Start training from score -5.480989\n",
      "[LightGBM] [Info] Start training from score -4.311181\n",
      "[LightGBM] [Info] Start training from score -4.700194\n",
      "[LightGBM] [Info] Start training from score -5.220388\n",
      "[LightGBM] [Info] Start training from score -5.098691\n",
      "[LightGBM] [Info] Start training from score -5.611254\n",
      "[LightGBM] [Info] Start training from score -5.220388\n",
      "[LightGBM] [Info] Start training from score -7.060349\n",
      "[LightGBM] [Info] Start training from score -4.542056\n",
      "[LightGBM] [Info] Start training from score -5.047918\n",
      "[LightGBM] [Info] Start training from score -4.838733\n",
      "[LightGBM] [Info] Start training from score -4.838733\n",
      "[LightGBM] [Info] Start training from score -4.472864\n",
      "[LightGBM] [Info] Start training from score -6.295743\n",
      "[LightGBM] [Info] Start training from score -6.213051\n",
      "[LightGBM] [Info] Start training from score -6.922199\n",
      "[LightGBM] [Info] Start training from score -5.664838\n",
      "[LightGBM] [Info] Start training from score -5.655706\n",
      "[LightGBM] [Info] Start training from score -6.385894\n",
      "[LightGBM] [Info] Start training from score -3.979459\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    }
   ],
   "source": [
    "model = lgb.train(params, lgb_train, num_boost_round=100)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6eaa0d4-78eb-4e5e-b44b-7d2dc5c13742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model_name ='../June_Weights_HOG/HOG_LIGHTGBM.pkl'\n",
    "pickle.dump(model,open(model_name,'wb'))\n",
    "\n",
    "print(\"done\")\n",
    "\n",
    "\n",
    "#########################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5052d22c-6951-41ca-b4f3-0f74b0f21e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "VGG_model.save('May_Weights/GENERAL_VGG_v1.h5')\n",
    "\n",
    "\n",
    "le_filename = 'May_Weights/GENERAL_LABEL_v1.le'\n",
    "pickle.dump(le, open(le_filename, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b8addb-f384-4e57-adec-a56cd3beb79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_filename = 'May_Weights/GENERAL_FEATURES_v1.pkl'\n",
    "pickle.dump(features, open(features_filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bed6af-8bd0-4387-a5a1-f2156a0fb914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b09e7c-7501-4528-a3dc-41db5c21e92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load modelsavedModels\n",
    "#vgg_filename = 'vgg16_model.sav'\n",
    "#svm_filename ='svm.sav'\n",
    "#VGG_model = pickle.load(open(vgg_filename, 'rb'))\n",
    "#clf = pickle.load(open(svm_filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56ed492-0342-4565-91cf-2be02cffeacd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d34cb07-e050-4e68-9f50-0d2513f48518",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c4b1d2-7456-4dcf-9199-7de099d2833b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead9d88d-25c3-4ac2-841b-89a4fdcf97f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "0e361806-ec6a-4626-81ac-c039c4880bbb",
   "metadata": {},
   "source": [
    "One Class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db7f014-2f41-455a-b2bc-bf7bcf77e612",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run second part here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e73ce4b-15df-4b26-9c96-f38a47d7db37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9f10cc-ca66-4801-9d45-c8adb2e777ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ipkernel_launcher.py --source \"D:\\Python\\env\\Lameness\\Frames\\Videos\\20220201_145508_7108.mp4\"  --yolo-weights weights_slm/best_6_23_gpu.pt --view-img --save-crop --device 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5139acf2-ee9e-4f49-a18a-7e106c993efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#python -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7debfd9a-a80d-46f8-8cc7-862b4a779647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfd271f-3b94-4b68-b067-a7962a2c36f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21048563-d565-4833-97c1-879c8471da0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X_For_RF) ## print me"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
